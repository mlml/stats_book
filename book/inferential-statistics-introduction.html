<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Quantitative Methods for Linguistic Data</title>
  <meta name="description" content="Quantitative Methods for Linguistic Data">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Quantitative Methods for Linguistic Data" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Quantitative Methods for Linguistic Data" />
  
  
  

<meta name="author" content="Morgan Sonderegger, Michael Wagner, Francisco Torreira">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="hypothesis-testing.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Quantitative Methods for Linguistic Data</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html"><i class="fa fa-check"></i><b>1</b> Inferential statistics: Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sample-population"><i class="fa fa-check"></i><b>1.1</b> Population vs. sample</a><ul>
<li class="chapter" data-level="1.1.1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sample-to-population-high-level"><i class="fa fa-check"></i><b>1.1.1</b> Sample <span class="math inline">\(\to\)</span> population: High level</a></li>
<li class="chapter" data-level="1.1.2" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sdsm"><i class="fa fa-check"></i><b>1.1.2</b> Sampling distribution of the sample mean</a></li>
<li class="chapter" data-level="1.1.3" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sampling-from-a-non-normal-distribution"><i class="fa fa-check"></i><b>1.1.3</b> Sampling from a non-normal distribution</a></li>
<li class="chapter" data-level="" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#exercises"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#confidence-intervals"><i class="fa fa-check"></i><b>1.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="1.3" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#t-distribution"><i class="fa fa-check"></i><b>1.3</b> <span class="math inline">\(t\)</span> distribution</a><ul>
<li class="chapter" data-level="1.3.1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#t-based-confidence-intervals"><i class="fa fa-check"></i><b>1.3.1</b> <span class="math inline">\(t\)</span>-based confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#other-reading"><i class="fa fa-check"></i><b>1.4</b> Other reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>2</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="2.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-high-level"><i class="fa fa-check"></i><b>2.1</b> Hypothesis testing: High-level</a></li>
<li class="chapter" data-level="2.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#z-scores"><i class="fa fa-check"></i><b>2.2</b> <span class="math inline">\(z\)</span>-scores</a></li>
<li class="chapter" data-level="2.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-tests"><i class="fa fa-check"></i><b>2.3</b> <span class="math inline">\(t\)</span>-tests</a><ul>
<li class="chapter" data-level="2.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#single-sample-t-test-setup"><i class="fa fa-check"></i><b>2.3.1</b> Single-sample <span class="math inline">\(t\)</span>-test: Setup</a></li>
<li class="chapter" data-level="2.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-in-general"><i class="fa fa-check"></i><b>2.3.2</b> Hypothesis testing in general</a></li>
<li class="chapter" data-level="2.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-sample-t-test"><i class="fa fa-check"></i><b>2.3.3</b> Two-sample <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="2.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#welch-example"><i class="fa fa-check"></i><b>2.3.4</b> Unequal variances: Welch <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="2.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-test-assumptions"><i class="fa fa-check"></i><b>2.3.5</b> Assumptions behind <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="2.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paired-t-test"><i class="fa fa-check"></i><b>2.3.6</b> Paired <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="2.3.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#reporting-a-hypothesis-test"><i class="fa fa-check"></i><b>2.3.7</b> Reporting a hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#checking-normality"><i class="fa fa-check"></i><b>2.4</b> Checking normality</a><ul>
<li class="chapter" data-level="2.4.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#visual-methods"><i class="fa fa-check"></i><b>2.4.1</b> Visual methods</a></li>
<li class="chapter" data-level="2.4.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#q-q-plots"><i class="fa fa-check"></i><b>2.4.2</b> Q-Q plots</a></li>
<li class="chapter" data-level="2.4.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#shapiro-wilk-example"><i class="fa fa-check"></i><b>2.4.3</b> Hypothesis test</a></li>
<li class="chapter" data-level="2.4.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#other-parametric-tests"><i class="fa fa-check"></i><b>2.4.4</b> Other parametric tests</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#non-parametric-tests"><i class="fa fa-check"></i><b>2.5</b> Non-parametric tests</a><ul>
<li class="chapter" data-level="2.5.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#wilcoxson-tests"><i class="fa fa-check"></i><b>2.5.1</b> Wilcoxson tests</a></li>
<li class="chapter" data-level="2.5.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-sample-wilcoxson-test"><i class="fa fa-check"></i><b>2.5.2</b> Two-sample Wilcoxson test</a></li>
<li class="chapter" data-level="2.5.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#parametric-versus-non-parametric-tests"><i class="fa fa-check"></i><b>2.5.3</b> Parametric versus non-parametric tests</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#other-reading-1"><i class="fa fa-check"></i><b>2.6</b> Other reading</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>3</b> Linear regression</a><ul>
<li class="chapter" data-level="3.1" data-path="linear-regression.html"><a href="linear-regression.html#regression-general-introduction"><i class="fa fa-check"></i><b>3.1</b> Regression: General introduction</a><ul>
<li class="chapter" data-level="3.1.1" data-path="linear-regression.html"><a href="linear-regression.html#linear-models"><i class="fa fa-check"></i><b>3.1.1</b> Linear models</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-regression.html"><a href="linear-regression.html#terminology"><i class="fa fa-check"></i><b>3.1.2</b> Terminology</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear-regression.html"><a href="linear-regression.html#steps-and-assumptions-of-regression-analysis"><i class="fa fa-check"></i><b>3.1.3</b> Steps and assumptions of regression analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear-regression.html"><a href="linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>3.2</b> Simple linear regression</a><ul>
<li class="chapter" data-level="3.2.1" data-path="linear-regression.html"><a href="linear-regression.html#slr-continuous-predictor"><i class="fa fa-check"></i><b>3.2.1</b> SLR: Continuous predictor</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-regression.html"><a href="linear-regression.html#slr-parameter-estimation"><i class="fa fa-check"></i><b>3.2.2</b> SLR: Parameter estimation</a></li>
<li class="chapter" data-level="3.2.3" data-path="linear-regression.html"><a href="linear-regression.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>3.2.3</b> Hypothesis testing</a></li>
<li class="chapter" data-level="3.2.4" data-path="linear-regression.html"><a href="linear-regression.html#quality-of-fit"><i class="fa fa-check"></i><b>3.2.4</b> Quality of fit</a></li>
<li class="chapter" data-level="3.2.5" data-path="linear-regression.html"><a href="linear-regression.html#categorical-predictor"><i class="fa fa-check"></i><b>3.2.5</b> Categorical predictor</a></li>
<li class="chapter" data-level="3.2.6" data-path="linear-regression.html"><a href="linear-regression.html#slr-with-a-binary-categorical-predictor-vs.two-sample-t-test"><i class="fa fa-check"></i><b>3.2.6</b> SLR with a binary categorical predictor vs. two-sample <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="linear-regression.html"><a href="linear-regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>3.3</b> Multiple linear regression</a><ul>
<li class="chapter" data-level="3.3.1" data-path="linear-regression.html"><a href="linear-regression.html#goodness-of-fit-metrics"><i class="fa fa-check"></i><b>3.3.1</b> Goodness of fit metrics</a></li>
<li class="chapter" data-level="3.3.2" data-path="linear-regression.html"><a href="linear-regression.html#interactions-and-factors"><i class="fa fa-check"></i><b>3.3.2</b> Interactions and factors</a></li>
<li class="chapter" data-level="3.3.3" data-path="linear-regression.html"><a href="linear-regression.html#plotting-interactions"><i class="fa fa-check"></i><b>3.3.3</b> Plotting interactions</a></li>
<li class="chapter" data-level="3.3.4" data-path="linear-regression.html"><a href="linear-regression.html#categorical-factors-with-more-than-two-levels"><i class="fa fa-check"></i><b>3.3.4</b> Categorical factors with more than two levels</a></li>
<li class="chapter" data-level="3.3.5" data-path="linear-regression.html"><a href="linear-regression.html#releveling-factors"><i class="fa fa-check"></i><b>3.3.5</b> Releveling factors</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="linear-regression.html"><a href="linear-regression.html#linear-regression-assumptions"><i class="fa fa-check"></i><b>3.4</b> Linear regression assumptions</a><ul>
<li class="chapter" data-level="3.4.1" data-path="linear-regression.html"><a href="linear-regression.html#visual-methods-1"><i class="fa fa-check"></i><b>3.4.1</b> Visual methods</a></li>
<li class="chapter" data-level="3.4.2" data-path="linear-regression.html"><a href="linear-regression.html#assumption-1-linearity"><i class="fa fa-check"></i><b>3.4.2</b> Assumption 1: Linearity</a></li>
<li class="chapter" data-level="3.4.3" data-path="linear-regression.html"><a href="linear-regression.html#c2ioe"><i class="fa fa-check"></i><b>3.4.3</b> Assumption 2: Independence of errors</a></li>
<li class="chapter" data-level="3.4.4" data-path="linear-regression.html"><a href="linear-regression.html#assumption-3-normality-of-errors"><i class="fa fa-check"></i><b>3.4.4</b> Assumption 3: Normality of errors</a></li>
<li class="chapter" data-level="3.4.5" data-path="linear-regression.html"><a href="linear-regression.html#assumtion-4-constancy-of-variance"><i class="fa fa-check"></i><b>3.4.5</b> Assumtion 4: Constancy of variance</a></li>
<li class="chapter" data-level="3.4.6" data-path="linear-regression.html"><a href="linear-regression.html#interim-summary"><i class="fa fa-check"></i><b>3.4.6</b> Interim summary</a></li>
<li class="chapter" data-level="3.4.7" data-path="linear-regression.html"><a href="linear-regression.html#transforming-to-normality"><i class="fa fa-check"></i><b>3.4.7</b> Transforming to normality</a></li>
<li class="chapter" data-level="3.4.8" data-path="linear-regression.html"><a href="linear-regression.html#assumption-5-linear-independence-of-predictors"><i class="fa fa-check"></i><b>3.4.8</b> Assumption 5: Linear independence of predictors</a></li>
<li class="chapter" data-level="3.4.9" data-path="linear-regression.html"><a href="linear-regression.html#collinearity"><i class="fa fa-check"></i><b>3.4.9</b> Collinearity</a></li>
<li class="chapter" data-level="3.4.10" data-path="linear-regression.html"><a href="linear-regression.html#assumption-6-observations"><i class="fa fa-check"></i><b>3.4.10</b> Assumption 6: Observations</a></li>
<li class="chapter" data-level="3.4.11" data-path="linear-regression.html"><a href="linear-regression.html#lin-reg-measuring-influence"><i class="fa fa-check"></i><b>3.4.11</b> Measuring influence</a></li>
<li class="chapter" data-level="3.4.12" data-path="linear-regression.html"><a href="linear-regression.html#outliers"><i class="fa fa-check"></i><b>3.4.12</b> Outliers</a></li>
<li class="chapter" data-level="3.4.13" data-path="linear-regression.html"><a href="linear-regression.html#regression-assumptions-reassurance"><i class="fa fa-check"></i><b>3.4.13</b> Regression assumptions: Reassurance</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="linear-regression.html"><a href="linear-regression.html#lm-model-comparison"><i class="fa fa-check"></i><b>3.5</b> Model comparison</a><ul>
<li class="chapter" data-level="3.5.1" data-path="linear-regression.html"><a href="linear-regression.html#nested-model-comparison"><i class="fa fa-check"></i><b>3.5.1</b> Nested model comparison</a></li>
<li class="chapter" data-level="3.5.2" data-path="linear-regression.html"><a href="linear-regression.html#non-nested-model-comparison"><i class="fa fa-check"></i><b>3.5.2</b> Non-nested model comparison</a></li>
<li class="chapter" data-level="3.5.3" data-path="linear-regression.html"><a href="linear-regression.html#c2varselect"><i class="fa fa-check"></i><b>3.5.3</b> Variable selection</a></li>
<li class="chapter" data-level="3.5.4" data-path="linear-regression.html"><a href="linear-regression.html#interpretability-issues"><i class="fa fa-check"></i><b>3.5.4</b> Interpretability issues</a></li>
<li class="chapter" data-level="3.5.5" data-path="linear-regression.html"><a href="linear-regression.html#interim-recipe-building-a-multiple-linear-regression-model"><i class="fa fa-check"></i><b>3.5.5</b> Interim recipe: Building a multiple linear regression model</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="linear-regression.html"><a href="linear-regression.html#c2solns"><i class="fa fa-check"></i><b>3.6</b> Solutions</a><ul>
<li class="chapter" data-level="3.6.1" data-path="linear-regression.html"><a href="linear-regression.html#multiple-linear-regression-solutions"><i class="fa fa-check"></i><b>3.6.1</b> Multiple linear regression: Solutions</a></li>
<li class="chapter" data-level="3.6.2" data-path="linear-regression.html"><a href="linear-regression.html#linear-regression-assumptions-solutions"><i class="fa fa-check"></i><b>3.6.2</b> Linear regression assumptions: Solutions</a></li>
<li class="chapter" data-level="3.6.3" data-path="linear-regression.html"><a href="linear-regression.html#model-comparison-solutions"><i class="fa fa-check"></i><b>3.6.3</b> Model comparison: Solutions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="cda.html"><a href="cda.html"><i class="fa fa-check"></i><b>4</b> Categorical data analysis: Preliminaries</a><ul>
<li class="chapter" data-level="4.1" data-path="cda.html"><a href="cda.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a><ul>
<li class="chapter" data-level="4.1.1" data-path="cda.html"><a href="cda.html#x2-contingency-tables"><i class="fa fa-check"></i><b>4.1.1</b> 2x2 contingency tables</a></li>
<li class="chapter" data-level="4.1.2" data-path="cda.html"><a href="cda.html#the-chi-squared-test"><i class="fa fa-check"></i><b>4.1.2</b> The chi-squared test</a></li>
<li class="chapter" data-level="4.1.3" data-path="cda.html"><a href="cda.html#fishers-exact-test"><i class="fa fa-check"></i><b>4.1.3</b> Fisher’s exact test</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="cda.html"><a href="cda.html#towards-logistic-regression"><i class="fa fa-check"></i><b>4.2</b> Towards logistic regression</a><ul>
<li class="chapter" data-level="4.2.1" data-path="cda.html"><a href="cda.html#odds"><i class="fa fa-check"></i><b>4.2.1</b> Odds</a></li>
<li class="chapter" data-level="4.2.2" data-path="cda.html"><a href="cda.html#log-odds"><i class="fa fa-check"></i><b>4.2.2</b> Log-odds</a></li>
<li class="chapter" data-level="4.2.3" data-path="cda.html"><a href="cda.html#odds-ratios"><i class="fa fa-check"></i><b>4.2.3</b> Odds ratios</a></li>
<li class="chapter" data-level="4.2.4" data-path="cda.html"><a href="cda.html#log-odds-sample-and-population"><i class="fa fa-check"></i><b>4.2.4</b> Log odds: sample and population</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="cda.html"><a href="cda.html#cda-other-readings"><i class="fa fa-check"></i><b>4.3</b> Other readings</a></li>
<li class="chapter" data-level="4.4" data-path="cda.html"><a href="cda.html#c3solns"><i class="fa fa-check"></i><b>4.4</b> Solutions</a><ul>
<li class="chapter" data-level="4.4.1" data-path="cda.html"><a href="cda.html#solutions-to-exercise-1"><i class="fa fa-check"></i><b>4.4.1</b> Solutions to Exercise 1:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>5</b> Logistic regression</a><ul>
<li class="chapter" data-level="5.1" data-path="logistic-regression.html"><a href="logistic-regression.html#simple-logistic-regression"><i class="fa fa-check"></i><b>5.1</b> Simple logistic regression</a><ul>
<li class="chapter" data-level="5.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#log-reg-hyp-test"><i class="fa fa-check"></i><b>5.1.1</b> Hypothesis testing</a></li>
<li class="chapter" data-level="5.1.2" data-path="logistic-regression.html"><a href="logistic-regression.html#interpreting-the-coefficients-logit-odds-and-probability"><i class="fa fa-check"></i><b>5.1.2</b> Interpreting the coefficients: Logit, odds, and probability</a></li>
<li class="chapter" data-level="5.1.3" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression-as-a-glm"><i class="fa fa-check"></i><b>5.1.3</b> Logistic regression as a GLM</a></li>
<li class="chapter" data-level="5.1.4" data-path="logistic-regression.html"><a href="logistic-regression.html#c4differences"><i class="fa fa-check"></i><b>5.1.4</b> Differences from linear regression: Fitting and interpretation</a></li>
<li class="chapter" data-level="5.1.5" data-path="logistic-regression.html"><a href="logistic-regression.html#fitting-a-logistic-regression-model"><i class="fa fa-check"></i><b>5.1.5</b> Fitting a logistic regression model</a></li>
<li class="chapter" data-level="5.1.6" data-path="logistic-regression.html"><a href="logistic-regression.html#interpretation"><i class="fa fa-check"></i><b>5.1.6</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="logistic-regression.html"><a href="logistic-regression.html#evaluating-logistic-regression-models"><i class="fa fa-check"></i><b>5.2</b> Evaluating logistic regression models</a><ul>
<li class="chapter" data-level="5.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#c4lrt"><i class="fa fa-check"></i><b>5.2.1</b> Likelihood ratio test</a></li>
<li class="chapter" data-level="5.2.2" data-path="logistic-regression.html"><a href="logistic-regression.html#classification-accuracy"><i class="fa fa-check"></i><b>5.2.2</b> Classification accuracy</a></li>
<li class="chapter" data-level="5.2.3" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression-pseudo-r2"><i class="fa fa-check"></i><b>5.2.3</b> Pseudo-<span class="math inline">\(R^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="logistic-regression.html"><a href="logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>5.3</b> Multiple logistic regression</a><ul>
<li class="chapter" data-level="5.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#likelihood-ratio-test-general-case"><i class="fa fa-check"></i><b>5.3.1</b> Likelihood ratio test: General case</a></li>
<li class="chapter" data-level="5.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#log-reg-worked-example"><i class="fa fa-check"></i><b>5.3.2</b> Worked example</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="logistic-regression.html"><a href="logistic-regression.html#model-criticism-logistic-regression"><i class="fa fa-check"></i><b>5.4</b> Model criticism for logistic regression</a><ul>
<li class="chapter" data-level="5.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#residual-plots"><i class="fa fa-check"></i><b>5.4.1</b> Residual plots</a></li>
<li class="chapter" data-level="5.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression-cooks-distance"><i class="fa fa-check"></i><b>5.4.2</b> Cook’s distance</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="logistic-regression.html"><a href="logistic-regression.html#other-readings"><i class="fa fa-check"></i><b>5.5</b> Other readings</a></li>
<li class="chapter" data-level="5.6" data-path="logistic-regression.html"><a href="logistic-regression.html#c4solns"><i class="fa fa-check"></i><b>5.6</b> Solutions</a></li>
<li class="chapter" data-level="5.7" data-path="logistic-regression.html"><a href="logistic-regression.html#c4appendix2"><i class="fa fa-check"></i><b>5.7</b> Appendix: Other Generalized Linear Models</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><i class="fa fa-check"></i><b>6</b> Practical Regression Topics 1: Multi-level factors, contrast coding, interactions</a><ul>
<li class="chapter" data-level="6.1" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#multi-level-factors-introduction"><i class="fa fa-check"></i><b>6.1</b> Multi-level factors: Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#contrast-coding"><i class="fa fa-check"></i><b>6.2</b> Contrast coding</a><ul>
<li class="chapter" data-level="6.2.1" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#first-examples"><i class="fa fa-check"></i><b>6.2.1</b> First examples</a></li>
<li class="chapter" data-level="6.2.2" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#basic-interpretation-of-contrasts"><i class="fa fa-check"></i><b>6.2.2</b> Basic interpretation of contrasts</a></li>
<li class="chapter" data-level="6.2.3" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#contrast-coding-schemes"><i class="fa fa-check"></i><b>6.2.3</b> Contrast coding schemes</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#c5mlf"><i class="fa fa-check"></i><b>6.3</b> Assessing a multi-level factor’s contribution</a></li>
<li class="chapter" data-level="6.4" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#practice-with-interactions"><i class="fa fa-check"></i><b>6.4</b> Practice with interactions</a></li>
<li class="chapter" data-level="6.5" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#c5solns"><i class="fa fa-check"></i><b>6.5</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lmem.html"><a href="lmem.html"><i class="fa fa-check"></i><b>7</b> Linear mixed models</a><ul>
<li class="chapter" data-level="7.1" data-path="lmem.html"><a href="lmem.html#mixed-effects-models-motivation"><i class="fa fa-check"></i><b>7.1</b> Mixed-effects models: Motivation</a><ul>
<li class="chapter" data-level="7.1.1" data-path="lmem.html"><a href="lmem.html#simpsons-paradox"><i class="fa fa-check"></i><b>7.1.1</b> Simpson’s paradox</a></li>
<li class="chapter" data-level="7.1.2" data-path="lmem.html"><a href="lmem.html#repeated-measure-anovas"><i class="fa fa-check"></i><b>7.1.2</b> Repeated-measure ANOVAs</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="lmem.html"><a href="lmem.html#linear-mixed-models-1-one-grouping-factor-random-intercepts"><i class="fa fa-check"></i><b>7.2</b> Linear mixed models 1: One grouping factor, random intercepts</a><ul>
<li class="chapter" data-level="7.2.1" data-path="lmem.html"><a href="lmem.html#c6model1A"><i class="fa fa-check"></i><b>7.2.1</b> Model 1A: Simple linear regression</a></li>
<li class="chapter" data-level="7.2.2" data-path="lmem.html"><a href="lmem.html#c6model1b"><i class="fa fa-check"></i><b>7.2.2</b> Model 1B: Random intercept only</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="lmem.html"><a href="lmem.html#c6lmm2"><i class="fa fa-check"></i><b>7.3</b> Linear mixed models 2: One grouping factor, random intercepts and slopes</a><ul>
<li class="chapter" data-level="7.3.1" data-path="lmem.html"><a href="lmem.html#c6model1c"><i class="fa fa-check"></i><b>7.3.1</b> Model 1C</a></li>
<li class="chapter" data-level="7.3.2" data-path="lmem.html"><a href="lmem.html#fitting-model-1c"><i class="fa fa-check"></i><b>7.3.2</b> Fitting Model 1C</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="lmem.html"><a href="lmem.html#linear-mixed-models-3-two-grouping-factors"><i class="fa fa-check"></i><b>7.4</b> Linear mixed models 3: Two grouping factors</a><ul>
<li class="chapter" data-level="7.4.1" data-path="lmem.html"><a href="lmem.html#c6model2A"><i class="fa fa-check"></i><b>7.4.1</b> Model 2A: By-participant and by-item random intercepts</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="lmem.html"><a href="lmem.html#evaluating-lmms"><i class="fa fa-check"></i><b>7.5</b> Evaluating LMMs</a><ul>
<li class="chapter" data-level="7.5.1" data-path="lmem.html"><a href="lmem.html#hypothesis-testing-2"><i class="fa fa-check"></i><b>7.5.1</b> Hypothesis testing</a></li>
<li class="chapter" data-level="7.5.2" data-path="lmem.html"><a href="lmem.html#significance-of-a-random-effect-term"><i class="fa fa-check"></i><b>7.5.2</b> Significance of a random effect term</a></li>
<li class="chapter" data-level="7.5.3" data-path="lmem.html"><a href="lmem.html#c6fixedp"><i class="fa fa-check"></i><b>7.5.3</b> Significance of fixed effects</a></li>
<li class="chapter" data-level="7.5.4" data-path="lmem.html"><a href="lmem.html#evaluating-goodness-of-fit"><i class="fa fa-check"></i><b>7.5.4</b> Evaluating goodness of fit</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="lmem.html"><a href="lmem.html#linear-mixed-models-4-multiple-predictors"><i class="fa fa-check"></i><b>7.6</b> Linear mixed models 4: Multiple predictors</a><ul>
<li class="chapter" data-level="7.6.1" data-path="lmem.html"><a href="lmem.html#types-of-predictors"><i class="fa fa-check"></i><b>7.6.1</b> Types of predictors</a></li>
<li class="chapter" data-level="7.6.2" data-path="lmem.html"><a href="lmem.html#c6model3A"><i class="fa fa-check"></i><b>7.6.2</b> Model 3A: Random intercepts only</a></li>
<li class="chapter" data-level="7.6.3" data-path="lmem.html"><a href="lmem.html#c6model3B"><i class="fa fa-check"></i><b>7.6.3</b> Model 3B: Random intercepts and all possible random slopes</a></li>
<li class="chapter" data-level="7.6.4" data-path="lmem.html"><a href="lmem.html#assessing-variability"><i class="fa fa-check"></i><b>7.6.4</b> Assessing variability</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="lmem.html"><a href="lmem.html#more-on-random-slopes"><i class="fa fa-check"></i><b>7.7</b> More on random slopes</a><ul>
<li class="chapter" data-level="7.7.1" data-path="lmem.html"><a href="lmem.html#what-does-adding-a-random-slope-term-do"><i class="fa fa-check"></i><b>7.7.1</b> What does adding a random slope term do?</a></li>
<li class="chapter" data-level="7.7.2" data-path="lmem.html"><a href="lmem.html#adding-a-random-slope"><i class="fa fa-check"></i><b>7.7.2</b> Discussion: Adding a random slope</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="lmem.html"><a href="lmem.html#random-effect-correlations"><i class="fa fa-check"></i><b>7.8</b> Random effect correlations</a><ul>
<li class="chapter" data-level="7.8.1" data-path="lmem.html"><a href="lmem.html#model-1e-correlated-random-slope-intercept"><i class="fa fa-check"></i><b>7.8.1</b> Model 1E: <strong>Correlated</strong> random slope &amp; intercept</a></li>
<li class="chapter" data-level="7.8.2" data-path="lmem.html"><a href="lmem.html#c6discuss"><i class="fa fa-check"></i><b>7.8.2</b> Dicussion: Adding a correlation</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="lmem.html"><a href="lmem.html#model-criticism-for-linear-mixed-models"><i class="fa fa-check"></i><b>7.9</b> Model criticism for linear mixed models</a><ul>
<li class="chapter" data-level="7.9.1" data-path="lmem.html"><a href="lmem.html#model-3b-residual-plots"><i class="fa fa-check"></i><b>7.9.1</b> Model 3B: Residual plots</a></li>
<li class="chapter" data-level="7.9.2" data-path="lmem.html"><a href="lmem.html#model-3b-random-effect-distribution"><i class="fa fa-check"></i><b>7.9.2</b> Model 3B: Random effect distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="lmem.html"><a href="lmem.html#c6factorsissue"><i class="fa fa-check"></i><b>7.10</b> Random slopes for factors</a><ul>
<li class="chapter" data-level="7.10.1" data-path="lmem.html"><a href="lmem.html#model-with-random-effect-correlations"><i class="fa fa-check"></i><b>7.10.1</b> Model with random-effect correlations</a></li>
<li class="chapter" data-level="7.10.2" data-path="lmem.html"><a href="lmem.html#lmem-mwrec"><i class="fa fa-check"></i><b>7.10.2</b> Models without random-effect correlations</a></li>
</ul></li>
<li class="chapter" data-level="7.11" data-path="lmem.html"><a href="lmem.html#other-readings-1"><i class="fa fa-check"></i><b>7.11</b> Other readings</a></li>
<li class="chapter" data-level="7.12" data-path="lmem.html"><a href="lmem.html#c6extraexamples"><i class="fa fa-check"></i><b>7.12</b> Appendix: Extra examples</a><ul>
<li class="chapter" data-level="7.12.1" data-path="lmem.html"><a href="lmem.html#lmm-simulation-confint"><i class="fa fa-check"></i><b>7.12.1</b> Predicting confidence intervals by simulation</a></li>
<li class="chapter" data-level="7.12.2" data-path="lmem.html"><a href="lmem.html#random-intercept-and-slope-model-for-givenness-data"><i class="fa fa-check"></i><b>7.12.2</b> Random intercept and slope model for <code>givenness</code> data</a></li>
</ul></li>
<li class="chapter" data-level="7.13" data-path="lmem.html"><a href="lmem.html#c6extendedexercise"><i class="fa fa-check"></i><b>7.13</b> Appendix: Extended exercise</a></li>
<li class="chapter" data-level="7.14" data-path="lmem.html"><a href="lmem.html#c6solns"><i class="fa fa-check"></i><b>7.14</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html"><i class="fa fa-check"></i><b>8</b> Mixed-effects logistic regression</a><ul>
<li class="chapter" data-level="8.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#preliminaries"><i class="fa fa-check"></i><b>8.1</b> Preliminaries</a><ul>
<li class="chapter" data-level="8.1.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#motivation"><i class="fa fa-check"></i><b>8.1.1</b> Motivation</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#basics"><i class="fa fa-check"></i><b>8.2</b> Basics</a><ul>
<li class="chapter" data-level="8.2.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7m1"><i class="fa fa-check"></i><b>8.2.1</b> Model 1: <code>givenness</code> data, crossed random effects (intercepts + slopes)</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#hypothesis-testing-3"><i class="fa fa-check"></i><b>8.3</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="8.3.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fixed-effects"><i class="fa fa-check"></i><b>8.3.1</b> Fixed effects</a></li>
<li class="chapter" data-level="8.3.2" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#random-effects"><i class="fa fa-check"></i><b>8.3.2</b> Random effects</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fixed-and-random-effects"><i class="fa fa-check"></i><b>8.4</b> Fixed and random effects</a></li>
<li class="chapter" data-level="8.5" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#melr-practice"><i class="fa fa-check"></i><b>8.5</b> MELR Practice</a><ul>
<li class="chapter" data-level="8.5.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7ex1"><i class="fa fa-check"></i><b>8.5.1</b> Exercise 1: tapping</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-criticism-for-mixed-effects-logistic-regression"><i class="fa fa-check"></i><b>8.6</b> Model criticism for mixed-effects logistic regression</a><ul>
<li class="chapter" data-level="8.6.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#random-effect-distributions"><i class="fa fa-check"></i><b>8.6.1</b> Random-effect distributions</a></li>
<li class="chapter" data-level="8.6.2" data-path="logistic-regression.html"><a href="logistic-regression.html#residual-plots"><i class="fa fa-check"></i><b>8.6.2</b> Residual plots</a></li>
<li class="chapter" data-level="8.6.3" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#influence"><i class="fa fa-check"></i><b>8.6.3</b> Influence</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#evaluation-measures"><i class="fa fa-check"></i><b>8.7</b> Evaluation measures</a><ul>
<li class="chapter" data-level="8.7.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#evaluation-measure-1-likelihood-ratio-test"><i class="fa fa-check"></i><b>8.7.1</b> Evaluation measure 1: Likelihood ratio test</a></li>
<li class="chapter" data-level="8.7.2" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#evaluation-measure-2-classification-accuracy"><i class="fa fa-check"></i><b>8.7.2</b> Evaluation measure 2: Classification accuracy</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#miscellaneous-mixed-effects-regression-topics"><i class="fa fa-check"></i><b>8.8</b> Miscellaneous mixed-effects regression topics</a><ul>
<li class="chapter" data-level="8.8.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7m2"><i class="fa fa-check"></i><b>8.8.1</b> Random-effect correlation issues</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#other-readings-2"><i class="fa fa-check"></i><b>8.9</b> Other readings</a></li>
<li class="chapter" data-level="8.10" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#appendices"><i class="fa fa-check"></i><b>8.10</b> Appendices</a><ul>
<li class="chapter" data-level="8.10.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#melr-random-slopes-for-factors"><i class="fa fa-check"></i><b>8.10.1</b> Appendix: Random slopes for factors</a></li>
<li class="chapter" data-level="8.10.2" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7appendix2"><i class="fa fa-check"></i><b>8.10.2</b> Appendix: Multi-level factors and uncorrelated random effects</a></li>
<li class="chapter" data-level="8.10.3" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#appendix-what-can-happen-if-a-random-slope-isnt-included"><i class="fa fa-check"></i><b>8.10.3</b> Appendix: What can happen if a random slope isn’t included?</a></li>
</ul></li>
<li class="chapter" data-level="8.11" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7solns"><i class="fa fa-check"></i><b>8.11</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><i class="fa fa-check"></i><b>9</b> Practical regression topics 2: Ordered factors, nonlinear effects, model predictions, post-hoc tests</a><ul>
<li class="chapter" data-level="9.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#introduction-1"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#ordered-factors"><i class="fa fa-check"></i><b>9.2</b> Ordered factors</a><ul>
<li class="chapter" data-level="9.2.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#orthogonal-polynomial-contrasts"><i class="fa fa-check"></i><b>9.2.1</b> Orthogonal polynomial contrasts</a></li>
<li class="chapter" data-level="9.2.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#using-an-ordered-factor-as-a-predictor"><i class="fa fa-check"></i><b>9.2.2</b> Using an ordered factor as a predictor</a></li>
<li class="chapter" data-level="9.2.3" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#further-points"><i class="fa fa-check"></i><b>9.2.3</b> Further points</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#nonlinear-effects"><i class="fa fa-check"></i><b>9.3</b> Nonlinear effects</a><ul>
<li class="chapter" data-level="9.3.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#splines-definition-and-benefits"><i class="fa fa-check"></i><b>9.3.1</b> Splines: Definition and benefits</a></li>
<li class="chapter" data-level="9.3.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#restricted-cubic-splines"><i class="fa fa-check"></i><b>9.3.2</b> Restricted cubic splines</a></li>
<li class="chapter" data-level="9.3.3" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#choosing-spline-complexity"><i class="fa fa-check"></i><b>9.3.3</b> Choosing spline complexity</a></li>
<li class="chapter" data-level="9.3.4" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#rcs-components"><i class="fa fa-check"></i><b>9.3.4</b> RCS components</a></li>
<li class="chapter" data-level="9.3.5" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#using-rcs-in-a-mixed-model"><i class="fa fa-check"></i><b>9.3.5</b> Using RCS in a mixed model</a></li>
<li class="chapter" data-level="9.3.6" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#random-slopes-for-rcs-terms"><i class="fa fa-check"></i><b>9.3.6</b> Random slopes for RCS terms</a></li>
<li class="chapter" data-level="9.3.7" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#nonlinear-effects-summary"><i class="fa fa-check"></i><b>9.3.7</b> Nonlinear effects: Summary</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#predictions-from-mixed-models"><i class="fa fa-check"></i><b>9.4</b> Predictions from mixed models</a><ul>
<li class="chapter" data-level="9.4.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#making-model-predictions"><i class="fa fa-check"></i><b>9.4.1</b> Making Model Predictions</a></li>
<li class="chapter" data-level="9.4.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#simulation-based-predictions"><i class="fa fa-check"></i><b>9.4.2</b> Simulation-based predictions</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#post-hoc-mult-comp"><i class="fa fa-check"></i><b>9.5</b> Post-hoc tests and multiple comparisons</a></li>
<li class="chapter" data-level="9.6" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8indivpreds"><i class="fa fa-check"></i><b>9.6</b> Appendix: Model predictions for indiviudal participants</a><ul>
<li class="chapter" data-level="9.6.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#predictions-incorporating-offsets-for-individual-speakers"><i class="fa fa-check"></i><b>9.6.1</b> Predictions incorporating offsets for individual speakers</a></li>
<li class="chapter" data-level="9.6.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#predicted-williams-effect-for-each-speaker"><i class="fa fa-check"></i><b>9.6.2</b> Predicted Williams effect for each speaker</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8slopesForFactors"><i class="fa fa-check"></i><b>9.7</b> Appendix: Random slopes for factors</a></li>
<li class="chapter" data-level="9.8" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8solns"><i class="fa fa-check"></i><b>9.8</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="datasets-appendix.html"><a href="datasets-appendix.html"><i class="fa fa-check"></i><b>10</b> Appendix: Datasets and packages</a><ul>
<li class="chapter" data-level="10.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#engdata"><i class="fa fa-check"></i><b>10.1</b> <code>english</code> lexical decision and naming latencies</a></li>
<li class="chapter" data-level="10.2" data-path="datasets-appendix.html"><a href="datasets-appendix.html#dutch-regularity"><i class="fa fa-check"></i><b>10.2</b> Dutch <code id="dregdata">regularity</code></a></li>
<li class="chapter" data-level="10.3" data-path="datasets-appendix.html"><a href="datasets-appendix.html#european-french-phrase-medial-vowel-devoicing"><i class="fa fa-check"></i><b>10.3</b> European French phrase-medial vowel <code id="devdata">devoicing</code></a><ul>
<li class="chapter" data-level="10.3.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background"><i class="fa fa-check"></i><b>10.3.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="datasets-appendix.html"><a href="datasets-appendix.html#north-american-english-tapping"><i class="fa fa-check"></i><b>10.4</b> North American English <code id="tapdata">tapping</code></a><ul>
<li class="chapter" data-level="10.4.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-1"><i class="fa fa-check"></i><b>10.4.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="datasets-appendix.html"><a href="datasets-appendix.html#halfdata"><i class="fa fa-check"></i><b>10.5</b> <code>halfrhyme</code>: English half-rhymes</a></li>
<li class="chapter" data-level="10.6" data-path="datasets-appendix.html"><a href="datasets-appendix.html#givedata"><i class="fa fa-check"></i><b>10.6</b> <code>givenness</code> data: the Williams Effect</a><ul>
<li class="chapter" data-level="10.6.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-2"><i class="fa fa-check"></i><b>10.6.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="datasets-appendix.html"><a href="datasets-appendix.html#alternatives"><i class="fa fa-check"></i><b>10.7</b> <code id="altdata">alternatives</code></a><ul>
<li class="chapter" data-level="10.7.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-3"><i class="fa fa-check"></i><b>10.7.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="datasets-appendix.html"><a href="datasets-appendix.html#votdata"><i class="fa fa-check"></i><b>10.8</b> VOT</a><ul>
<li class="chapter" data-level="10.8.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-4"><i class="fa fa-check"></i><b>10.8.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="datasets-appendix.html"><a href="datasets-appendix.html#transitionsdata"><i class="fa fa-check"></i><b>10.9</b> Transitions</a></li>
<li class="chapter" data-level="10.10" data-path="datasets-appendix.html"><a href="datasets-appendix.html#packages"><i class="fa fa-check"></i><b>10.10</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Quantitative Methods for Linguistic Data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inferential-statistics-introduction" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Inferential statistics: Introduction</h1>
<p><strong>Preliminary code</strong></p>
<p>This code is needed to make other code below work:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)

## loads transitions.txt from OSF project for Roberts, Torreira, &amp; Levinson (2015) data
transitions &lt;-<span class="st"> </span><span class="kw">read.delim</span>(<span class="kw">url</span>(<span class="st">&quot;https://osf.io/4v8r7/download&quot;</span>))</code></pre></div>
<script src="js/hideOutput.js"></script>
<!-- TODO FUTURE: make solutions -->
<!-- **Note**: Most answers to questions/exercises not listed in text are in [Solutions](#infIntro-solns). -->
<p>This chapter introduces core concepts from inferential statistics:</p>
<ul>
<li><p>Population versus sample</p></li>
<li><p>The sample mean and its sampling distribution</p></li>
<li><p>Confidence intervals</p></li>
<li><p>The <span class="math inline">\(t\)</span> distribution</p></li>
</ul>
<!-- TODO future: write actual intro or at least make that list accurate -->
<p>We assume you are familiar with:</p>
<ul>
<li><p>The <code>tapping</code> dataset, described <a href="datasets-appendix.html#tapdata">here</a></p></li>
<li><p>Basic probability</p></li>
<li><p>Some data summarization and visualization techniques, ideally using <code>ggplot</code> and <code>tidyverse</code> packages such as <code>dplyr</code>.</p></li>
</ul>
<p>These were described in earlier lectures that have yet to be turned into book chapters.</p>
<!-- TODO future: update -->
<div id="sample-population" class="section level2">
<h2><span class="header-section-number">1.1</span> Population vs. sample</h2>
<p>In an experiment, we are typically interested in <strong>population</strong> values of a parameter. For example, for the <code>tapping</code> dataset, we want to determine:</p>
<ul>
<li><p><span class="math inline">\(p_i\)</span>, <span class="math inline">\(p_t\)</span>: the tapping rates when <code>syntax</code> = <em>intransitive</em> or <em>transitive</em></p></li>
<li><p><span class="math inline">\(p_i - p_t\)</span>: the difference between the rate of tapping in the two conditions.</p></li>
</ul>
<p>However, we can only take a <em>sample</em> of size <span class="math inline">\(n\)</span> and make an inference about the population. To estimate the two quantities above, we could use:</p>
<ul>
<li><p>The proportion of the <span class="math inline">\(n\)</span> observations which were tapped, when <code>syntax</code> = <em>intransitive</em> or <em>transitive</em>.</p></li>
<li><p>The difference between these two observed proportions</p></li>
</ul>
<p>This is much of what we do in statistical analysis: estimate quantities of interest, whose true values we will never actually know, based on a finite sample.</p>
<div id="sample-to-population-high-level" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Sample <span class="math inline">\(\to\)</span> population: High level</h3>
<p>In inferential statistics, the general procedure is to use the sample to calculate <em>sample statistics</em>. These sample statistics are used to estimate the <em>population values</em> of the parameters we actually care about. Ideally the sample statistics should be <em>unbiased estimators</em> of the population values, defined as:</p>
<ul>
<li><p>The more data we have, the closer the sample statistic gets to the population value</p></li>
<li><p>In the limit of an infinite sample, the sample statistic <strong>is</strong> the population value.</p></li>
</ul>
<p>For example:</p>
<ul>
<li><p><span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are often used to denote the population mean and standard deviation: the values we care about, but will never actually observe.</p></li>
<li><p><span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(s\)</span> are often used to denote the sample statistics estimating <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.</p></li>
<li><p>If you have <span class="math inline">\(n=1000000000\)</span>, we expect <span class="math inline">\(\bar{x}\)</span> to be very, very close to <span class="math inline">\(\mu\)</span>.</p></li>
</ul>
</div>
<div id="sdsm" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Sampling distribution of the sample mean</h3>
<p>The most basic sample statistic is the <em>sample mean</em>, which is the average of <span class="math inline">\(n\)</span> observations:</p>
<span class="math display">\[\begin{equation*}
  \bar{x} = \frac{\sum^n_{i=0} x_i}{n}
\end{equation*}\]</span>
<p>To understand how the sample mean is related to the population mean, let’s explore using simulations where we know the population value.</p>
<p>We can do this by:</p>
<ol style="list-style-type: decimal">
<li><p>Draw a sample of <span class="math inline">\(n\)</span> observations from a normal distribution with mean 0 and standard deviation <span class="math inline">\(\sigma\)</span> (using the <code>rnorm</code> command)</p></li>
<li><p>Calculate the sample mean using this sample, <span class="math inline">\(\bar{x}\)</span></p></li>
<li><p>Repeat (1)-(2) many times, and plot a histogram showing the distribution of sample mean values</p></li>
</ol>
<p>(The code for this in <a href="https://github.com/mlml/stats_book">the .Rmd file</a>, but is hidden on this page.)</p>
<p>These plots show the histograms when the sample mean is calculated over 15 observations (left top: <span class="math inline">\(n=15\)</span>) and over 50 observations (right top), varying the standard deviation <span class="math inline">\(\sigma\)</span> between 1 and 0.5. The superimposed curve shows the normal distribution with <span class="math inline">\(\mu=0\)</span> and <span class="math inline">\(\sigma =\)</span> 1 or 0.5.</p>
<!--- Code adapted from Johnson 2008 to recreate the figures --->
<div class="fold o">

</div>
<p><img src="01-inferential-statistics-basics_files/figure-html/unnamed-chunk-3-1.png" width="624" style="display: block; margin: auto;" /></p>
<hr />
<p><img src="01-inferential-statistics-basics_files/figure-html/unnamed-chunk-4-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>(These figures replicate Fig. 2.4 from <span class="citation">Johnson (<a href="#ref-johnson2008quantitative">2008</a>)</span>, using similar code to Johnson’s.)</p>
<p>We see that the distribution of the sample mean gets narrower for larger <span class="math inline">\(n\)</span>, and for smaller <span class="math inline">\(\sigma\)</span>: the more observations in the sample, or the less variable the quantity is that we are measuring, the less variation there is in the mean value that we calculate based on the sample.</p>
<blockquote>
<p><strong>Question</strong></p>
<ul>
<li>Why is this, intuitively?</li>
</ul>
</blockquote>
<p>These simulations illustrate an important fact: <strong>the sample mean is normally distributed</strong> (for <span class="math inline">\(n\)</span> observations from a <span class="math inline">\(N(\mu,\sigma)\)</span> distribution), with mean <span class="math inline">\(\mu\)</span>. It turns out that the standard deviation of the sample mean is <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span>.</p>
<!--- I think there was small index typo here: For an unbiased estimate of std dev we divide by (sample size - 1), however, we're starting at i = 0 to n so we have n + 1 samples. --->
We can never observe <span class="math inline">\(\sigma\)</span> directly (this is why we’re estimating it). However, we can make an unbiased estimator:
<span class="math display">\[\begin{equation*}
  s = \sqrt{\frac{\sum^n_{i=1} (x_i - \mu)^2}{n - 1}}
\end{equation*}\]</span>
and use it to compute the <em>standard error</em> of the sample mean, defined as:
<span class="math display">\[\begin{equation*}
SE = \frac{s}{\sqrt{n}}
\end{equation*}\]</span>
<p>The standard error is an unbiased estimator of <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span>. (And so <span class="math inline">\(\sqrt(n) SE\)</span> is an unbiased estimator of <span class="math inline">\(\sigma\)</span>.) The standard error quantifies how much error there is, on average (across many samples) in our estimate of the population mean using <span class="math inline">\(\bar{x}\)</span>.</p>
<p>Something to note here is that <strong>error scales as the square root of the sample size</strong>: the SE has a <span class="math inline">\(\sqrt{n}\)</span> in the denominator. This relationship will come up over and over in this course, and is the reason why collecting more data has diminishing returns. (Four times as much data is needed to halve the error, and so on.)</p>
</div>
<div id="sampling-from-a-non-normal-distribution" class="section level3">
<h3><span class="header-section-number">1.1.3</span> Sampling from a non-normal distribution</h3>
<p>What happens if we take the sample mean for observations from a non-normal distribution? We can use the same simulation procedure, this time sampling from an `F distribution’—the one used for ANOVAs. (Again, see the <a href="https://github.com/mlml/stats_book">Rmd file</a> for code.)</p>
<!--- Adapted from Johnson 2008 --->
<p><img src="01-inferential-statistics-basics_files/figure-html/unnamed-chunk-6-1.png" width="624" style="display: block; margin: auto;" /></p>
<p>(These figures replicate Fig. 2.3 from <span class="citation">Johnson (<a href="#ref-johnson2008quantitative">2008</a>)</span>, using similar code to Johnson’s.)</p>
<p>As you can see, the distribution of the sample mean is normal, even though the actual random variable whose mean is being estimated is not normal. This illustrates the <strong>central limit theorem</strong>:<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<ul>
<li><p>For a large enough sample from a random variable with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, the (sampling) distribution of the sample mean</p>
<ul>
<li><p>is approximately normally distributed with mean <span class="math inline">\(\mu\)</span> and standard deviation of <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span></p></li>
<li><p>regardless of the population distribution</p></li>
</ul>
<!-- * regardless of the population size --></li>
</ul>
<p>One example of this is our estimate of <span class="math inline">\(p_t\)</span> from <span class="math inline">\(n\)</span> samples for the tapping data. Even though the actual variable being measured (how many times does a participant tap?) is binomially distributed, our <strong>estimate</strong> of <span class="math inline">\(p_t\)</span> is normally distributed.</p>
<p>The central limit theorem is a very important mathematical result which allows us to apply the same tools of inferential statistics to many different kinds of data. Like gravity, it is so fundamental that it’s easy to forget how much more complicated life would be without it.</p>
</div>
<div id="exercises" class="section level3 unnumbered">
<h3>Exercises</h3>
<p><strong>Exercise 1</strong>:</p>
<p>Consider an imaginary dataset of measurements where participants say “hi” every time they hear a beep, and we measure the latency between the beep and the beginning of “hi”.</p>
<p>There are 100 participants, each of whom is measured once.</p>
<p>The sample mean and standard deviation are:</p>
<ul>
<li><p><span class="math inline">\(m\)</span> = 200 ms</p></li>
<li><p><span class="math inline">\(s\)</span> = 75 ms</p></li>
</ul>
<center>
<img src="images/day5_ex_hi.png" width="300" />
</center>
<ul>
<li>What is the standard error of the sample mean?</li>
</ul>
<!-- a. What's the standard error of the sample mean? -->
<pre><code>+ Hint: SE = $\frac{s}{\sqrt{n}}$</code></pre>
<!-- answer: 7.5 -->
<ul>
<li><p>How many participants would we need in total to reduce the standard error by a factor of 2?</p>
<ol style="list-style-type: lower-alpha">
<li><p>200 participants</p></li>
<li><p>400 participants</p></li>
<li><p>1000 participants</p></li>
</ol></li>
</ul>
<p><strong>Exercise 2</strong></p>
<p>This exercise uses the <code>transitions</code> dataset, described <a href="datasets-appendix.html#transitionsdata">here</a>.</p>
<p>This dataset describes approximately 20,000 transitions between conversational turns in the Switchboard Corpus of telephone calls, and can be used to analyze what factors affect the duration of transitions.</p>
<p>Using the transitions dataset, and <code>summarise()</code> (from <code>dplyr</code>), create a dataframe with one column for each of:</p>
<ul>
<li><p>Mean transition duration (<code>dur</code>)</p></li>
<li><p>Standard deviation of transition duration</p></li>
<li><p>Number of observations</p></li>
<li><p>Standard error of the mean transition duration</p></li>
</ul>
(Don’t click unless you want to see the solution!)
<div class="fold s o">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## the transitions dataset was loaded at the beginning of this page

<span class="kw">library</span>(dplyr)
transitions %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">meanDur =</span> <span class="kw">mean</span>(dur), <span class="dt">n =</span> <span class="kw">n</span>(), <span class="dt">sd =</span> <span class="kw">sd</span>(dur), <span class="dt">se =</span> sd/<span class="kw">sqrt</span>(n))</code></pre></div>
<pre><code>##    meanDur     n       sd       se
## 1 185.7611 21090 473.3708 3.259591</code></pre>
</div>
</div>
</div>
<div id="confidence-intervals" class="section level2">
<h2><span class="header-section-number">1.2</span> Confidence intervals</h2>
<p>An important additional measure of uncertainty in the sample mean, related to the standard error, is the <em>confidence interval</em>. Recall that the sample mean is normally distributed with mean <span class="math inline">\(\mu\)</span> and standard deviation of <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span> (the standard error of the sample mean, or <em>SE</em>).</p>
<p>In addition, 95% of the area in a normal distribution lies within 1.96 standard deviations of its mean:</p>
<p><img src="01-inferential-statistics-basics_files/figure-html/unnamed-chunk-8-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>This motivates defining the 95% <em>confidence interval</em> of the sample mean:</p>
<ul>
<li>(sample mean - 1.96<span class="math inline">\(\times\)</span>SE, sample mean + 1.96<span class="math inline">\(\times\)</span>SE)</li>
</ul>
<p>(You’ll often see “mean <span class="math inline">\(\pm\)</span> 2 standard errors”, or “mean <span class="math inline">\(\pm\)</span> 2<span class="math inline">\(\sigma\)</span>” used as “errorbars”; this is just because <span class="math inline">\(1.96 \approx 2\)</span>.)</p>
<p>If we keep collecting samples, in the long run about 95% of these intervals would contain the true (population) mean within CI.</p>
<p><strong>Warning</strong>: This does not mean that there is a 95% probability that the population mean lies within a given CI!</p>
<p>This is a common misconception of what confidence intervals mean.</p>
<div id="example" class="section level4 unnumbered">
<h4>Example</h4>
<p>Using the <code>transitions</code> dataset, let’s look at the (sample) mean and 95% confidence intervals of transition duration as a function of speaker gender:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)

transitions %&gt;%<span class="st"> </span><span class="kw">group_by</span>(sexB) %&gt;%
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">meanDur =</span> <span class="kw">mean</span>(dur), <span class="dt">se=</span><span class="kw">sd</span>(dur)/<span class="kw">sqrt</span>(<span class="kw">n</span>())) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(sexB, meanDur)) +
<span class="st">    </span><span class="kw">geom_point</span>() +
<span class="st">    </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>meanDur<span class="fl">-1.96</span>*se, <span class="dt">ymax=</span>meanDur<span class="fl">+1.96</span>*se), <span class="dt">width=</span><span class="fl">0.1</span>) +
<span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Speaker gender&quot;</span>) +
<span class="st">    </span><span class="kw">ylab</span>(<span class="st">&quot;Mean transition duration (ms) +/- 95% CI&quot;</span>)</code></pre></div>
<p><img src="01-inferential-statistics-basics_files/figure-html/unnamed-chunk-9-1.png" width="384" style="display: block; margin: auto;" /></p>
<p><strong>Q</strong>: What does the errorbar here mean, exactly?</p>
</div>
</div>
<div id="t-distribution" class="section level2">
<h2><span class="header-section-number">1.3</span> <span class="math inline">\(t\)</span> distribution</h2>
<p>We are usually interested in estimating not just means, but also <span class="math inline">\(\sigma\)</span>’s. In particular, we’re usually interested in <span class="math inline">\(\mu/(\sigma/\sqrt{n})\)</span>: how far a mean is from zero, relative to the standard error of mean (a population value). For example, in the preceding plot, we are interested in how big the difference between male and female speakers is <em>relative to errorbar size</em>.</p>
We can’t actually observe <span class="math inline">\(\sigma\)</span>, and thus <span class="math inline">\(\mu/(\sigma/\sqrt{n})\)</span>. Instead we have to use <span class="math inline">\(s\)</span>, which is an unbiased estimator of <span class="math inline">\(\sigma\)</span>: <!-- --- meaning that its expected value is $\sigma$ for sufficiently large sample size ($n$): -->
<span class="math display">\[\begin{equation*}
  s = \sqrt{\frac{\sum^n_{i = 1} \left(x_i - \mu\right)^2}{n - 1}}
\end{equation*}\]</span>
<p>While <span class="math inline">\(\mu/(\sigma/\sqrt{n})\)</span> is normally distributed, as the sample size becomes smaller, <span class="math inline">\(s\)</span> becomes more uncertain (note the <span class="math inline">\(n-1\)</span> in denominator), and our estimate of <span class="math inline">\(\mu/(\sigma/\sqrt{n})\)</span> is not normally distributed.</p>
<p>To correct for this non-normal distribution, we use the <em><span class="math inline">\(t\)</span> distribution</em>: this is the distribution of <span class="math inline">\(m/(s/\sqrt{n})\)</span>, and is sensitive to sample size. For a sample of <span class="math inline">\(n\)</span> observations, the estimated standard error of the mean ``follows a <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n-1\)</span> degrees of freedom’’:</p>
<p><span class="math display">\[
SE \approx \frac{s}{\sqrt{n}} \sim t_{n-1}
\]</span></p>
<p>The <span class="math inline">\(t\)</span> distribution looks similar to a normal distribution, but has “fatter tails” for smaller sample sizes (<span class="math inline">\(n &lt; 30\)</span>):</p>
<p><img src="01-inferential-statistics-basics_files/figure-html/unnamed-chunk-10-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Once <span class="math inline">\(n\)</span> is larger than about 30, the <span class="math inline">\(t\)</span> distribution is very similar to a normal distribution, which is the ‘Z’ line.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<div id="t-based-confidence-intervals" class="section level3">
<h3><span class="header-section-number">1.3.1</span> <span class="math inline">\(t\)</span>-based confidence intervals</h3>
<p>In a normal distribution, 95% of the distribution is within 1.96 standard deviations from the mean.</p>
<p>This code shows how many standard errors from the mean the upper bound of the 95% <span class="math inline">\(t\)</span>-based CI is, as sample size increases:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>
n &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">500</span>)

<span class="co"># two-sided t-distribution use 1 - alpha/2</span>
<span class="dv">1</span> -<span class="st"> </span>alpha/<span class="dv">2</span></code></pre></div>
<pre><code>## [1] 0.975</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cbind</span>(n, <span class="kw">qt</span>(<span class="dv">1</span> -<span class="st"> </span>alpha/<span class="dv">2</span>, n))</code></pre></div>
<pre><code>##        n         
## [1,]   5 2.570582
## [2,]  15 2.131450
## [3,]  25 2.059539
## [4,]  50 2.008559
## [5,] 100 1.983972
## [6,] 500 1.964720</code></pre>
<p>Because a <span class="math inline">\(t\)</span> distribution is a little wider than a normal distribution, 95% confidence intervals based on the <span class="math inline">\(t\)</span> distribution are slightly larger than those based on a normal distribution. Note that was <span class="math inline">\(n\)</span> gets large we approach 1.96, as seen with the normal distribution. This illustrates that for large enough samples (about <span class="math inline">\(n&gt;30\)</span>), the <span class="math inline">\(t\)</span> distribution is similar to the normal distribution.</p>
<p>When calculating errorbars (for plots, or to report in a paper), we usually should probably use <span class="math inline">\(t\)</span>-based CI’s, but it’s easier to calculate CI’s based on a normal distribution (also called `<span class="math inline">\(z\)</span>-based’), and the difference is minimal as long as <span class="math inline">\(n\)</span> isn’t too small.</p>
<div id="example-sample-sizes-in-the-transitions-dataset" class="section level4 unnumbered">
<h4>Example: Sample sizes in the <code>transitions</code> dataset</h4>
<p>For female (<code>F</code>) and male (<code>M</code>) speakers:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    <span class="kw">table</span>(transitions$sexB)</code></pre></div>
<pre><code>## 
##     F     M 
##  9550 11540</code></pre>
<p>suppose now we which to construct a plot showing the mean transition duration (ms) .</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">transitions %&gt;%<span class="st"> </span><span class="kw">group_by</span>(sexB) %&gt;%
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">meanDur =</span> <span class="kw">mean</span>(dur), <span class="dt">se=</span><span class="kw">n</span>()/<span class="kw">sd</span>(dur)) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(sexB, meanDur)) +
<span class="st">    </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Speaker sex&quot;</span>) +
<span class="st">    </span><span class="kw">ylab</span>(<span class="st">&quot;Mean transition duration (ms) +/- 95% CI&quot;</span>)</code></pre></div>
<p><img src="01-inferential-statistics-basics_files/figure-html/unnamed-chunk-14-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>What critical value do we use if we wish to add 95% CIs in our plot using <code>geom_errorbar</code>? That is, how should we complete the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">transitions %&gt;%<span class="st"> </span><span class="kw">group_by</span>(sexB) %&gt;%
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">meanDur =</span> <span class="kw">mean</span>(dur), <span class="dt">se=</span><span class="kw">n</span>()/<span class="kw">sd</span>(dur)) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(sexB, meanDur)) +
<span class="st">    </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>meanDur-_____*se, <span class="dt">ymax=</span>meanDur+_____*se), <span class="dt">width=</span><span class="fl">0.1</span>) +
<span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Speaker sex&quot;</span>) +
<span class="st">    </span><span class="kw">ylab</span>(<span class="st">&quot;Mean transition duration (ms) +/- 95% CI&quot;</span>)</code></pre></div>
<p>As discussed above, we should probably use 1.96; the same as in <span class="math inline">\(Z\)</span>-based confidence intervals:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">transitions %&gt;%<span class="st"> </span><span class="kw">group_by</span>(sexB) %&gt;%
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">meanDur =</span> <span class="kw">mean</span>(dur), <span class="dt">se=</span><span class="kw">n</span>()/<span class="kw">sd</span>(dur)) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(sexB, meanDur)) +
<span class="st">    </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>meanDur<span class="fl">-1.96</span>*se, <span class="dt">ymax=</span>meanDur<span class="fl">+1.96</span>*se), <span class="dt">width=</span><span class="fl">0.1</span>) +
<span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Speaker sex&quot;</span>) +
<span class="st">    </span><span class="kw">ylab</span>(<span class="st">&quot;Mean transition duration (ms) +/- 95% CI&quot;</span>)</code></pre></div>
<p><img src="01-inferential-statistics-basics_files/figure-html/unnamed-chunk-16-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>However, for smaller samples the confidence intervals will be wider!</p>
</div>
</div>
</div>
<div id="other-reading" class="section level2">
<h2><span class="header-section-number">1.4</span> Other reading</h2>
<p>THe concepts in this chapter are covered to varying degrees of detail, with R examples, in many sources. Some for general audiences:</p>
<ul>
<li><p><span class="citation">Dalgaard (<a href="#ref-dalgaard2008introductory">2008</a>)</span>: Ch. 3</p></li>
<li><p><span class="citation">Crawley (<a href="#ref-crawley2015statistics">2015</a>)</span>: Ch. 1, 4, 5</p></li>
</ul>
<p>and some specialized for language scientists/psychologists, such as:</p>
<ul>
<li><p><span class="citation">Vasishth &amp; Nicenboim (<a href="#ref-vasishth2016statistical">2016</a>)</span></p></li>
<li><p><span class="citation">Navarro (<a href="#ref-NavarroOnline">2015</a>)</span>: Ch. 10</p></li>
<li><p><span class="citation">Vasishth (<a href="#ref-vasishth2014introduction">2014</a>)</span>: Ch. 2</p></li>
</ul>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-johnson2008quantitative">
<p>Johnson, K. (2008). <em>Quantitative methods in linguistics</em>. Malden, MA: Wiley-Blackwell.</p>
</div>
<div id="ref-dalgaard2008introductory">
<p>Dalgaard, P. (2008). <em>Introductory statistics with R</em> (2nd ed.). New York, NY: Springer.</p>
</div>
<div id="ref-crawley2015statistics">
<p>Crawley, M. J. (2015). <em>Statistics: an introduction using R</em> (Second edition). Wiley.</p>
</div>
<div id="ref-vasishth2016statistical">
<p>Vasishth, S., &amp; Nicenboim, B. (2016). Statistical methods for linguistic research: Foundational ideas–Part i. <em>Language and Linguistics Compass</em>, <em>10</em>(8), 349–369.</p>
</div>
<div id="ref-NavarroOnline">
<p>Navarro, D. (2015). <em>Learning Statistics with R</em>. School of Psychology, University of Adelaide, Adelaide, Australia.</p>
</div>
<div id="ref-vasishth2014introduction">
<p>Vasishth, S. (2014). An introduction to statistical data analysis. <em>Summer 2014 Version. Available at <a href="https://github.com/vasishth/Statistics-lecture-notes-Potsdam/">Https://Github.com/Vasishth/Statistics-Lecture-Notes-Potsdam/</a></em>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>More precisely, we are assuming the form of the CLT where the observations are independent and identically distributed. See e.g. <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">the Wikipedia page</a> for more details on variants of the CLT.<a href="inferential-statistics-introduction.html#fnref1">↩</a></p></li>
<li id="fn2"><p>This fact will come in handy when we cover more complex regression models, where it can be difficult to calculate the correct degrees of freedom.<a href="inferential-statistics-introduction.html#fnref2">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="hypothesis-testing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
