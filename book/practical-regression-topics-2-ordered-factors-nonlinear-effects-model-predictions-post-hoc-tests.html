<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Quantitative Methods for Linguistic Data</title>
  <meta name="description" content="Quantitative Methods for Linguistic Data">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Quantitative Methods for Linguistic Data" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Quantitative Methods for Linguistic Data" />
  
  
  

<meta name="author" content="Morgan Sonderegger, Michael Wagner, Francisco Torreira">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="mixed-effects-logistic-regression.html">
<link rel="next" href="datasets-appendix.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Quantitative Methods for Linguistic Data</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html"><i class="fa fa-check"></i><b>1</b> Inferential statistics: Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#loads-transitions.txt-from-osf-project-for-roberts-torreira-levinson-2015-data"><i class="fa fa-check"></i><b>1.1</b> loads transitions.txt from OSF project for Roberts, Torreira, &amp; Levinson (2015) data</a></li>
<li class="chapter" data-level="1.2" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sample-population"><i class="fa fa-check"></i><b>1.2</b> Population vs. sample</a><ul>
<li class="chapter" data-level="1.2.1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sample-to-population-high-level"><i class="fa fa-check"></i><b>1.2.1</b> Sample <span class="math inline">\(\to\)</span> population: High level</a></li>
<li class="chapter" data-level="1.2.2" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sdsm"><i class="fa fa-check"></i><b>1.2.2</b> Sampling distribution of the sample mean</a></li>
<li class="chapter" data-level="1.2.3" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#sampling-from-a-non-normal-distribution"><i class="fa fa-check"></i><b>1.2.3</b> Sampling from a non-normal distribution</a></li>
<li class="chapter" data-level="" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#exercises"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#the-transitions-dataset-was-loaded-at-the-beginning-of-this-page"><i class="fa fa-check"></i><b>1.3</b> the transitions dataset was loaded at the beginning of this page</a></li>
<li class="chapter" data-level="1.4" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#meandur-n-sd-se"><i class="fa fa-check"></i><b>1.4</b> meanDur n sd se</a></li>
<li class="chapter" data-level="1.5" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section"><i class="fa fa-check"></i><b>1.5</b> 1 185.7611 21090 473.3708 3.259591</a></li>
<li class="chapter" data-level="1.6" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#confidence-intervals"><i class="fa fa-check"></i><b>1.6</b> Confidence intervals</a></li>
<li class="chapter" data-level="1.7" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#t-distribution"><i class="fa fa-check"></i><b>1.7</b> <span class="math inline">\(t\)</span> distribution</a><ul>
<li class="chapter" data-level="1.7.1" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#t-based-confidence-intervals"><i class="fa fa-check"></i><b>1.7.1</b> <span class="math inline">\(t\)</span>-based confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-1"><i class="fa fa-check"></i><b>1.8</b> [1] 0.975</a></li>
<li class="chapter" data-level="1.9" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#n"><i class="fa fa-check"></i><b>1.9</b> n</a></li>
<li class="chapter" data-level="1.10" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-2"><i class="fa fa-check"></i><b>1.10</b> [1,] 5 2.570582</a></li>
<li class="chapter" data-level="1.11" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-3"><i class="fa fa-check"></i><b>1.11</b> [2,] 15 2.131450</a></li>
<li class="chapter" data-level="1.12" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-4"><i class="fa fa-check"></i><b>1.12</b> [3,] 25 2.059539</a></li>
<li class="chapter" data-level="1.13" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-5"><i class="fa fa-check"></i><b>1.13</b> [4,] 50 2.008559</a></li>
<li class="chapter" data-level="1.14" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-6"><i class="fa fa-check"></i><b>1.14</b> [5,] 100 1.983972</a></li>
<li class="chapter" data-level="1.15" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-7"><i class="fa fa-check"></i><b>1.15</b> [6,] 500 1.964720</a></li>
<li class="chapter" data-level="1.16" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-8"><i class="fa fa-check"></i><b>1.16</b> </a></li>
<li class="chapter" data-level="1.17" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#f-m"><i class="fa fa-check"></i><b>1.17</b> F M</a></li>
<li class="chapter" data-level="1.18" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#section-9"><i class="fa fa-check"></i><b>1.18</b> 9550 11540</a></li>
<li class="chapter" data-level="1.19" data-path="inferential-statistics-introduction.html"><a href="inferential-statistics-introduction.html#other-reading"><i class="fa fa-check"></i><b>1.19</b> Other reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>2</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="2.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#loads-transitions.txt-from-osf-project-for-roberts-torreira-levinson-2015-data-1"><i class="fa fa-check"></i><b>2.1</b> loads transitions.txt from OSF project for Roberts, Torreira, &amp; Levinson (2015) data</a></li>
<li class="chapter" data-level="2.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-high-level"><i class="fa fa-check"></i><b>2.2</b> Hypothesis testing: High-level</a></li>
<li class="chapter" data-level="2.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#z-scores"><i class="fa fa-check"></i><b>2.3</b> <span class="math inline">\(z\)</span>-scores</a></li>
<li class="chapter" data-level="2.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-tests"><i class="fa fa-check"></i><b>2.4</b> <span class="math inline">\(t\)</span>-tests</a><ul>
<li class="chapter" data-level="2.4.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#single-sample-t-test-setup"><i class="fa fa-check"></i><b>2.4.1</b> Single-sample <span class="math inline">\(t\)</span>-test: Setup</a></li>
<li class="chapter" data-level="2.4.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-in-general"><i class="fa fa-check"></i><b>2.4.2</b> Hypothesis testing in general</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-10"><i class="fa fa-check"></i><b>2.5</b> [1] 6.494323</a></li>
<li class="chapter" data-level="2.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-11"><i class="fa fa-check"></i><b>2.6</b> </a></li>
<li class="chapter" data-level="2.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#one-sample-t-test"><i class="fa fa-check"></i><b>2.7</b> One Sample t-test</a></li>
<li class="chapter" data-level="2.8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-12"><i class="fa fa-check"></i><b>2.8</b> </a></li>
<li class="chapter" data-level="2.9" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-dwrittenfrequency-t-2.1317-df-19-p-value-0.04631-alternative-hypothesis-true-mean-is-not-equal-to-6.494-95-percent-confidence-interval-6.516539-8.958954-sample-estimates-mean-of-x-7.737747-one-sample-t-test-data-dwrittenfrequency"><i class="fa fa-check"></i><b>2.9</b> data: d<span class="math inline">\(WrittenFrequency ## t = 2.1317, df = 19, p-value = 0.04631 ## alternative hypothesis: true mean is not equal to 6.494 ## 95 percent confidence interval: ## 6.516539 8.958954 ## sample estimates: ## mean of x ## 7.737747 ## ## One Sample t-test ## ## data: d\)</span>WrittenFrequency</a></li>
<li class="chapter" data-level="2.10" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-2.1505-df-102-p-value-0.03388"><i class="fa fa-check"></i><b>2.10</b> t = 2.1505, df = 102, p-value = 0.03388</a></li>
<li class="chapter" data-level="2.11" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-mean-is-not-equal-to-6.494"><i class="fa fa-check"></i><b>2.11</b> alternative hypothesis: true mean is not equal to 6.494</a></li>
<li class="chapter" data-level="2.12" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#percent-confidence-interval"><i class="fa fa-check"></i><b>2.12</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="2.13" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-13"><i class="fa fa-check"></i><b>2.13</b> 6.522260 7.193689</a></li>
<li class="chapter" data-level="2.14" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sample-estimates"><i class="fa fa-check"></i><b>2.14</b> sample estimates:</a></li>
<li class="chapter" data-level="2.15" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#mean-of-x"><i class="fa fa-check"></i><b>2.15</b> mean of x</a></li>
<li class="chapter" data-level="2.16" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-14"><i class="fa fa-check"></i><b>2.16</b> 6.857975</a><ul>
<li class="chapter" data-level="2.16.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-sample-t-test"><i class="fa fa-check"></i><b>2.16.1</b> Two-sample <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="2.17" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-15"><i class="fa fa-check"></i><b>2.17</b> </a></li>
<li class="chapter" data-level="2.18" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-sample-t-test"><i class="fa fa-check"></i><b>2.18</b> Two Sample t-test</a></li>
<li class="chapter" data-level="2.19" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-16"><i class="fa fa-check"></i><b>2.19</b> </a></li>
<li class="chapter" data-level="2.20" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-regularitywrittenfrequency-by-regularitytype"><i class="fa fa-check"></i><b>2.20</b> data: regularity<span class="math inline">\(WrittenFrequency by regularity\)</span>type</a></li>
<li class="chapter" data-level="2.21" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t--2.6406-df-698-p-value-0.008462"><i class="fa fa-check"></i><b>2.21</b> t = -2.6406, df = 698, p-value = 0.008462</a></li>
<li class="chapter" data-level="2.22" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-difference-in-means-is-not-equal-to-0"><i class="fa fa-check"></i><b>2.22</b> alternative hypothesis: true difference in means is not equal to 0</a></li>
<li class="chapter" data-level="2.23" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#percent-confidence-interval-1"><i class="fa fa-check"></i><b>2.23</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="2.24" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-17"><i class="fa fa-check"></i><b>2.24</b> -0.8834591 -0.1299488</a></li>
<li class="chapter" data-level="2.25" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sample-estimates-1"><i class="fa fa-check"></i><b>2.25</b> sample estimates:</a></li>
<li class="chapter" data-level="2.26" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#mean-in-group-hebben-mean-in-group-nonheb"><i class="fa fa-check"></i><b>2.26</b> mean in group hebben mean in group nonheb</a></li>
<li class="chapter" data-level="2.27" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-18"><i class="fa fa-check"></i><b>2.27</b> 6.494323 7.001027</a><ul>
<li class="chapter" data-level="2.27.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#welch-example"><i class="fa fa-check"></i><b>2.27.1</b> Unequal variances: Welch <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="2.28" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-19"><i class="fa fa-check"></i><b>2.28</b> </a></li>
<li class="chapter" data-level="2.29" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#welch-two-sample-t-test"><i class="fa fa-check"></i><b>2.29</b> Welch Two Sample t-test</a></li>
<li class="chapter" data-level="2.30" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-20"><i class="fa fa-check"></i><b>2.30</b> </a></li>
<li class="chapter" data-level="2.31" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-regularitywrittenfrequency-by-regularitytype-1"><i class="fa fa-check"></i><b>2.31</b> data: regularity<span class="math inline">\(WrittenFrequency by regularity\)</span>type</a></li>
<li class="chapter" data-level="2.32" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t--2.6688-df-179.82-p-value-0.008309"><i class="fa fa-check"></i><b>2.32</b> t = -2.6688, df = 179.82, p-value = 0.008309</a></li>
<li class="chapter" data-level="2.33" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-difference-in-means-is-not-equal-to-0-1"><i class="fa fa-check"></i><b>2.33</b> alternative hypothesis: true difference in means is not equal to 0</a></li>
<li class="chapter" data-level="2.34" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#percent-confidence-interval-2"><i class="fa fa-check"></i><b>2.34</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="2.35" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-21"><i class="fa fa-check"></i><b>2.35</b> -0.8813494 -0.1320584</a></li>
<li class="chapter" data-level="2.36" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sample-estimates-2"><i class="fa fa-check"></i><b>2.36</b> sample estimates:</a></li>
<li class="chapter" data-level="2.37" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#mean-in-group-hebben-mean-in-group-nonheb-1"><i class="fa fa-check"></i><b>2.37</b> mean in group hebben mean in group nonheb</a></li>
<li class="chapter" data-level="2.38" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-22"><i class="fa fa-check"></i><b>2.38</b> 6.494323 7.001027</a><ul>
<li class="chapter" data-level="2.38.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-test-assumptions"><i class="fa fa-check"></i><b>2.38.1</b> Assumptions behind <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="2.38.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paired-t-test"><i class="fa fa-check"></i><b>2.38.2</b> Paired <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="2.39" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#a-tibble-349-x-3"><i class="fa fa-check"></i><b>2.39</b> # A tibble: 349 x 3</a></li>
<li class="chapter" data-level="2.40" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#file-meandurfirst-meandurafter"><i class="fa fa-check"></i><b>2.40</b> file meanDurFirst meanDurAfter</a></li>
<li class="chapter" data-level="2.41" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-23"><i class="fa fa-check"></i><b>2.41</b> <fct> <dbl> <dbl></a></li>
<li class="chapter" data-level="2.42" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3154.eaf-231.-245."><i class="fa fa-check"></i><b>2.42</b> 1 sw3154.eaf 231. 245.</a></li>
<li class="chapter" data-level="2.43" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3155.eaf-19-153."><i class="fa fa-check"></i><b>2.43</b> 2 sw3155.eaf 19 153.</a></li>
<li class="chapter" data-level="2.44" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3156.eaf-131--9.11"><i class="fa fa-check"></i><b>2.44</b> 3 sw3156.eaf 131 -9.11</a></li>
<li class="chapter" data-level="2.45" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3159.eaf-166.--28.3"><i class="fa fa-check"></i><b>2.45</b> 4 sw3159.eaf 166. -28.3</a></li>
<li class="chapter" data-level="2.46" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3161.eaf--352.-34.3"><i class="fa fa-check"></i><b>2.46</b> 5 sw3161.eaf -352. 34.3</a></li>
<li class="chapter" data-level="2.47" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3168.eaf-31.7-120."><i class="fa fa-check"></i><b>2.47</b> 6 sw3168.eaf 31.7 120.</a></li>
<li class="chapter" data-level="2.48" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3169.eaf-nan-202."><i class="fa fa-check"></i><b>2.48</b> 7 sw3169.eaf NaN 202.</a></li>
<li class="chapter" data-level="2.49" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3171.eaf--76.8--120."><i class="fa fa-check"></i><b>2.49</b> 8 sw3171.eaf -76.8 -120.</a></li>
<li class="chapter" data-level="2.50" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3174.eaf-378.-75.7"><i class="fa fa-check"></i><b>2.50</b> 9 sw3174.eaf 378. 75.7</a></li>
<li class="chapter" data-level="2.51" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sw3182.eaf-330.-139."><i class="fa fa-check"></i><b>2.51</b> 10 sw3182.eaf 330. 139.</a></li>
<li class="chapter" data-level="2.52" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#with-339-more-rows"><i class="fa fa-check"></i><b>2.52</b> # … with 339 more rows</a></li>
<li class="chapter" data-level="2.53" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-24"><i class="fa fa-check"></i><b>2.53</b> </a></li>
<li class="chapter" data-level="2.54" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paired-t-test"><i class="fa fa-check"></i><b>2.54</b> Paired t-test</a></li>
<li class="chapter" data-level="2.55" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-25"><i class="fa fa-check"></i><b>2.55</b> </a></li>
<li class="chapter" data-level="2.56" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-dmeandurfirst-and-dmeandurafter"><i class="fa fa-check"></i><b>2.56</b> data: d<span class="math inline">\(meanDurFirst and d\)</span>meanDurAfter</a></li>
<li class="chapter" data-level="2.57" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-5.9893-df-346-p-value-5.283e-09"><i class="fa fa-check"></i><b>2.57</b> t = 5.9893, df = 346, p-value = 5.283e-09</a></li>
<li class="chapter" data-level="2.58" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-difference-in-means-is-not-equal-to-0-2"><i class="fa fa-check"></i><b>2.58</b> alternative hypothesis: true difference in means is not equal to 0</a></li>
<li class="chapter" data-level="2.59" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#percent-confidence-interval-3"><i class="fa fa-check"></i><b>2.59</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="2.60" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-26"><i class="fa fa-check"></i><b>2.60</b> 42.10084 83.27295</a></li>
<li class="chapter" data-level="2.61" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sample-estimates-3"><i class="fa fa-check"></i><b>2.61</b> sample estimates:</a></li>
<li class="chapter" data-level="2.62" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#mean-of-the-differences"><i class="fa fa-check"></i><b>2.62</b> mean of the differences</a></li>
<li class="chapter" data-level="2.63" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-27"><i class="fa fa-check"></i><b>2.63</b> 62.6869</a><ul>
<li class="chapter" data-level="2.63.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#reporting-a-hypothesis-test"><i class="fa fa-check"></i><b>2.63.1</b> Reporting a hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="2.64" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#checking-normality"><i class="fa fa-check"></i><b>2.64</b> Checking normality</a><ul>
<li class="chapter" data-level="2.64.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#visual-methods"><i class="fa fa-check"></i><b>2.64.1</b> Visual methods</a></li>
</ul></li>
<li class="chapter" data-level="2.65" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#stat_bin-using-bins-30.-pick-better-value-with-binwidth."><i class="fa fa-check"></i><b>2.65</b> <code>stat_bin()</code> using <code>bins = 30</code>. Pick better value with <code>binwidth</code>.</a><ul>
<li class="chapter" data-level="2.65.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#q-q-plots"><i class="fa fa-check"></i><b>2.65.1</b> Q-Q plots</a></li>
<li class="chapter" data-level="2.65.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#shapiro-wilk-example"><i class="fa fa-check"></i><b>2.65.2</b> Hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="2.66" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-28"><i class="fa fa-check"></i><b>2.66</b> </a></li>
<li class="chapter" data-level="2.67" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#shapiro-wilk-normality-test"><i class="fa fa-check"></i><b>2.67</b> Shapiro-Wilk normality test</a></li>
<li class="chapter" data-level="2.68" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-29"><i class="fa fa-check"></i><b>2.68</b> </a></li>
<li class="chapter" data-level="2.69" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-hebbenwrittenfrequency"><i class="fa fa-check"></i><b>2.69</b> data: hebben$WrittenFrequency</a></li>
<li class="chapter" data-level="2.70" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#w-0.97396-p-value-1.324e-08"><i class="fa fa-check"></i><b>2.70</b> W = 0.97396, p-value = 1.324e-08</a><ul>
<li class="chapter" data-level="2.70.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#other-parametric-tests"><i class="fa fa-check"></i><b>2.70.1</b> Other parametric tests</a></li>
</ul></li>
<li class="chapter" data-level="2.71" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#non-parametric-tests"><i class="fa fa-check"></i><b>2.71</b> Non-parametric tests</a><ul>
<li class="chapter" data-level="2.71.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#wilcoxson-tests"><i class="fa fa-check"></i><b>2.71.1</b> Wilcoxson tests</a></li>
<li class="chapter" data-level="2.71.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-sample-wilcoxson-test"><i class="fa fa-check"></i><b>2.71.2</b> Two-sample Wilcoxson test</a></li>
</ul></li>
<li class="chapter" data-level="2.72" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-30"><i class="fa fa-check"></i><b>2.72</b> </a></li>
<li class="chapter" data-level="2.73" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#wilcoxon-rank-sum-test-with-continuity-correction"><i class="fa fa-check"></i><b>2.73</b> Wilcoxon rank sum test with continuity correction</a></li>
<li class="chapter" data-level="2.74" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-31"><i class="fa fa-check"></i><b>2.74</b> </a></li>
<li class="chapter" data-level="2.75" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-writtenfrequency-by-type"><i class="fa fa-check"></i><b>2.75</b> data: WrittenFrequency by type</a></li>
<li class="chapter" data-level="2.76" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#w-29315-p-value-0.002444"><i class="fa fa-check"></i><b>2.76</b> W = 29315, p-value = 0.002444</a></li>
<li class="chapter" data-level="2.77" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-location-shift-is-not-equal-to-0"><i class="fa fa-check"></i><b>2.77</b> alternative hypothesis: true location shift is not equal to 0</a><ul>
<li class="chapter" data-level="2.77.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#parametric-versus-non-parametric-tests"><i class="fa fa-check"></i><b>2.77.1</b> Parametric versus non-parametric tests</a></li>
</ul></li>
<li class="chapter" data-level="2.78" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-32"><i class="fa fa-check"></i><b>2.78</b> </a></li>
<li class="chapter" data-level="2.79" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#welch-two-sample-t-test-1"><i class="fa fa-check"></i><b>2.79</b> Welch Two Sample t-test</a></li>
<li class="chapter" data-level="2.80" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-33"><i class="fa fa-check"></i><b>2.80</b> </a></li>
<li class="chapter" data-level="2.81" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-x1-and-x2"><i class="fa fa-check"></i><b>2.81</b> data: x1 and x2</a></li>
<li class="chapter" data-level="2.82" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-5.3111-df-147.12-p-value-3.948e-07"><i class="fa fa-check"></i><b>2.82</b> t = 5.3111, df = 147.12, p-value = 3.948e-07</a></li>
<li class="chapter" data-level="2.83" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-difference-in-means-is-not-equal-to-0-3"><i class="fa fa-check"></i><b>2.83</b> alternative hypothesis: true difference in means is not equal to 0</a></li>
<li class="chapter" data-level="2.84" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#percent-confidence-interval-4"><i class="fa fa-check"></i><b>2.84</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="2.85" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-34"><i class="fa fa-check"></i><b>2.85</b> 0.3312187 0.7237747</a></li>
<li class="chapter" data-level="2.86" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sample-estimates-4"><i class="fa fa-check"></i><b>2.86</b> sample estimates:</a></li>
<li class="chapter" data-level="2.87" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#mean-of-x-mean-of-y"><i class="fa fa-check"></i><b>2.87</b> mean of x mean of y</a></li>
<li class="chapter" data-level="2.88" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-35"><i class="fa fa-check"></i><b>2.88</b> 1.489870 0.962373</a></li>
<li class="chapter" data-level="2.89" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-36"><i class="fa fa-check"></i><b>2.89</b> </a></li>
<li class="chapter" data-level="2.90" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#wilcoxon-rank-sum-test-with-continuity-correction-1"><i class="fa fa-check"></i><b>2.90</b> Wilcoxon rank sum test with continuity correction</a></li>
<li class="chapter" data-level="2.91" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#section-37"><i class="fa fa-check"></i><b>2.91</b> </a></li>
<li class="chapter" data-level="2.92" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#data-x1-and-x2-1"><i class="fa fa-check"></i><b>2.92</b> data: x1 and x2</a></li>
<li class="chapter" data-level="2.93" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#w-6936-p-value-2.254e-06"><i class="fa fa-check"></i><b>2.93</b> W = 6936, p-value = 2.254e-06</a></li>
<li class="chapter" data-level="2.94" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#alternative-hypothesis-true-location-shift-is-not-equal-to-0-1"><i class="fa fa-check"></i><b>2.94</b> alternative hypothesis: true location shift is not equal to 0</a></li>
<li class="chapter" data-level="2.95" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#other-reading-1"><i class="fa fa-check"></i><b>2.95</b> Other reading</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>3</b> Linear regression</a><ul>
<li class="chapter" data-level="3.1" data-path="linear-regression.html"><a href="linear-regression.html#loads-alternativesmcgillling620.csv-from-osf-project-for-wagner-2016-data"><i class="fa fa-check"></i><b>3.1</b> loads alternativesMcGillLing620.csv from OSF project for Wagner (2016) data</a></li>
<li class="chapter" data-level="3.2" data-path="linear-regression.html"><a href="linear-regression.html#loads-french_medial_vowel_devoicing.txt-from-osf-project-for-torreira-ernestus-2010-data"><i class="fa fa-check"></i><b>3.2</b> loads french_medial_vowel_devoicing.txt from OSF project for Torreira &amp; Ernestus (2010) data</a></li>
<li class="chapter" data-level="3.3" data-path="linear-regression.html"><a href="linear-regression.html#loads-halfrhymemcgillling620.csv-from-osf-project-for-harder-2013-data"><i class="fa fa-check"></i><b>3.3</b> loads halfrhymeMcGillLing620.csv from OSF project for Harder (2013) data</a></li>
<li class="chapter" data-level="3.4" data-path="linear-regression.html"><a href="linear-regression.html#regression-general-introduction"><i class="fa fa-check"></i><b>3.4</b> Regression: General introduction</a><ul>
<li class="chapter" data-level="3.4.1" data-path="linear-regression.html"><a href="linear-regression.html#linear-models"><i class="fa fa-check"></i><b>3.4.1</b> Linear models</a></li>
<li class="chapter" data-level="3.4.2" data-path="linear-regression.html"><a href="linear-regression.html#terminology"><i class="fa fa-check"></i><b>3.4.2</b> Terminology</a></li>
<li class="chapter" data-level="3.4.3" data-path="linear-regression.html"><a href="linear-regression.html#steps-and-assumptions-of-regression-analysis"><i class="fa fa-check"></i><b>3.4.3</b> Steps and assumptions of regression analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="linear-regression.html"><a href="linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>3.5</b> Simple linear regression</a><ul>
<li class="chapter" data-level="3.5.1" data-path="linear-regression.html"><a href="linear-regression.html#slr-continuous-predictor"><i class="fa fa-check"></i><b>3.5.1</b> SLR: Continuous predictor</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequency-rtlexdec"><i class="fa fa-check"></i><b>3.6</b> WrittenFrequency RTlexdec</a></li>
<li class="chapter" data-level="3.7" data-path="linear-regression.html"><a href="linear-regression.html#section-38"><i class="fa fa-check"></i><b>3.7</b> 1 3.912023 6.543754</a></li>
<li class="chapter" data-level="3.8" data-path="linear-regression.html"><a href="linear-regression.html#section-39"><i class="fa fa-check"></i><b>3.8</b> 2 4.521789 6.397596</a></li>
<li class="chapter" data-level="3.9" data-path="linear-regression.html"><a href="linear-regression.html#section-40"><i class="fa fa-check"></i><b>3.9</b> 3 6.505784 6.304942</a></li>
<li class="chapter" data-level="3.10" data-path="linear-regression.html"><a href="linear-regression.html#section-41"><i class="fa fa-check"></i><b>3.10</b> 4 5.017280 6.424221</a></li>
<li class="chapter" data-level="3.11" data-path="linear-regression.html"><a href="linear-regression.html#section-42"><i class="fa fa-check"></i><b>3.11</b> 5 4.890349 6.450597</a></li>
<li class="chapter" data-level="3.12" data-path="linear-regression.html"><a href="linear-regression.html#section-43"><i class="fa fa-check"></i><b>3.12</b> 6 4.770685 6.531970</a><ul>
<li class="chapter" data-level="3.12.1" data-path="linear-regression.html"><a href="linear-regression.html#slr-parameter-estimation"><i class="fa fa-check"></i><b>3.12.1</b> SLR: Parameter estimation</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="linear-regression.html"><a href="linear-regression.html#section-44"><i class="fa fa-check"></i><b>3.13</b> </a></li>
<li class="chapter" data-level="3.14" data-path="linear-regression.html"><a href="linear-regression.html#call"><i class="fa fa-check"></i><b>3.14</b> Call:</a></li>
<li class="chapter" data-level="3.15" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-writtenfrequency-data-young"><i class="fa fa-check"></i><b>3.15</b> lm(formula = RTlexdec ~ WrittenFrequency, data = young)</a></li>
<li class="chapter" data-level="3.16" data-path="linear-regression.html"><a href="linear-regression.html#section-45"><i class="fa fa-check"></i><b>3.16</b> </a></li>
<li class="chapter" data-level="3.17" data-path="linear-regression.html"><a href="linear-regression.html#coefficients"><i class="fa fa-check"></i><b>3.17</b> Coefficients:</a></li>
<li class="chapter" data-level="3.18" data-path="linear-regression.html"><a href="linear-regression.html#intercept-writtenfrequency"><i class="fa fa-check"></i><b>3.18</b> (Intercept) WrittenFrequency</a></li>
<li class="chapter" data-level="3.19" data-path="linear-regression.html"><a href="linear-regression.html#section-46"><i class="fa fa-check"></i><b>3.19</b> 6.62556 -0.03711</a><ul>
<li class="chapter" data-level="3.19.1" data-path="linear-regression.html"><a href="linear-regression.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>3.19.1</b> Hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="3.20" data-path="linear-regression.html"><a href="linear-regression.html#section-47"><i class="fa fa-check"></i><b>3.20</b> </a></li>
<li class="chapter" data-level="3.21" data-path="linear-regression.html"><a href="linear-regression.html#call-1"><i class="fa fa-check"></i><b>3.21</b> Call:</a></li>
<li class="chapter" data-level="3.22" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-writtenfrequency-data-young-1"><i class="fa fa-check"></i><b>3.22</b> lm(formula = RTlexdec ~ WrittenFrequency, data = young)</a></li>
<li class="chapter" data-level="3.23" data-path="linear-regression.html"><a href="linear-regression.html#section-48"><i class="fa fa-check"></i><b>3.23</b> </a></li>
<li class="chapter" data-level="3.24" data-path="linear-regression.html"><a href="linear-regression.html#residuals"><i class="fa fa-check"></i><b>3.24</b> Residuals:</a></li>
<li class="chapter" data-level="3.25" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max"><i class="fa fa-check"></i><b>3.25</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.26" data-path="linear-regression.html"><a href="linear-regression.html#section-49"><i class="fa fa-check"></i><b>3.26</b> -0.34664 -0.05523 -0.00546 0.05167 0.34877</a></li>
<li class="chapter" data-level="3.27" data-path="linear-regression.html"><a href="linear-regression.html#section-50"><i class="fa fa-check"></i><b>3.27</b> </a></li>
<li class="chapter" data-level="3.28" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-1"><i class="fa fa-check"></i><b>3.28</b> Coefficients:</a></li>
<li class="chapter" data-level="3.29" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt"><i class="fa fa-check"></i><b>3.29</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.30" data-path="linear-regression.html"><a href="linear-regression.html#intercept-6.6255559-0.0049432-1340.34-2e-16-writtenfrequency--0.0371069-0.0009242--40.15-2e-16"><i class="fa fa-check"></i><b>3.30</b> (Intercept) 6.6255559 0.0049432 1340.34 &lt;2e-16 <strong><em> ## WrittenFrequency -0.0371069 0.0009242 -40.15 &lt;2e-16 </em></strong></a></li>
<li class="chapter" data-level="3.31" data-path="linear-regression.html"><a href="linear-regression.html#section-51"><i class="fa fa-check"></i><b>3.31</b> —</a></li>
<li class="chapter" data-level="3.32" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1"><i class="fa fa-check"></i><b>3.32</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="3.33" data-path="linear-regression.html"><a href="linear-regression.html#section-52"><i class="fa fa-check"></i><b>3.33</b> </a></li>
<li class="chapter" data-level="3.34" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-0.08142-on-2282-degrees-of-freedom"><i class="fa fa-check"></i><b>3.34</b> Residual standard error: 0.08142 on 2282 degrees of freedom</a></li>
<li class="chapter" data-level="3.35" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.414-adjusted-r-squared-0.4137"><i class="fa fa-check"></i><b>3.35</b> Multiple R-squared: 0.414, Adjusted R-squared: 0.4137</a></li>
<li class="chapter" data-level="3.36" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-1612-on-1-and-2282-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.36</b> F-statistic: 1612 on 1 and 2282 DF, p-value: &lt; 2.2e-16</a></li>
<li class="chapter" data-level="3.37" data-path="linear-regression.html"><a href="linear-regression.html#section-53"><i class="fa fa-check"></i><b>3.37</b> 2.5 % 97.5 %</a></li>
<li class="chapter" data-level="3.38" data-path="linear-regression.html"><a href="linear-regression.html#intercept-6.61586227-6.63524948"><i class="fa fa-check"></i><b>3.38</b> (Intercept) 6.61586227 6.63524948</a></li>
<li class="chapter" data-level="3.39" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequency--0.03891921--0.03529463"><i class="fa fa-check"></i><b>3.39</b> WrittenFrequency -0.03891921 -0.03529463</a><ul>
<li class="chapter" data-level="3.39.1" data-path="linear-regression.html"><a href="linear-regression.html#quality-of-fit"><i class="fa fa-check"></i><b>3.39.1</b> Quality of fit</a></li>
</ul></li>
<li class="chapter" data-level="3.40" data-path="linear-regression.html"><a href="linear-regression.html#section-54"><i class="fa fa-check"></i><b>3.40</b> </a></li>
<li class="chapter" data-level="3.41" data-path="linear-regression.html"><a href="linear-regression.html#call-2"><i class="fa fa-check"></i><b>3.41</b> Call:</a></li>
<li class="chapter" data-level="3.42" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-writtenfrequency-data-d"><i class="fa fa-check"></i><b>3.42</b> lm(formula = RTlexdec ~ WrittenFrequency, data = d)</a></li>
<li class="chapter" data-level="3.43" data-path="linear-regression.html"><a href="linear-regression.html#section-55"><i class="fa fa-check"></i><b>3.43</b> </a></li>
<li class="chapter" data-level="3.44" data-path="linear-regression.html"><a href="linear-regression.html#residuals-1"><i class="fa fa-check"></i><b>3.44</b> Residuals:</a></li>
<li class="chapter" data-level="3.45" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-1"><i class="fa fa-check"></i><b>3.45</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.46" data-path="linear-regression.html"><a href="linear-regression.html#section-56"><i class="fa fa-check"></i><b>3.46</b> -0.127857 -0.045072 -0.005826 0.042917 0.235034</a></li>
<li class="chapter" data-level="3.47" data-path="linear-regression.html"><a href="linear-regression.html#section-57"><i class="fa fa-check"></i><b>3.47</b> </a></li>
<li class="chapter" data-level="3.48" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-2"><i class="fa fa-check"></i><b>3.48</b> Coefficients:</a></li>
<li class="chapter" data-level="3.49" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-1"><i class="fa fa-check"></i><b>3.49</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.50" data-path="linear-regression.html"><a href="linear-regression.html#intercept-6.61733-0.02190-302.236-2e-16-writtenfrequency--0.03501-0.00419--8.354-4.43e-13"><i class="fa fa-check"></i><b>3.50</b> (Intercept) 6.61733 0.02190 302.236 &lt; 2e-16 <strong><em> ## WrittenFrequency -0.03501 0.00419 -8.354 4.43e-13 </em></strong></a></li>
<li class="chapter" data-level="3.51" data-path="linear-regression.html"><a href="linear-regression.html#section-58"><i class="fa fa-check"></i><b>3.51</b> —</a></li>
<li class="chapter" data-level="3.52" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-1"><i class="fa fa-check"></i><b>3.52</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="3.53" data-path="linear-regression.html"><a href="linear-regression.html#section-59"><i class="fa fa-check"></i><b>3.53</b> </a></li>
<li class="chapter" data-level="3.54" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-0.07121-on-98-degrees-of-freedom"><i class="fa fa-check"></i><b>3.54</b> Residual standard error: 0.07121 on 98 degrees of freedom</a></li>
<li class="chapter" data-level="3.55" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.4159-adjusted-r-squared-0.41"><i class="fa fa-check"></i><b>3.55</b> Multiple R-squared: 0.4159, Adjusted R-squared: 0.41</a></li>
<li class="chapter" data-level="3.56" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-69.79-on-1-and-98-df-p-value-4.43e-13"><i class="fa fa-check"></i><b>3.56</b> F-statistic: 69.79 on 1 and 98 DF, p-value: 4.43e-13</a></li>
<li class="chapter" data-level="3.57" data-path="linear-regression.html"><a href="linear-regression.html#section-60"><i class="fa fa-check"></i><b>3.57</b> </a></li>
<li class="chapter" data-level="3.58" data-path="linear-regression.html"><a href="linear-regression.html#pearsons-product-moment-correlation"><i class="fa fa-check"></i><b>3.58</b> Pearson’s product-moment correlation</a></li>
<li class="chapter" data-level="3.59" data-path="linear-regression.html"><a href="linear-regression.html#section-61"><i class="fa fa-check"></i><b>3.59</b> </a></li>
<li class="chapter" data-level="3.60" data-path="linear-regression.html"><a href="linear-regression.html#data-dwrittenfrequency-and-drtlexdec"><i class="fa fa-check"></i><b>3.60</b> data: d<span class="math inline">\(WrittenFrequency and d\)</span>RTlexdec</a></li>
<li class="chapter" data-level="3.61" data-path="linear-regression.html"><a href="linear-regression.html#t--8.354-df-98-p-value-4.43e-13"><i class="fa fa-check"></i><b>3.61</b> t = -8.354, df = 98, p-value = 4.43e-13</a></li>
<li class="chapter" data-level="3.62" data-path="linear-regression.html"><a href="linear-regression.html#alternative-hypothesis-true-correlation-is-not-equal-to-0"><i class="fa fa-check"></i><b>3.62</b> alternative hypothesis: true correlation is not equal to 0</a></li>
<li class="chapter" data-level="3.63" data-path="linear-regression.html"><a href="linear-regression.html#percent-confidence-interval-5"><i class="fa fa-check"></i><b>3.63</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="3.64" data-path="linear-regression.html"><a href="linear-regression.html#section-62"><i class="fa fa-check"></i><b>3.64</b> -0.7467533 -0.5135699</a></li>
<li class="chapter" data-level="3.65" data-path="linear-regression.html"><a href="linear-regression.html#sample-estimates-5"><i class="fa fa-check"></i><b>3.65</b> sample estimates:</a></li>
<li class="chapter" data-level="3.66" data-path="linear-regression.html"><a href="linear-regression.html#cor"><i class="fa fa-check"></i><b>3.66</b> cor</a></li>
<li class="chapter" data-level="3.67" data-path="linear-regression.html"><a href="linear-regression.html#section-63"><i class="fa fa-check"></i><b>3.67</b> -0.644931</a><ul>
<li class="chapter" data-level="3.67.1" data-path="linear-regression.html"><a href="linear-regression.html#categorical-predictor"><i class="fa fa-check"></i><b>3.67.1</b> Categorical predictor</a></li>
<li class="chapter" data-level="3.67.2" data-path="linear-regression.html"><a href="linear-regression.html#slr-with-a-binary-categorical-predictor-vs.two-sample-t-test"><i class="fa fa-check"></i><b>3.67.2</b> SLR with a binary categorical predictor vs. two-sample <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="3.68" data-path="linear-regression.html"><a href="linear-regression.html#section-64"><i class="fa fa-check"></i><b>3.68</b> </a></li>
<li class="chapter" data-level="3.69" data-path="linear-regression.html"><a href="linear-regression.html#two-sample-t-test-1"><i class="fa fa-check"></i><b>3.69</b> Two Sample t-test</a></li>
<li class="chapter" data-level="3.70" data-path="linear-regression.html"><a href="linear-regression.html#section-65"><i class="fa fa-check"></i><b>3.70</b> </a></li>
<li class="chapter" data-level="3.71" data-path="linear-regression.html"><a href="linear-regression.html#data-rtlexdec-by-agesubject"><i class="fa fa-check"></i><b>3.71</b> data: RTlexdec by AgeSubject</a></li>
<li class="chapter" data-level="3.72" data-path="linear-regression.html"><a href="linear-regression.html#t-67.468-df-4566-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.72</b> t = 67.468, df = 4566, p-value &lt; 2.2e-16</a></li>
<li class="chapter" data-level="3.73" data-path="linear-regression.html"><a href="linear-regression.html#alternative-hypothesis-true-difference-in-means-is-not-equal-to-0-4"><i class="fa fa-check"></i><b>3.73</b> alternative hypothesis: true difference in means is not equal to 0</a></li>
<li class="chapter" data-level="3.74" data-path="linear-regression.html"><a href="linear-regression.html#percent-confidence-interval-6"><i class="fa fa-check"></i><b>3.74</b> 95 percent confidence interval:</a></li>
<li class="chapter" data-level="3.75" data-path="linear-regression.html"><a href="linear-regression.html#section-66"><i class="fa fa-check"></i><b>3.75</b> 0.2152787 0.2281642</a></li>
<li class="chapter" data-level="3.76" data-path="linear-regression.html"><a href="linear-regression.html#sample-estimates-6"><i class="fa fa-check"></i><b>3.76</b> sample estimates:</a></li>
<li class="chapter" data-level="3.77" data-path="linear-regression.html"><a href="linear-regression.html#mean-in-group-old-mean-in-group-young"><i class="fa fa-check"></i><b>3.77</b> mean in group old mean in group young</a></li>
<li class="chapter" data-level="3.78" data-path="linear-regression.html"><a href="linear-regression.html#section-67"><i class="fa fa-check"></i><b>3.78</b> 6.660958 6.439237</a></li>
<li class="chapter" data-level="3.79" data-path="linear-regression.html"><a href="linear-regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>3.79</b> Multiple linear regression</a></li>
<li class="chapter" data-level="3.80" data-path="linear-regression.html"><a href="linear-regression.html#section-68"><i class="fa fa-check"></i><b>3.80</b> </a></li>
<li class="chapter" data-level="3.81" data-path="linear-regression.html"><a href="linear-regression.html#call-3"><i class="fa fa-check"></i><b>3.81</b> Call:</a></li>
<li class="chapter" data-level="3.82" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-writtenfrequency-agesubject-data-english"><i class="fa fa-check"></i><b>3.82</b> lm(formula = RTlexdec ~ WrittenFrequency + AgeSubject, data = english)</a></li>
<li class="chapter" data-level="3.83" data-path="linear-regression.html"><a href="linear-regression.html#section-69"><i class="fa fa-check"></i><b>3.83</b> </a></li>
<li class="chapter" data-level="3.84" data-path="linear-regression.html"><a href="linear-regression.html#residuals-2"><i class="fa fa-check"></i><b>3.84</b> Residuals:</a></li>
<li class="chapter" data-level="3.85" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-2"><i class="fa fa-check"></i><b>3.85</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.86" data-path="linear-regression.html"><a href="linear-regression.html#section-70"><i class="fa fa-check"></i><b>3.86</b> -0.34622 -0.06029 -0.00722 0.05178 0.44999</a></li>
<li class="chapter" data-level="3.87" data-path="linear-regression.html"><a href="linear-regression.html#section-71"><i class="fa fa-check"></i><b>3.87</b> </a></li>
<li class="chapter" data-level="3.88" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-3"><i class="fa fa-check"></i><b>3.88</b> Coefficients:</a></li>
<li class="chapter" data-level="3.89" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-2"><i class="fa fa-check"></i><b>3.89</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.90" data-path="linear-regression.html"><a href="linear-regression.html#intercept-6.8467921-0.0039792-1720.64-2e-16-writtenfrequency--0.0370103-0.0007033--52.62-2e-16"><i class="fa fa-check"></i><b>3.90</b> (Intercept) 6.8467921 0.0039792 1720.64 &lt;2e-16 <strong><em> ## WrittenFrequency -0.0370103 0.0007033 -52.62 &lt;2e-16 </em></strong></a></li>
<li><a href="linear-regression.html#agesubjectyoung--0.2217215-0.0025930--85.51-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.08763-on-4565-degrees-of-freedom-multiple-r-squared-0.6883-adjusted-r-squared-0.6882-f-statistic-5040-on-2-and-4565-df-p-value-2.2e-16-1-6.661-goodness-of-fit-metrics-interactions-and-factors-example---call-lmformula-rtnaming-writtenfrequency-agesubject-data-english-residuals-min-1q-median-3q-max--0.160510--0.033425--0.002963-0.030855-0.181032-coefficients-estimate-std.-error-t-value-prt-intercept-6.5517608-0.0029118-2250.09-2e-16-writtenfrequency--0.0116031-0.0005444--21.31-2e-16-agesubjectyoung--0.3651823-0.0041179--88.68-2e-16-writtenfrequencyagesubjectyoung-0.0046191-0.0007699-6.00-2.13e-09-intercept-writtenfrequency-agesubjectyoung-writtenfrequencyagesubjectyoung-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.04796-on-4564-degrees-of-freedom-multiple-r-squared-0.9278-adjusted-r-squared-0.9278-f-statistic-1.956e04-on-3-and-4564-df-p-value-2.2e-16-plotting-interactions-categorical-factors-with-more-than-two-levels-exercise---call-lmformula-familysize-auxiliary-data-regularity-residuals-min-1q-median-3q-max--2.9133--0.7982--0.0250-0.7442-3.5983-coefficients-estimate-std.-error-t-value-prt-intercept-2.59000-0.04902-52.839-2e-16-auxiliaryzijn-0.39274-0.26780-1.467-0.1430-auxiliaryzijnheb-0.32329-0.12594-2.567-0.0105"><span class="toc-section-number">3.91</span> AgeSubjectyoung -0.2217215 0.0025930 -85.51 &lt;2e-16 <strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Residual standard error: 0.08763 on 4565 degrees of freedom ## Multiple R-squared: 0.6883, Adjusted R-squared: 0.6882 ## F-statistic: 5040 on 2 and 4565 DF, p-value: &lt; 2.2e-16 ## [1] 6.661 ### Goodness of fit metrics ### Interactions and factors #### Example {-} ## ## Call: ## lm(formula = RTnaming ~ WrittenFrequency </em> AgeSubject, data = english) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.160510 -0.033425 -0.002963 0.030855 0.181032 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.5517608 0.0029118 2250.09 &lt; 2e-16 ## WrittenFrequency -0.0116031 0.0005444 -21.31 &lt; 2e-16 ## AgeSubjectyoung -0.3651823 0.0041179 -88.68 &lt; 2e-16 ## WrittenFrequency:AgeSubjectyoung 0.0046191 0.0007699 6.00 2.13e-09 ##<br />
## (Intercept) </strong><em> ## WrittenFrequency </em><strong> ## AgeSubjectyoung </strong><em> ## WrittenFrequency:AgeSubjectyoung </em><strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Residual standard error: 0.04796 on 4564 degrees of freedom ## Multiple R-squared: 0.9278, Adjusted R-squared: 0.9278 ## F-statistic: 1.956e+04 on 3 and 4564 DF, p-value: &lt; 2.2e-16 ### Plotting interactions ### Categorical factors with more than two levels #### Exercise {-} ## ## Call: ## lm(formula = FamilySize ~ Auxiliary, data = regularity) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.9133 -0.7982 -0.0250 0.7442 3.5983 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 2.59000 0.04902 52.839 &lt;2e-16 </strong><em> ## Auxiliaryzijn 0.39274 0.26780 1.467 0.1430<br />
## Auxiliaryzijnheb 0.32329 0.12594 2.567 0.0105 </em></a></li>
<li class="chapter" data-level="3.92" data-path="linear-regression.html"><a href="linear-regression.html#section-72"><i class="fa fa-check"></i><b>3.92</b> —</a></li>
<li class="chapter" data-level="3.93" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-2"><i class="fa fa-check"></i><b>3.93</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="3.94" data-path="linear-regression.html"><a href="linear-regression.html#section-73"><i class="fa fa-check"></i><b>3.94</b> </a></li>
<li class="chapter" data-level="3.95" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-1.177-on-697-degrees-of-freedom"><i class="fa fa-check"></i><b>3.95</b> Residual standard error: 1.177 on 697 degrees of freedom</a></li>
<li class="chapter" data-level="3.96" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.01169-adjusted-r-squared-0.008855"><i class="fa fa-check"></i><b>3.96</b> Multiple R-squared: 0.01169, Adjusted R-squared: 0.008855</a></li>
<li class="chapter" data-level="3.97" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-4.123-on-2-and-697-df-p-value-0.0166"><i class="fa fa-check"></i><b>3.97</b> F-statistic: 4.123 on 2 and 697 DF, p-value: 0.0166</a><ul>
<li class="chapter" data-level="3.97.1" data-path="linear-regression.html"><a href="linear-regression.html#releveling-factors"><i class="fa fa-check"></i><b>3.97.1</b> Releveling factors</a></li>
</ul></li>
<li class="chapter" data-level="3.98" data-path="linear-regression.html"><a href="linear-regression.html#section-74"><i class="fa fa-check"></i><b>3.98</b> </a></li>
<li class="chapter" data-level="3.99" data-path="linear-regression.html"><a href="linear-regression.html#call-4"><i class="fa fa-check"></i><b>3.99</b> Call:</a></li>
<li class="chapter" data-level="3.100" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-familysize-auxiliary-data-regularity"><i class="fa fa-check"></i><b>3.100</b> lm(formula = FamilySize ~ Auxiliary, data = regularity)</a></li>
<li class="chapter" data-level="3.101" data-path="linear-regression.html"><a href="linear-regression.html#section-75"><i class="fa fa-check"></i><b>3.101</b> </a></li>
<li class="chapter" data-level="3.102" data-path="linear-regression.html"><a href="linear-regression.html#residuals-3"><i class="fa fa-check"></i><b>3.102</b> Residuals:</a></li>
<li class="chapter" data-level="3.103" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-3"><i class="fa fa-check"></i><b>3.103</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.104" data-path="linear-regression.html"><a href="linear-regression.html#section-76"><i class="fa fa-check"></i><b>3.104</b> -2.9133 -0.7982 -0.0250 0.7442 3.5983</a></li>
<li class="chapter" data-level="3.105" data-path="linear-regression.html"><a href="linear-regression.html#section-77"><i class="fa fa-check"></i><b>3.105</b> </a></li>
<li class="chapter" data-level="3.106" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-4"><i class="fa fa-check"></i><b>3.106</b> Coefficients:</a></li>
<li class="chapter" data-level="3.107" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-3"><i class="fa fa-check"></i><b>3.107</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li><a href="linear-regression.html#intercept-2.98274-0.26328-11.329-2e-16-auxiliaryhebben--0.39274-0.26780--1.467-0.143-auxiliaryzijnheb--0.06946-0.28771--0.241-0.809-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-1.177-on-697-degrees-of-freedom-multiple-r-squared-0.01169-adjusted-r-squared-0.008855-f-statistic-4.123-on-2-and-697-df-p-value-0.0166-linear-regression-assumptions-linear-regression-assumptions-visual-methods-assumption-1-linearity-example---call-lmformula-rintensity-rduration-irduration2-data-alt-residuals-min-1q-median-3q-max--16.3199--3.5197--0.2448-2.9515-19.1480-coefficients-estimate-std.-error-t-value-prt-intercept-5.8280-0.2622-22.228-2e-16"><span class="toc-section-number">3.108</span> (Intercept) 2.98274 0.26328 11.329 &lt;2e-16 <strong><em> ## Auxiliaryhebben -0.39274 0.26780 -1.467 0.143<br />
## Auxiliaryzijnheb -0.06946 0.28771 -0.241 0.809<br />
## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Residual standard error: 1.177 on 697 degrees of freedom ## Multiple R-squared: 0.01169, Adjusted R-squared: 0.008855 ## F-statistic: 4.123 on 2 and 697 DF, p-value: 0.0166 ## Linear regression assumptions {#linear-regression-assumptions} ### Visual methods ### Assumption 1: Linearity #### Example {-} ## ## Call: ## lm(formula = rintensity ~ rduration + I(rduration^2), data = alt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -16.3199 -3.5197 -0.2448 2.9515 19.1480 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 5.8280 0.2622 22.228 &lt;2e-16 </em></strong></a></li>
<li class="chapter" data-level="3.109" data-path="linear-regression.html"><a href="linear-regression.html#rduration-3.8841-0.3263-11.904-2e-16-irduration2--3.1381-0.3429--9.151-2e-16"><i class="fa fa-check"></i><b>3.109</b> rduration 3.8841 0.3263 11.904 &lt;2e-16 <strong><em> ## I(rduration^2) -3.1381 0.3429 -9.151 &lt;2e-16 </em></strong></a></li>
<li class="chapter" data-level="3.110" data-path="linear-regression.html"><a href="linear-regression.html#section-78"><i class="fa fa-check"></i><b>3.110</b> —</a></li>
<li class="chapter" data-level="3.111" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-3"><i class="fa fa-check"></i><b>3.111</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="3.112" data-path="linear-regression.html"><a href="linear-regression.html#section-79"><i class="fa fa-check"></i><b>3.112</b> </a></li>
<li class="chapter" data-level="3.113" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-5.05-on-627-degrees-of-freedom"><i class="fa fa-check"></i><b>3.113</b> Residual standard error: 5.05 on 627 degrees of freedom</a></li>
<li class="chapter" data-level="3.114" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.358-adjusted-r-squared-0.3559"><i class="fa fa-check"></i><b>3.114</b> Multiple R-squared: 0.358, Adjusted R-squared: 0.3559</a></li>
<li class="chapter" data-level="3.115" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-174.8-on-2-and-627-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.115</b> F-statistic: 174.8 on 2 and 627 DF, p-value: &lt; 2.2e-16</a><ul>
<li class="chapter" data-level="3.115.1" data-path="linear-regression.html"><a href="linear-regression.html#c2ioe"><i class="fa fa-check"></i><b>3.115.1</b> Assumption 2: Independence of errors</a></li>
<li class="chapter" data-level="3.115.2" data-path="linear-regression.html"><a href="linear-regression.html#assumption-3-normality-of-errors"><i class="fa fa-check"></i><b>3.115.2</b> Assumption 3: Normality of errors</a></li>
<li class="chapter" data-level="3.115.3" data-path="linear-regression.html"><a href="linear-regression.html#assumtion-4-constancy-of-variance"><i class="fa fa-check"></i><b>3.115.3</b> Assumtion 4: Constancy of variance</a></li>
<li class="chapter" data-level="3.115.4" data-path="linear-regression.html"><a href="linear-regression.html#interim-summary"><i class="fa fa-check"></i><b>3.115.4</b> Interim summary</a></li>
<li class="chapter" data-level="3.115.5" data-path="linear-regression.html"><a href="linear-regression.html#transforming-to-normality"><i class="fa fa-check"></i><b>3.115.5</b> Transforming to normality</a></li>
<li class="chapter" data-level="3.115.6" data-path="linear-regression.html"><a href="linear-regression.html#assumption-5-linear-independence-of-predictors"><i class="fa fa-check"></i><b>3.115.6</b> Assumption 5: Linear independence of predictors</a></li>
<li class="chapter" data-level="3.115.7" data-path="linear-regression.html"><a href="linear-regression.html#collinearity"><i class="fa fa-check"></i><b>3.115.7</b> Collinearity</a></li>
</ul></li>
<li class="chapter" data-level="3.116" data-path="linear-regression.html"><a href="linear-regression.html#section-80"><i class="fa fa-check"></i><b>3.116</b> </a></li>
<li class="chapter" data-level="3.117" data-path="linear-regression.html"><a href="linear-regression.html#call-5"><i class="fa fa-check"></i><b>3.117</b> Call:</a></li>
<li class="chapter" data-level="3.118" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-familiarity-data-d"><i class="fa fa-check"></i><b>3.118</b> lm(formula = RTlexdec ~ Familiarity, data = d)</a></li>
<li class="chapter" data-level="3.119" data-path="linear-regression.html"><a href="linear-regression.html#section-81"><i class="fa fa-check"></i><b>3.119</b> </a></li>
<li class="chapter" data-level="3.120" data-path="linear-regression.html"><a href="linear-regression.html#residuals-4"><i class="fa fa-check"></i><b>3.120</b> Residuals:</a></li>
<li class="chapter" data-level="3.121" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-4"><i class="fa fa-check"></i><b>3.121</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.122" data-path="linear-regression.html"><a href="linear-regression.html#section-82"><i class="fa fa-check"></i><b>3.122</b> -0.094956 -0.035753 0.002142 0.050448 0.093090</a></li>
<li class="chapter" data-level="3.123" data-path="linear-regression.html"><a href="linear-regression.html#section-83"><i class="fa fa-check"></i><b>3.123</b> </a></li>
<li class="chapter" data-level="3.124" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-5"><i class="fa fa-check"></i><b>3.124</b> Coefficients:</a></li>
<li class="chapter" data-level="3.125" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-4"><i class="fa fa-check"></i><b>3.125</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.126" data-path="linear-regression.html"><a href="linear-regression.html#intercept-6.645471-0.038231-173.83-2e-16-familiarity--0.047697-0.009502--5.02-4.44e-05"><i class="fa fa-check"></i><b>3.126</b> (Intercept) 6.645471 0.038231 173.83 &lt; 2e-16 <strong><em> ## Familiarity -0.047697 0.009502 -5.02 4.44e-05 </em></strong></a></li>
<li class="chapter" data-level="3.127" data-path="linear-regression.html"><a href="linear-regression.html#section-84"><i class="fa fa-check"></i><b>3.127</b> —</a></li>
<li class="chapter" data-level="3.128" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-4"><i class="fa fa-check"></i><b>3.128</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="3.129" data-path="linear-regression.html"><a href="linear-regression.html#section-85"><i class="fa fa-check"></i><b>3.129</b> </a></li>
<li class="chapter" data-level="3.130" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-0.05699-on-23-degrees-of-freedom"><i class="fa fa-check"></i><b>3.130</b> Residual standard error: 0.05699 on 23 degrees of freedom</a></li>
<li class="chapter" data-level="3.131" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.5228-adjusted-r-squared-0.502"><i class="fa fa-check"></i><b>3.131</b> Multiple R-squared: 0.5228, Adjusted R-squared: 0.502</a></li>
<li class="chapter" data-level="3.132" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-25.2-on-1-and-23-df-p-value-4.442e-05"><i class="fa fa-check"></i><b>3.132</b> F-statistic: 25.2 on 1 and 23 DF, p-value: 4.442e-05</a></li>
<li class="chapter" data-level="3.133" data-path="linear-regression.html"><a href="linear-regression.html#section-86"><i class="fa fa-check"></i><b>3.133</b> </a></li>
<li class="chapter" data-level="3.134" data-path="linear-regression.html"><a href="linear-regression.html#call-6"><i class="fa fa-check"></i><b>3.134</b> Call:</a></li>
<li class="chapter" data-level="3.135" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-familiarity-writtenfrequency-lengthinletters"><i class="fa fa-check"></i><b>3.135</b> lm(formula = RTlexdec ~ Familiarity + WrittenFrequency + LengthInLetters,</a></li>
<li class="chapter" data-level="3.136" data-path="linear-regression.html"><a href="linear-regression.html#data-d"><i class="fa fa-check"></i><b>3.136</b> data = d)</a></li>
<li class="chapter" data-level="3.137" data-path="linear-regression.html"><a href="linear-regression.html#section-87"><i class="fa fa-check"></i><b>3.137</b> </a></li>
<li class="chapter" data-level="3.138" data-path="linear-regression.html"><a href="linear-regression.html#residuals-5"><i class="fa fa-check"></i><b>3.138</b> Residuals:</a></li>
<li class="chapter" data-level="3.139" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-5"><i class="fa fa-check"></i><b>3.139</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.140" data-path="linear-regression.html"><a href="linear-regression.html#section-88"><i class="fa fa-check"></i><b>3.140</b> -0.090416 -0.040823 -0.008442 0.042555 0.094739</a></li>
<li class="chapter" data-level="3.141" data-path="linear-regression.html"><a href="linear-regression.html#section-89"><i class="fa fa-check"></i><b>3.141</b> </a></li>
<li class="chapter" data-level="3.142" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-6"><i class="fa fa-check"></i><b>3.142</b> Coefficients:</a></li>
<li class="chapter" data-level="3.143" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-5"><i class="fa fa-check"></i><b>3.143</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li><a href="linear-regression.html#intercept-6.66953-0.07094-94.013-2e-16-familiarity--0.03333-0.01821--1.831-0.0814-.-writtenfrequency--0.01017-0.01117--0.911-0.3728-lengthinletters--0.00643-0.01410--0.456-0.6530-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.05838-on-21-degrees-of-freedom-multiple-r-squared-0.5429-adjusted-r-squared-0.4776-f-statistic-8.313-on-3-and-21-df-p-value-0.0007782-effects-of-collinearity-diagnosing-collinearity-1-16.0162-is-collinearity-a-problem-assumption-6-observations-measuring-influence-lin-reg-measuring-influence-example---outliers-regression-assumptions-reassurance-model-comparison-lm-model-comparison-nested-model-comparison-example---c2ex1-analysis-of-variance-table-model-1-rtlexdec-writtenfrequency-model-2-rtlexdec-writtenfrequency-agesubject-lengthinletters-res.df-rss-df-sum-of-sq-f-prf-1-4566-91.194-2-4564-35.004-2-56.19-3663.1-2.2e-16"><span class="toc-section-number">3.144</span> (Intercept) 6.66953 0.07094 94.013 &lt;2e-16 <strong><em> ## Familiarity -0.03333 0.01821 -1.831 0.0814 .<br />
## WrittenFrequency -0.01017 0.01117 -0.911 0.3728<br />
## LengthInLetters -0.00643 0.01410 -0.456 0.6530<br />
## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Residual standard error: 0.05838 on 21 degrees of freedom ## Multiple R-squared: 0.5429, Adjusted R-squared: 0.4776 ## F-statistic: 8.313 on 3 and 21 DF, p-value: 0.0007782 #### Effects of collinearity #### Diagnosing collinearity<br />
## [1] 16.0162 #### Is collinearity a problem? ### Assumption 6: Observations ### Measuring influence {#lin-reg-measuring-influence} #### Example {-} ### Outliers ### Regression assumptions: Reassurance ## Model comparison {#lm-model-comparison} ### Nested model comparison #### Example {- #c2ex1} ## Analysis of Variance Table ## ## Model 1: RTlexdec ~ WrittenFrequency ## Model 2: RTlexdec ~ WrittenFrequency + AgeSubject + LengthInLetters ## Res.Df RSS Df Sum of Sq F Pr(&gt;F)<br />
## 1 4566 91.194<br />
## 2 4564 35.004 2 56.19 3663.1 &lt; 2.2e-16 </em></strong></a></li>
<li class="chapter" data-level="3.145" data-path="linear-regression.html"><a href="linear-regression.html#section-90"><i class="fa fa-check"></i><b>3.145</b> —</a></li>
<li class="chapter" data-level="3.146" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-5"><i class="fa fa-check"></i><b>3.146</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a><ul>
<li class="chapter" data-level="3.146.1" data-path="linear-regression.html"><a href="linear-regression.html#non-nested-model-comparison"><i class="fa fa-check"></i><b>3.146.1</b> Non-nested model comparison</a></li>
</ul></li>
<li class="chapter" data-level="3.147" data-path="linear-regression.html"><a href="linear-regression.html#df-aic"><i class="fa fa-check"></i><b>3.147</b> df AIC</a></li>
<li class="chapter" data-level="3.148" data-path="linear-regression.html"><a href="linear-regression.html#m1-3--4908.994"><i class="fa fa-check"></i><b>3.148</b> m1 3 -4908.994</a></li>
<li class="chapter" data-level="3.149" data-path="linear-regression.html"><a href="linear-regression.html#m2-4--9274.590"><i class="fa fa-check"></i><b>3.149</b> m2 4 -9274.590</a></li>
<li class="chapter" data-level="3.150" data-path="linear-regression.html"><a href="linear-regression.html#m3-5--9278.948"><i class="fa fa-check"></i><b>3.150</b> m3 5 -9278.948</a></li>
<li class="chapter" data-level="3.151" data-path="linear-regression.html"><a href="linear-regression.html#m4-4--4909.437"><i class="fa fa-check"></i><b>3.151</b> m4 4 -4909.437</a></li>
<li class="chapter" data-level="3.152" data-path="linear-regression.html"><a href="linear-regression.html#df-bic"><i class="fa fa-check"></i><b>3.152</b> df BIC</a></li>
<li class="chapter" data-level="3.153" data-path="linear-regression.html"><a href="linear-regression.html#m1-3--4889.713"><i class="fa fa-check"></i><b>3.153</b> m1 3 -4889.713</a></li>
<li class="chapter" data-level="3.154" data-path="linear-regression.html"><a href="linear-regression.html#m2-4--9248.883"><i class="fa fa-check"></i><b>3.154</b> m2 4 -9248.883</a></li>
<li class="chapter" data-level="3.155" data-path="linear-regression.html"><a href="linear-regression.html#m3-5--9246.814"><i class="fa fa-check"></i><b>3.155</b> m3 5 -9246.814</a></li>
<li class="chapter" data-level="3.156" data-path="linear-regression.html"><a href="linear-regression.html#m4-4--4883.729"><i class="fa fa-check"></i><b>3.156</b> m4 4 -4883.729</a><ul>
<li class="chapter" data-level="3.156.1" data-path="linear-regression.html"><a href="linear-regression.html#c2varselect"><i class="fa fa-check"></i><b>3.156.1</b> Variable selection</a></li>
</ul></li>
<li class="chapter" data-level="3.157" data-path="linear-regression.html"><a href="linear-regression.html#split-the-english-data-in-half-randomly"><i class="fa fa-check"></i><b>3.157</b> split the English data in half, randomly:</a></li>
<li class="chapter" data-level="3.158" data-path="linear-regression.html"><a href="linear-regression.html#fit-full-model-to-each-half-dataset"><i class="fa fa-check"></i><b>3.158</b> fit full model to each half-dataset</a></li>
<li class="chapter" data-level="3.159" data-path="linear-regression.html"><a href="linear-regression.html#trace0-suppresses-ouput"><i class="fa fa-check"></i><b>3.159</b> trace=0 suppresses ouput</a></li>
<li class="chapter" data-level="3.160" data-path="linear-regression.html"><a href="linear-regression.html#the-two-resulting-models"><i class="fa fa-check"></i><b>3.160</b> the two resulting models</a></li>
<li class="chapter" data-level="3.161" data-path="linear-regression.html"><a href="linear-regression.html#section-91"><i class="fa fa-check"></i><b>3.161</b> </a></li>
<li class="chapter" data-level="3.162" data-path="linear-regression.html"><a href="linear-regression.html#call-7"><i class="fa fa-check"></i><b>3.162</b> Call:</a></li>
<li class="chapter" data-level="3.163" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-writtenfrequency-familiarity-agesubject"><i class="fa fa-check"></i><b>3.163</b> lm(formula = RTlexdec ~ WrittenFrequency + Familiarity + AgeSubject +</a></li>
<li class="chapter" data-level="3.164" data-path="linear-regression.html"><a href="linear-regression.html#lengthinletters-familysize-writtenfrequencyfamiliarity"><i class="fa fa-check"></i><b>3.164</b> LengthInLetters + FamilySize + WrittenFrequency:Familiarity +</a></li>
<li class="chapter" data-level="3.165" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyagesubject-writtenfrequencylengthinletters"><i class="fa fa-check"></i><b>3.165</b> WrittenFrequency:AgeSubject + WrittenFrequency:LengthInLetters +</a></li>
<li class="chapter" data-level="3.166" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyfamilysize-familiarityagesubject-familiaritylengthinletters"><i class="fa fa-check"></i><b>3.166</b> WrittenFrequency:FamilySize + Familiarity:AgeSubject + Familiarity:LengthInLetters +</a></li>
<li class="chapter" data-level="3.167" data-path="linear-regression.html"><a href="linear-regression.html#familiarityfamilysize-agesubjectlengthinletters-lengthinlettersfamilysize"><i class="fa fa-check"></i><b>3.167</b> Familiarity:FamilySize + AgeSubject:LengthInLetters + LengthInLetters:FamilySize +</a></li>
<li class="chapter" data-level="3.168" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyfamiliarityagesubject-writtenfrequencyagesubjectlengthinletters"><i class="fa fa-check"></i><b>3.168</b> WrittenFrequency:Familiarity:AgeSubject + WrittenFrequency:AgeSubject:LengthInLetters,</a></li>
<li class="chapter" data-level="3.169" data-path="linear-regression.html"><a href="linear-regression.html#data-english.1"><i class="fa fa-check"></i><b>3.169</b> data = english.1)</a></li>
<li class="chapter" data-level="3.170" data-path="linear-regression.html"><a href="linear-regression.html#section-92"><i class="fa fa-check"></i><b>3.170</b> </a></li>
<li class="chapter" data-level="3.171" data-path="linear-regression.html"><a href="linear-regression.html#residuals-6"><i class="fa fa-check"></i><b>3.171</b> Residuals:</a></li>
<li class="chapter" data-level="3.172" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-6"><i class="fa fa-check"></i><b>3.172</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.173" data-path="linear-regression.html"><a href="linear-regression.html#section-93"><i class="fa fa-check"></i><b>3.173</b> -0.42008 -0.05175 -0.00326 0.04572 0.37444</a></li>
<li class="chapter" data-level="3.174" data-path="linear-regression.html"><a href="linear-regression.html#section-94"><i class="fa fa-check"></i><b>3.174</b> </a></li>
<li class="chapter" data-level="3.175" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-7"><i class="fa fa-check"></i><b>3.175</b> Coefficients:</a></li>
<li class="chapter" data-level="3.176" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error"><i class="fa fa-check"></i><b>3.176</b> Estimate Std. Error</a></li>
<li class="chapter" data-level="3.177" data-path="linear-regression.html"><a href="linear-regression.html#intercept-7.189260-0.045538"><i class="fa fa-check"></i><b>3.177</b> (Intercept) 7.189260 0.045538</a></li>
<li class="chapter" data-level="3.178" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequency--0.084197-0.011610"><i class="fa fa-check"></i><b>3.178</b> WrittenFrequency -0.084197 0.011610</a></li>
<li class="chapter" data-level="3.179" data-path="linear-regression.html"><a href="linear-regression.html#familiarity--0.058426-0.014137"><i class="fa fa-check"></i><b>3.179</b> Familiarity -0.058426 0.014137</a></li>
<li class="chapter" data-level="3.180" data-path="linear-regression.html"><a href="linear-regression.html#agesubjectyoung--0.413999-0.058362"><i class="fa fa-check"></i><b>3.180</b> AgeSubjectyoung -0.413999 0.058362</a></li>
<li class="chapter" data-level="3.181" data-path="linear-regression.html"><a href="linear-regression.html#lengthinletters--0.004709-0.008692"><i class="fa fa-check"></i><b>3.181</b> LengthInLetters -0.004709 0.008692</a></li>
<li class="chapter" data-level="3.182" data-path="linear-regression.html"><a href="linear-regression.html#familysize--0.112072-0.018225"><i class="fa fa-check"></i><b>3.182</b> FamilySize -0.112072 0.018225</a></li>
<li class="chapter" data-level="3.183" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyfamiliarity-0.008855-0.001203"><i class="fa fa-check"></i><b>3.183</b> WrittenFrequency:Familiarity 0.008855 0.001203</a></li>
<li class="chapter" data-level="3.184" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyagesubjectyoung-0.045885-0.011738"><i class="fa fa-check"></i><b>3.184</b> WrittenFrequency:AgeSubjectyoung 0.045885 0.011738</a></li>
<li class="chapter" data-level="3.185" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencylengthinletters-0.004581-0.002131"><i class="fa fa-check"></i><b>3.185</b> WrittenFrequency:LengthInLetters 0.004581 0.002131</a></li>
<li class="chapter" data-level="3.186" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyfamilysize-0.005662-0.001863"><i class="fa fa-check"></i><b>3.186</b> WrittenFrequency:FamilySize 0.005662 0.001863</a></li>
<li class="chapter" data-level="3.187" data-path="linear-regression.html"><a href="linear-regression.html#familiarityagesubjectyoung-0.030455-0.008445"><i class="fa fa-check"></i><b>3.187</b> Familiarity:AgeSubjectyoung 0.030455 0.008445</a></li>
<li class="chapter" data-level="3.188" data-path="linear-regression.html"><a href="linear-regression.html#familiaritylengthinletters--0.006493-0.002830"><i class="fa fa-check"></i><b>3.188</b> Familiarity:LengthInLetters -0.006493 0.002830</a></li>
<li class="chapter" data-level="3.189" data-path="linear-regression.html"><a href="linear-regression.html#familiarityfamilysize-0.007705-0.003262"><i class="fa fa-check"></i><b>3.189</b> Familiarity:FamilySize 0.007705 0.003262</a></li>
<li class="chapter" data-level="3.190" data-path="linear-regression.html"><a href="linear-regression.html#agesubjectyounglengthinletters-0.013042-0.011006"><i class="fa fa-check"></i><b>3.190</b> AgeSubjectyoung:LengthInLetters 0.013042 0.011006</a></li>
<li class="chapter" data-level="3.191" data-path="linear-regression.html"><a href="linear-regression.html#lengthinlettersfamilysize-0.006179-0.003240"><i class="fa fa-check"></i><b>3.191</b> LengthInLetters:FamilySize 0.006179 0.003240</a></li>
<li class="chapter" data-level="3.192" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyfamiliarityagesubjectyoung--0.006894-0.001396"><i class="fa fa-check"></i><b>3.192</b> WrittenFrequency:Familiarity:AgeSubjectyoung -0.006894 0.001396</a></li>
<li class="chapter" data-level="3.193" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequencyagesubjectyounglengthinletters--0.003181-0.002059"><i class="fa fa-check"></i><b>3.193</b> WrittenFrequency:AgeSubjectyoung:LengthInLetters -0.003181 0.002059</a></li>
<li class="chapter" data-level="3.194" data-path="linear-regression.html"><a href="linear-regression.html#t-value-prt"><i class="fa fa-check"></i><b>3.194</b> t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.195" data-path="linear-regression.html"><a href="linear-regression.html#intercept-157.875-2e-16-writtenfrequency--7.252-5.61e-13"><i class="fa fa-check"></i><b>3.195</b> (Intercept) 157.875 &lt; 2e-16 <strong><em> ## WrittenFrequency -7.252 5.61e-13 </em></strong></a></li>
<li class="chapter" data-level="3.196" data-path="linear-regression.html"><a href="linear-regression.html#familiarity--4.133-3.71e-05-agesubjectyoung--7.094-1.74e-12"><i class="fa fa-check"></i><b>3.196</b> Familiarity -4.133 3.71e-05 <strong><em> ## AgeSubjectyoung -7.094 1.74e-12 </em></strong></a></li>
<li class="chapter" data-level="3.197" data-path="linear-regression.html"><a href="linear-regression.html#lengthinletters--0.542-0.588063"><i class="fa fa-check"></i><b>3.197</b> LengthInLetters -0.542 0.588063</a></li>
<li class="chapter" data-level="3.198" data-path="linear-regression.html"><a href="linear-regression.html#familysize--6.149-9.17e-10-writtenfrequencyfamiliarity-7.360-2.56e-13"><i class="fa fa-check"></i><b>3.198</b> FamilySize -6.149 9.17e-10 <strong><em> ## WrittenFrequency:Familiarity 7.360 2.56e-13 </em></strong></a></li>
<li><a href="linear-regression.html#writtenfrequencyagesubjectyoung-3.909-9.53e-05-writtenfrequencylengthinletters-2.150-0.031699-writtenfrequencyfamilysize-3.039-0.002405"><span class="toc-section-number">3.199</span> WrittenFrequency:AgeSubjectyoung 3.909 9.53e-05 <strong><em> ## WrittenFrequency:LengthInLetters 2.150 0.031699 </em><br />
## WrittenFrequency:FamilySize 3.039 0.002405 </strong></a></li>
<li><a href="linear-regression.html#familiarityagesubjectyoung-3.606-0.000317-familiaritylengthinletters--2.295-0.021842-familiarityfamilysize-2.362-0.018245-agesubjectyounglengthinletters-1.185-0.236150-lengthinlettersfamilysize-1.907-0.056609-.-writtenfrequencyfamiliarityagesubjectyoung--4.940-8.39e-07-writtenfrequencyagesubjectyounglengthinletters--1.545-0.122548-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.07727-on-2267-degrees-of-freedom-multiple-r-squared-0.755-adjusted-r-squared-0.7533-f-statistic-436.6-on-16-and-2267-df-p-value-2.2e-16-call-lmformula-rtlexdec-writtenfrequency-familiarity-agesubject-lengthinletters-familysize-writtenfrequencyfamiliarity-writtenfrequencylengthinletters-writtenfrequencyfamilysize-familiarityagesubject-familiaritylengthinletters-familiarityfamilysize-lengthinlettersfamilysize-writtenfrequencylengthinlettersfamilysize-data-english.2-residuals-min-1q-median-3q-max--0.30263--0.05327--0.00526-0.04654-0.50932-coefficients-estimate-std.-error-t-value-intercept-7.0214673-0.0616493-113.894-writtenfrequency--0.0338445-0.0137689--2.458-familiarity--0.0768169-0.0139772--5.496-agesubjectyoung--0.2047469-0.0113464--18.045-lengthinletters-0.0228065-0.0137176-1.663-familysize--0.0362279-0.0365663--0.991-writtenfrequencyfamiliarity-0.0072404-0.0009183-7.884-writtenfrequencylengthinletters--0.0024614-0.0029950--0.822-writtenfrequencyfamilysize--0.0096833-0.0055442--1.747-familiarityagesubjectyoung--0.0042687-0.0028607--1.492-familiaritylengthinletters--0.0044449-0.0028657--1.551-familiarityfamilysize-0.0137811-0.0031320-4.400-lengthinlettersfamilysize--0.0059273-0.0082370--0.720-writtenfrequencylengthinlettersfamilysize-0.0020024-0.0012937-1.548-prt-intercept-2e-16-writtenfrequency-0.0140-familiarity-4.32e-08-agesubjectyoung-2e-16-lengthinletters-0.0965-.-familysize-0.3219-writtenfrequencyfamiliarity-4.87e-15-writtenfrequencylengthinletters-0.4113-writtenfrequencyfamilysize-0.0808-.-familiarityagesubjectyoung-0.1358-familiaritylengthinletters-0.1210-familiarityfamilysize-1.13e-05-lengthinlettersfamilysize-0.4718-writtenfrequencylengthinlettersfamilysize-0.1218-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.08024-on-2270-degrees-of-freedom-multiple-r-squared-0.7444-adjusted-r-squared-0.7429-f-statistic-508.4-on-13-and-2270-df-p-value-2.2e-16-method-3-gelman2007data-exercise-phrase-medial-devoicing-in-european-french---c2ex5-analysis-of-variance-table-model-1-syldur-speechrate-c1-v2-model-2-syldur-speechrate-c1-v2-func-model-3-syldur-speechrate-c1-v2-func-res.df-rss-df-sum-of-sq-f-prf-1-529-528092-2-528-518990-1-9102.4-9.3121-0.002392"><span class="toc-section-number">3.200</span> Familiarity:AgeSubjectyoung 3.606 0.000317 <strong><em> ## Familiarity:LengthInLetters -2.295 0.021842 </em><br />
## Familiarity:FamilySize 2.362 0.018245 *<br />
## AgeSubjectyoung:LengthInLetters 1.185 0.236150<br />
## LengthInLetters:FamilySize 1.907 0.056609 .<br />
## WrittenFrequency:Familiarity:AgeSubjectyoung -4.940 8.39e-07 </strong><em> ## WrittenFrequency:AgeSubjectyoung:LengthInLetters -1.545 0.122548<br />
## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Residual standard error: 0.07727 on 2267 degrees of freedom ## Multiple R-squared: 0.755, Adjusted R-squared: 0.7533 ## F-statistic: 436.6 on 16 and 2267 DF, p-value: &lt; 2.2e-16 ## ## Call: ## lm(formula = RTlexdec ~ WrittenFrequency + Familiarity + AgeSubject + ## LengthInLetters + FamilySize + WrittenFrequency:Familiarity + ## WrittenFrequency:LengthInLetters + WrittenFrequency:FamilySize + ## Familiarity:AgeSubject + Familiarity:LengthInLetters + Familiarity:FamilySize + ## LengthInLetters:FamilySize + WrittenFrequency:LengthInLetters:FamilySize, ## data = english.2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.30263 -0.05327 -0.00526 0.04654 0.50932 ## ## Coefficients: ## Estimate Std. Error t value ## (Intercept) 7.0214673 0.0616493 113.894 ## WrittenFrequency -0.0338445 0.0137689 -2.458 ## Familiarity -0.0768169 0.0139772 -5.496 ## AgeSubjectyoung -0.2047469 0.0113464 -18.045 ## LengthInLetters 0.0228065 0.0137176 1.663 ## FamilySize -0.0362279 0.0365663 -0.991 ## WrittenFrequency:Familiarity 0.0072404 0.0009183 7.884 ## WrittenFrequency:LengthInLetters -0.0024614 0.0029950 -0.822 ## WrittenFrequency:FamilySize -0.0096833 0.0055442 -1.747 ## Familiarity:AgeSubjectyoung -0.0042687 0.0028607 -1.492 ## Familiarity:LengthInLetters -0.0044449 0.0028657 -1.551 ## Familiarity:FamilySize 0.0137811 0.0031320 4.400 ## LengthInLetters:FamilySize -0.0059273 0.0082370 -0.720 ## WrittenFrequency:LengthInLetters:FamilySize 0.0020024 0.0012937 1.548 ## Pr(&gt;|t|)<br />
## (Intercept) &lt; 2e-16 </em><strong> ## WrittenFrequency 0.0140 *<br />
## Familiarity 4.32e-08 </strong><em> ## AgeSubjectyoung &lt; 2e-16 </em><strong> ## LengthInLetters 0.0965 .<br />
## FamilySize 0.3219<br />
## WrittenFrequency:Familiarity 4.87e-15 </strong><em> ## WrittenFrequency:LengthInLetters 0.4113<br />
## WrittenFrequency:FamilySize 0.0808 .<br />
## Familiarity:AgeSubjectyoung 0.1358<br />
## Familiarity:LengthInLetters 0.1210<br />
## Familiarity:FamilySize 1.13e-05 </em><strong> ## LengthInLetters:FamilySize 0.4718<br />
## WrittenFrequency:LengthInLetters:FamilySize 0.1218<br />
## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Residual standard error: 0.08024 on 2270 degrees of freedom ## Multiple R-squared: 0.7444, Adjusted R-squared: 0.7429 ## F-statistic: 508.4 on 13 and 2270 DF, p-value: &lt; 2.2e-16 #### Method 3: <span class="citation">Gelman &amp; Hill (<a href="#ref-gelman2007data">2007</a>)</span> #### Exercise: Phrase medial devoicing in European French {- #c2ex5} ## Analysis of Variance Table ## ## Model 1: syldur ~ (speechrate + c1 + v)^2 ## Model 2: syldur ~ (speechrate + c1 + v)^2 + func ## Model 3: syldur ~ (speechrate + c1 + v)^2 * func ## Res.Df RSS Df Sum of Sq F Pr(&gt;F)<br />
## 1 529 528092<br />
## 2 528 518990 1 9102.4 9.3121 0.002392 </strong></a></li>
<li class="chapter" data-level="3.201" data-path="linear-regression.html"><a href="linear-regression.html#section-95"><i class="fa fa-check"></i><b>3.201</b> 3 523 511219 5 7770.7 1.5900 0.161123</a></li>
<li class="chapter" data-level="3.202" data-path="linear-regression.html"><a href="linear-regression.html#section-96"><i class="fa fa-check"></i><b>3.202</b> —</a></li>
<li class="chapter" data-level="3.203" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-6"><i class="fa fa-check"></i><b>3.203</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="3.204" data-path="linear-regression.html"><a href="linear-regression.html#section-97"><i class="fa fa-check"></i><b>3.204</b> </a></li>
<li class="chapter" data-level="3.205" data-path="linear-regression.html"><a href="linear-regression.html#call-8"><i class="fa fa-check"></i><b>3.205</b> Call:</a></li>
<li class="chapter" data-level="3.206" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-syldur-speechrate-c1-v2-func-data-df"><i class="fa fa-check"></i><b>3.206</b> lm(formula = syldur ~ (speechrate + c1 + v)^2 + func, data = df)</a></li>
<li class="chapter" data-level="3.207" data-path="linear-regression.html"><a href="linear-regression.html#section-98"><i class="fa fa-check"></i><b>3.207</b> </a></li>
<li class="chapter" data-level="3.208" data-path="linear-regression.html"><a href="linear-regression.html#residuals-7"><i class="fa fa-check"></i><b>3.208</b> Residuals:</a></li>
<li class="chapter" data-level="3.209" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-7"><i class="fa fa-check"></i><b>3.209</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.210" data-path="linear-regression.html"><a href="linear-regression.html#section-99"><i class="fa fa-check"></i><b>3.210</b> -130.682 -21.233 0.304 20.544 103.960</a></li>
<li class="chapter" data-level="3.211" data-path="linear-regression.html"><a href="linear-regression.html#section-100"><i class="fa fa-check"></i><b>3.211</b> </a></li>
<li class="chapter" data-level="3.212" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-1-not-defined-because-of-singularities"><i class="fa fa-check"></i><b>3.212</b> Coefficients: (1 not defined because of singularities)</a></li>
<li class="chapter" data-level="3.213" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-6"><i class="fa fa-check"></i><b>3.213</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.214" data-path="linear-regression.html"><a href="linear-regression.html#intercept-247.5718-23.8023-10.401-2e-16-speechrate--15.6166-3.2983--4.735-2.82e-06"><i class="fa fa-check"></i><b>3.214</b> (Intercept) 247.5718 23.8023 10.401 &lt; 2e-16 <strong><em> ## speechrate -15.6166 3.2983 -4.735 2.82e-06 </em></strong></a></li>
<li><a href="linear-regression.html#c1k--89.2652-26.6617--3.348-0.000872-c1p--67.4682-39.4741--1.709-0.088006-.-c1s--27.7955-26.1708--1.062-0.288683-c1t--68.6392-27.3605--2.509-0.012416-vu-4.6582-31.5829-0.147-0.882802-vy-16.2882-20.2343-0.805-0.421194-funcf--13.8005-4.5350--3.043-0.002458"><span class="toc-section-number">3.215</span> c1k -89.2652 26.6617 -3.348 0.000872 <strong><em> ## c1p -67.4682 39.4741 -1.709 0.088006 .<br />
## c1s -27.7955 26.1708 -1.062 0.288683<br />
## c1t -68.6392 27.3605 -2.509 0.012416 </em><br />
## vu 4.6582 31.5829 0.147 0.882802<br />
## vy 16.2882 20.2343 0.805 0.421194<br />
## funcf -13.8005 4.5350 -3.043 0.002458 </strong></a></li>
<li><a href="linear-regression.html#speechratec1k-9.5259-3.7368-2.549-0.011077-speechratec1p-9.2280-5.8037-1.590-0.112428"><span class="toc-section-number">3.216</span> speechrate:c1k 9.5259 3.7368 2.549 0.011077 *<br />
## speechrate:c1p 9.2280 5.8037 1.590 0.112428</a></li>
<li class="chapter" data-level="3.217" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1s-4.4121-3.5902-1.229-0.219637"><i class="fa fa-check"></i><b>3.217</b> speechrate:c1s 4.4121 3.5902 1.229 0.219637</a></li>
<li><a href="linear-regression.html#speechratec1t-7.5638-3.7154-2.036-0.042268-speechratevu--0.6849-3.9631--0.173-0.862851"><span class="toc-section-number">3.218</span> speechrate:c1t 7.5638 3.7154 2.036 0.042268 *<br />
## speechrate:vu -0.6849 3.9631 -0.173 0.862851</a></li>
<li class="chapter" data-level="3.219" data-path="linear-regression.html"><a href="linear-regression.html#speechratevy--1.6412-2.6474--0.620-0.535579"><i class="fa fa-check"></i><b>3.219</b> speechrate:vy -1.6412 2.6474 -0.620 0.535579</a></li>
<li class="chapter" data-level="3.220" data-path="linear-regression.html"><a href="linear-regression.html#c1kvu-19.8107-22.1307-0.895-0.371104"><i class="fa fa-check"></i><b>3.220</b> c1k:vu 19.8107 22.1307 0.895 0.371104</a></li>
<li class="chapter" data-level="3.221" data-path="linear-regression.html"><a href="linear-regression.html#c1pvu--1.3369-25.6737--0.052-0.958489"><i class="fa fa-check"></i><b>3.221</b> c1p:vu -1.3369 25.6737 -0.052 0.958489</a></li>
<li class="chapter" data-level="3.222" data-path="linear-regression.html"><a href="linear-regression.html#c1svu-0.9348-22.3409-0.042-0.966639"><i class="fa fa-check"></i><b>3.222</b> c1s:vu 0.9348 22.3409 0.042 0.966639</a></li>
<li class="chapter" data-level="3.223" data-path="linear-regression.html"><a href="linear-regression.html#c1tvu-na-na-na-na"><i class="fa fa-check"></i><b>3.223</b> c1t:vu NA NA NA NA</a></li>
<li class="chapter" data-level="3.224" data-path="linear-regression.html"><a href="linear-regression.html#c1kvy--3.1728-13.8966--0.228-0.819491"><i class="fa fa-check"></i><b>3.224</b> c1k:vy -3.1728 13.8966 -0.228 0.819491</a></li>
<li class="chapter" data-level="3.225" data-path="linear-regression.html"><a href="linear-regression.html#c1pvy--9.7528-15.2713--0.639-0.523338"><i class="fa fa-check"></i><b>3.225</b> c1p:vy -9.7528 15.2713 -0.639 0.523338</a></li>
<li class="chapter" data-level="3.226" data-path="linear-regression.html"><a href="linear-regression.html#c1svy--18.2987-11.6317--1.573-0.116279"><i class="fa fa-check"></i><b>3.226</b> c1s:vy -18.2987 11.6317 -1.573 0.116279</a></li>
<li class="chapter" data-level="3.227" data-path="linear-regression.html"><a href="linear-regression.html#c1tvy--5.4756-11.9582--0.458-0.647219"><i class="fa fa-check"></i><b>3.227</b> c1t:vy -5.4756 11.9582 -0.458 0.647219</a></li>
<li class="chapter" data-level="3.228" data-path="linear-regression.html"><a href="linear-regression.html#section-101"><i class="fa fa-check"></i><b>3.228</b> —</a></li>
<li class="chapter" data-level="3.229" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-7"><i class="fa fa-check"></i><b>3.229</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="3.230" data-path="linear-regression.html"><a href="linear-regression.html#section-102"><i class="fa fa-check"></i><b>3.230</b> </a></li>
<li class="chapter" data-level="3.231" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-31.35-on-528-degrees-of-freedom"><i class="fa fa-check"></i><b>3.231</b> Residual standard error: 31.35 on 528 degrees of freedom</a></li>
<li class="chapter" data-level="3.232" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.3012-adjusted-r-squared-0.2734"><i class="fa fa-check"></i><b>3.232</b> Multiple R-squared: 0.3012, Adjusted R-squared: 0.2734</a></li>
<li class="chapter" data-level="3.233" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-10.84-on-21-and-528-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.233</b> F-statistic: 10.84 on 21 and 528 DF, p-value: &lt; 2.2e-16</a></li>
<li class="chapter" data-level="3.234" data-path="linear-regression.html"><a href="linear-regression.html#section-103"><i class="fa fa-check"></i><b>3.234</b> </a></li>
<li class="chapter" data-level="3.235" data-path="linear-regression.html"><a href="linear-regression.html#call-9"><i class="fa fa-check"></i><b>3.235</b> Call:</a></li>
<li class="chapter" data-level="3.236" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-syldur-speechrate-c1-func-speechratec1"><i class="fa fa-check"></i><b>3.236</b> lm(formula = syldur ~ speechrate + c1 + func + speechrate:c1 +</a></li>
<li class="chapter" data-level="3.237" data-path="linear-regression.html"><a href="linear-regression.html#c1func-data-df"><i class="fa fa-check"></i><b>3.237</b> c1:func, data = df)</a></li>
<li class="chapter" data-level="3.238" data-path="linear-regression.html"><a href="linear-regression.html#section-104"><i class="fa fa-check"></i><b>3.238</b> </a></li>
<li class="chapter" data-level="3.239" data-path="linear-regression.html"><a href="linear-regression.html#residuals-8"><i class="fa fa-check"></i><b>3.239</b> Residuals:</a></li>
<li class="chapter" data-level="3.240" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-8"><i class="fa fa-check"></i><b>3.240</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.241" data-path="linear-regression.html"><a href="linear-regression.html#section-105"><i class="fa fa-check"></i><b>3.241</b> -129.449 -19.780 0.762 21.343 104.048</a></li>
<li class="chapter" data-level="3.242" data-path="linear-regression.html"><a href="linear-regression.html#section-106"><i class="fa fa-check"></i><b>3.242</b> </a></li>
<li class="chapter" data-level="3.243" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-2-not-defined-because-of-singularities"><i class="fa fa-check"></i><b>3.243</b> Coefficients: (2 not defined because of singularities)</a></li>
<li class="chapter" data-level="3.244" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-7"><i class="fa fa-check"></i><b>3.244</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.245" data-path="linear-regression.html"><a href="linear-regression.html#intercept-255.813-20.798-12.300-2e-16-speechrate--16.508-2.991--5.520-5.3e-08"><i class="fa fa-check"></i><b>3.245</b> (Intercept) 255.813 20.798 12.300 &lt; 2e-16 <strong><em> ## speechrate -16.508 2.991 -5.520 5.3e-08 </em></strong></a></li>
<li><a href="linear-regression.html#c1k--87.803-25.813--3.401-0.000720-c1p--71.475-37.858--1.888-0.059566-.-c1s--41.730-23.963--1.741-0.082180-.-c1t--64.292-24.776--2.595-0.009719-funcf--21.398-5.558--3.850-0.000132-speechratec1k-10.350-3.559-2.908-0.003785"><span class="toc-section-number">3.246</span> c1k -87.803 25.813 -3.401 0.000720 <em><strong> ## c1p -71.475 37.858 -1.888 0.059566 .<br />
## c1s -41.730 23.963 -1.741 0.082180 .<br />
## c1t -64.292 24.776 -2.595 0.009719 </strong> ## funcf -21.398 5.558 -3.850 0.000132 </em><strong> ## speechrate:c1k 10.350 3.559 2.908 0.003785 </strong></a></li>
<li class="chapter" data-level="3.247" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1p-9.105-5.564-1.637-0.102310"><i class="fa fa-check"></i><b>3.247</b> speechrate:c1p 9.105 5.564 1.637 0.102310</a></li>
<li class="chapter" data-level="3.248" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1s-5.058-3.422-1.478-0.139894"><i class="fa fa-check"></i><b>3.248</b> speechrate:c1s 5.058 3.422 1.478 0.139894</a></li>
<li><a href="linear-regression.html#speechratec1t-7.322-3.498-2.093-0.036832-c1kfuncf--1.833-8.565--0.214-0.830655"><span class="toc-section-number">3.249</span> speechrate:c1t 7.322 3.498 2.093 0.036832 *<br />
## c1k:funcf -1.833 8.565 -0.214 0.830655</a></li>
<li class="chapter" data-level="3.250" data-path="linear-regression.html"><a href="linear-regression.html#c1pfuncf-na-na-na-na"><i class="fa fa-check"></i><b>3.250</b> c1p:funcf NA NA NA NA</a></li>
<li><a href="linear-regression.html#c1sfuncf-17.373-7.218-2.407-0.016427-c1tfuncf-na-na-na-na"><span class="toc-section-number">3.251</span> c1s:funcf 17.373 7.218 2.407 0.016427 *<br />
## c1t:funcf NA NA NA NA</a></li>
<li class="chapter" data-level="3.252" data-path="linear-regression.html"><a href="linear-regression.html#section-107"><i class="fa fa-check"></i><b>3.252</b> —</a></li>
<li class="chapter" data-level="3.253" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-8"><i class="fa fa-check"></i><b>3.253</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="3.254" data-path="linear-regression.html"><a href="linear-regression.html#section-108"><i class="fa fa-check"></i><b>3.254</b> </a></li>
<li class="chapter" data-level="3.255" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-31.14-on-537-degrees-of-freedom"><i class="fa fa-check"></i><b>3.255</b> Residual standard error: 31.14 on 537 degrees of freedom</a></li>
<li class="chapter" data-level="3.256" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.2987-adjusted-r-squared-0.283"><i class="fa fa-check"></i><b>3.256</b> Multiple R-squared: 0.2987, Adjusted R-squared: 0.283</a></li>
<li class="chapter" data-level="3.257" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-19.06-on-12-and-537-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.257</b> F-statistic: 19.06 on 12 and 537 DF, p-value: &lt; 2.2e-16</a></li>
<li class="chapter" data-level="3.258" data-path="linear-regression.html"><a href="linear-regression.html#section-109"><i class="fa fa-check"></i><b>3.258</b> </a></li>
<li class="chapter" data-level="3.259" data-path="linear-regression.html"><a href="linear-regression.html#call-10"><i class="fa fa-check"></i><b>3.259</b> Call:</a></li>
<li class="chapter" data-level="3.260" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-syldur-speechrate-c1-v-func-data-df"><i class="fa fa-check"></i><b>3.260</b> lm(formula = syldur ~ speechrate + c1 + v + func, data = df)</a></li>
<li class="chapter" data-level="3.261" data-path="linear-regression.html"><a href="linear-regression.html#section-110"><i class="fa fa-check"></i><b>3.261</b> </a></li>
<li class="chapter" data-level="3.262" data-path="linear-regression.html"><a href="linear-regression.html#residuals-9"><i class="fa fa-check"></i><b>3.262</b> Residuals:</a></li>
<li class="chapter" data-level="3.263" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-9"><i class="fa fa-check"></i><b>3.263</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.264" data-path="linear-regression.html"><a href="linear-regression.html#section-111"><i class="fa fa-check"></i><b>3.264</b> -131.151 -21.337 0.863 20.419 98.228</a></li>
<li class="chapter" data-level="3.265" data-path="linear-regression.html"><a href="linear-regression.html#section-112"><i class="fa fa-check"></i><b>3.265</b> </a></li>
<li class="chapter" data-level="3.266" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-8"><i class="fa fa-check"></i><b>3.266</b> Coefficients:</a></li>
<li class="chapter" data-level="3.267" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-8"><i class="fa fa-check"></i><b>3.267</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.268" data-path="linear-regression.html"><a href="linear-regression.html#intercept-208.8600-7.9734-26.195-2e-16-speechrate--9.5866-0.9546--10.043-2e-16"><i class="fa fa-check"></i><b>3.268</b> (Intercept) 208.8600 7.9734 26.195 &lt; 2e-16 <strong><em> ## speechrate -9.5866 0.9546 -10.043 &lt; 2e-16 </em></strong></a></li>
<li><a href="linear-regression.html#c1k--26.6525-5.8330--4.569-6.07e-06-c1p--11.0561-6.9893--1.582-0.11426-c1s--2.9871-5.3464--0.559-0.57659-c1t--18.3920-5.8075--3.167-0.00163-vu-12.3446-6.1420-2.010-0.04494"><span class="toc-section-number">3.269</span> c1k -26.6525 5.8330 -4.569 6.07e-06 <em><strong> ## c1p -11.0561 6.9893 -1.582 0.11426<br />
## c1s -2.9871 5.3464 -0.559 0.57659<br />
## c1t -18.3920 5.8075 -3.167 0.00163 </strong> ## vu 12.3446 6.1420 2.010 0.04494 </em></a></li>
<li class="chapter" data-level="3.270" data-path="linear-regression.html"><a href="linear-regression.html#vy--2.0698-3.4933--0.592-0.55377"><i class="fa fa-check"></i><b>3.270</b> vy -2.0698 3.4933 -0.592 0.55377</a></li>
<li><a href="linear-regression.html#funcf--13.3345-3.2684--4.080-5.19e-05-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-31.47-on-541-degrees-of-freedom-multiple-r-squared-0.2787-adjusted-r-squared-0.2681-f-statistic-26.13-on-8-and-541-df-p-value-2.2e-16-call-lmformula-syldur-speechrate-func-c1-v-data-df-residuals-min-1q-median-3q-max--130.275--20.390-0.522-20.501-103.274-coefficients-estimate-std.-error-t-value-prt-intercept-255.785-22.952-11.144-2e-16-speechrate--16.386-3.274--5.005-7.58e-07-funcf--29.289-17.059--1.717-0.08658-.-c1k--86.729-28.237--3.071-0.00224"><span class="toc-section-number">3.271</span> funcf -13.3345 3.2684 -4.080 5.19e-05 <strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Residual standard error: 31.47 on 541 degrees of freedom ## Multiple R-squared: 0.2787, Adjusted R-squared: 0.2681 ## F-statistic: 26.13 on 8 and 541 DF, p-value: &lt; 2.2e-16 ## ## Call: ## lm(formula = syldur ~ speechrate </em> (func + c1 + v), data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -130.275 -20.390 0.522 20.501 103.274 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 255.785 22.952 11.144 &lt; 2e-16 </strong><em> ## speechrate -16.386 3.274 -5.005 7.58e-07 </em><strong> ## funcf -29.289 17.059 -1.717 0.08658 .<br />
## c1k -86.729 28.237 -3.071 0.00224 </strong></a></li>
<li class="chapter" data-level="3.272" data-path="linear-regression.html"><a href="linear-regression.html#c1p--66.594-38.304--1.739-0.08269-."><i class="fa fa-check"></i><b>3.272</b> c1p -66.594 38.304 -1.739 0.08269 .</a></li>
<li class="chapter" data-level="3.273" data-path="linear-regression.html"><a href="linear-regression.html#c1s--29.059-26.392--1.101-0.27137"><i class="fa fa-check"></i><b>3.273</b> c1s -29.059 26.392 -1.101 0.27137</a></li>
<li><a href="linear-regression.html#c1t--60.538-27.829--2.175-0.03004-vu--6.158-27.997--0.220-0.82599"><span class="toc-section-number">3.274</span> c1t -60.538 27.829 -2.175 0.03004 *<br />
## vu -6.158 27.997 -0.220 0.82599</a></li>
<li class="chapter" data-level="3.275" data-path="linear-regression.html"><a href="linear-regression.html#vy-3.596-18.342-0.196-0.84463"><i class="fa fa-check"></i><b>3.275</b> vy 3.596 18.342 0.196 0.84463</a></li>
<li class="chapter" data-level="3.276" data-path="linear-regression.html"><a href="linear-regression.html#speechratefuncf-2.364-2.384-0.992-0.32172"><i class="fa fa-check"></i><b>3.276</b> speechrate:funcf 2.364 2.384 0.992 0.32172</a></li>
<li><a href="linear-regression.html#speechratec1k-8.949-4.009-2.232-0.02604-speechratec1p-8.235-5.645-1.459-0.14522"><span class="toc-section-number">3.277</span> speechrate:c1k 8.949 4.009 2.232 0.02604 *<br />
## speechrate:c1p 8.235 5.645 1.459 0.14522</a></li>
<li class="chapter" data-level="3.278" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1s-3.813-3.775-1.010-0.31291"><i class="fa fa-check"></i><b>3.278</b> speechrate:c1s 3.813 3.775 1.010 0.31291</a></li>
<li class="chapter" data-level="3.279" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1t-6.203-3.965-1.564-0.11829"><i class="fa fa-check"></i><b>3.279</b> speechrate:c1t 6.203 3.965 1.564 0.11829</a></li>
<li class="chapter" data-level="3.280" data-path="linear-regression.html"><a href="linear-regression.html#speechratevu-2.217-3.953-0.561-0.57512"><i class="fa fa-check"></i><b>3.280</b> speechrate:vu 2.217 3.953 0.561 0.57512</a></li>
<li class="chapter" data-level="3.281" data-path="linear-regression.html"><a href="linear-regression.html#speechratevy--1.013-2.585--0.392-0.69529"><i class="fa fa-check"></i><b>3.281</b> speechrate:vy -1.013 2.585 -0.392 0.69529</a></li>
<li class="chapter" data-level="3.282" data-path="linear-regression.html"><a href="linear-regression.html#section-113"><i class="fa fa-check"></i><b>3.282</b> —</a></li>
<li class="chapter" data-level="3.283" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-9"><i class="fa fa-check"></i><b>3.283</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="3.284" data-path="linear-regression.html"><a href="linear-regression.html#section-114"><i class="fa fa-check"></i><b>3.284</b> </a></li>
<li class="chapter" data-level="3.285" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-31.32-on-534-degrees-of-freedom"><i class="fa fa-check"></i><b>3.285</b> Residual standard error: 31.32 on 534 degrees of freedom</a></li>
<li class="chapter" data-level="3.286" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.2945-adjusted-r-squared-0.2747"><i class="fa fa-check"></i><b>3.286</b> Multiple R-squared: 0.2945, Adjusted R-squared: 0.2747</a></li>
<li class="chapter" data-level="3.287" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-14.86-on-15-and-534-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.287</b> F-statistic: 14.86 on 15 and 534 DF, p-value: &lt; 2.2e-16</a></li>
<li class="chapter" data-level="3.288" data-path="linear-regression.html"><a href="linear-regression.html#section-115"><i class="fa fa-check"></i><b>3.288</b> </a></li>
<li class="chapter" data-level="3.289" data-path="linear-regression.html"><a href="linear-regression.html#call-11"><i class="fa fa-check"></i><b>3.289</b> Call:</a></li>
<li class="chapter" data-level="3.290" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-syldur-func-speechrate-c1-v-data-df"><i class="fa fa-check"></i><b>3.290</b> lm(formula = syldur ~ func * (speechrate + c1 + v), data = df)</a></li>
<li class="chapter" data-level="3.291" data-path="linear-regression.html"><a href="linear-regression.html#section-116"><i class="fa fa-check"></i><b>3.291</b> </a></li>
<li class="chapter" data-level="3.292" data-path="linear-regression.html"><a href="linear-regression.html#residuals-10"><i class="fa fa-check"></i><b>3.292</b> Residuals:</a></li>
<li class="chapter" data-level="3.293" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-10"><i class="fa fa-check"></i><b>3.293</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.294" data-path="linear-regression.html"><a href="linear-regression.html#section-117"><i class="fa fa-check"></i><b>3.294</b> -132.663 -21.550 1.495 18.620 101.766</a></li>
<li class="chapter" data-level="3.295" data-path="linear-regression.html"><a href="linear-regression.html#section-118"><i class="fa fa-check"></i><b>3.295</b> </a></li>
<li class="chapter" data-level="3.296" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-4-not-defined-because-of-singularities"><i class="fa fa-check"></i><b>3.296</b> Coefficients: (4 not defined because of singularities)</a></li>
<li class="chapter" data-level="3.297" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-9"><i class="fa fa-check"></i><b>3.297</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li><a href="linear-regression.html#intercept-223.1977-11.2756-19.795-2e-16-funcf--46.3965-14.9707--3.099-0.00204-speechrate--11.8593-1.4817--8.004-7.47e-15-c1k--18.3159-7.5125--2.438-0.01509-c1p--11.6366-6.9622--1.671-0.09522-.-c1s--7.8271-5.5722--1.405-0.16070-c1t--13.3023-6.4106--2.075-0.03846-vu-11.5966-6.8487-1.693-0.09098-.-vy-0.8120-4.3953-0.185-0.85350-funcfspeechrate-3.4852-1.9453-1.792-0.07376-.-funcfc1k-0.3863-10.7540-0.036-0.97136-funcfc1p-na-na-na-na-funcfc1s-19.3740-8.7143-2.223-0.02661-funcfc1t-na-na-na-na-funcfvu-na-na-na-na-funcfvy-na-na-na-na-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-31.22-on-538-degrees-of-freedom-multiple-r-squared-0.2941-adjusted-r-squared-0.2797-f-statistic-20.38-on-11-and-538-df-p-value-2.2e-16-call-lmformula-syldur-speechrate-c1-func-speechratec1-funcc1-data-df-residuals-min-1q-median-3q-max--129.449--19.780-0.762-21.343-104.048-coefficients-2-not-defined-because-of-singularities-estimate-std.-error-t-value-prt-intercept-255.813-20.798-12.300-2e-16-speechrate--16.508-2.991--5.520-5.3e-08-c1k--87.803-25.813--3.401-0.000720-c1p--71.475-37.858--1.888-0.059566-.-c1s--41.730-23.963--1.741-0.082180-.-c1t--64.292-24.776--2.595-0.009719-funcf--21.398-5.558--3.850-0.000132"><span class="toc-section-number">3.298</span> (Intercept) 223.1977 11.2756 19.795 &lt; 2e-16 <em><strong> ## funcf -46.3965 14.9707 -3.099 0.00204 </strong> ## speechrate -11.8593 1.4817 -8.004 7.47e-15 </em><strong> ## c1k -18.3159 7.5125 -2.438 0.01509 *<br />
## c1p -11.6366 6.9622 -1.671 0.09522 .<br />
## c1s -7.8271 5.5722 -1.405 0.16070<br />
## c1t -13.3023 6.4106 -2.075 0.03846 *<br />
## vu 11.5966 6.8487 1.693 0.09098 .<br />
## vy 0.8120 4.3953 0.185 0.85350<br />
## funcf:speechrate 3.4852 1.9453 1.792 0.07376 .<br />
## funcf:c1k 0.3863 10.7540 0.036 0.97136<br />
## funcf:c1p NA NA NA NA<br />
## funcf:c1s 19.3740 8.7143 2.223 0.02661 *<br />
## funcf:c1t NA NA NA NA<br />
## funcf:vu NA NA NA NA<br />
## funcf:vy NA NA NA NA<br />
## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Residual standard error: 31.22 on 538 degrees of freedom ## Multiple R-squared: 0.2941, Adjusted R-squared: 0.2797 ## F-statistic: 20.38 on 11 and 538 DF, p-value: &lt; 2.2e-16 ## ## Call: ## lm(formula = syldur ~ speechrate + c1 + func + speechrate:c1 + ## func:c1, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -129.449 -19.780 0.762 21.343 104.048 ## ## Coefficients: (2 not defined because of singularities) ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 255.813 20.798 12.300 &lt; 2e-16 </strong><em> ## speechrate -16.508 2.991 -5.520 5.3e-08 </em><strong> ## c1k -87.803 25.813 -3.401 0.000720 </strong><em> ## c1p -71.475 37.858 -1.888 0.059566 .<br />
## c1s -41.730 23.963 -1.741 0.082180 .<br />
## c1t -64.292 24.776 -2.595 0.009719 <strong> ## funcf -21.398 5.558 -3.850 0.000132 </strong></em></a></li>
<li class="chapter" data-level="3.299" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1k-10.350-3.559-2.908-0.003785"><i class="fa fa-check"></i><b>3.299</b> speechrate:c1k 10.350 3.559 2.908 0.003785 **</a></li>
<li class="chapter" data-level="3.300" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1p-9.105-5.564-1.637-0.102310-1"><i class="fa fa-check"></i><b>3.300</b> speechrate:c1p 9.105 5.564 1.637 0.102310</a></li>
<li class="chapter" data-level="3.301" data-path="linear-regression.html"><a href="linear-regression.html#speechratec1s-5.058-3.422-1.478-0.139894-1"><i class="fa fa-check"></i><b>3.301</b> speechrate:c1s 5.058 3.422 1.478 0.139894</a></li>
<li><a href="linear-regression.html#speechratec1t-7.322-3.498-2.093-0.036832-c1kfuncf--1.833-8.565--0.214-0.830655-1"><span class="toc-section-number">3.302</span> speechrate:c1t 7.322 3.498 2.093 0.036832 *<br />
## c1k:funcf -1.833 8.565 -0.214 0.830655</a></li>
<li class="chapter" data-level="3.303" data-path="linear-regression.html"><a href="linear-regression.html#c1pfuncf-na-na-na-na-1"><i class="fa fa-check"></i><b>3.303</b> c1p:funcf NA NA NA NA</a></li>
<li><a href="linear-regression.html#c1sfuncf-17.373-7.218-2.407-0.016427-c1tfuncf-na-na-na-na-1"><span class="toc-section-number">3.304</span> c1s:funcf 17.373 7.218 2.407 0.016427 *<br />
## c1t:funcf NA NA NA NA</a></li>
<li class="chapter" data-level="3.305" data-path="linear-regression.html"><a href="linear-regression.html#section-119"><i class="fa fa-check"></i><b>3.305</b> —</a></li>
<li class="chapter" data-level="3.306" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-10"><i class="fa fa-check"></i><b>3.306</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="3.307" data-path="linear-regression.html"><a href="linear-regression.html#section-120"><i class="fa fa-check"></i><b>3.307</b> </a></li>
<li class="chapter" data-level="3.308" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-31.14-on-537-degrees-of-freedom-1"><i class="fa fa-check"></i><b>3.308</b> Residual standard error: 31.14 on 537 degrees of freedom</a></li>
<li class="chapter" data-level="3.309" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.2987-adjusted-r-squared-0.283-1"><i class="fa fa-check"></i><b>3.309</b> Multiple R-squared: 0.2987, Adjusted R-squared: 0.283</a></li>
<li class="chapter" data-level="3.310" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-19.06-on-12-and-537-df-p-value-2.2e-16-1"><i class="fa fa-check"></i><b>3.310</b> F-statistic: 19.06 on 12 and 537 DF, p-value: &lt; 2.2e-16</a><ul>
<li class="chapter" data-level="3.310.1" data-path="linear-regression.html"><a href="linear-regression.html#interpretability-issues"><i class="fa fa-check"></i><b>3.310.1</b> Interpretability issues</a></li>
</ul></li>
<li class="chapter" data-level="3.311" data-path="linear-regression.html"><a href="linear-regression.html#section-121"><i class="fa fa-check"></i><b>3.311</b> </a></li>
<li class="chapter" data-level="3.312" data-path="linear-regression.html"><a href="linear-regression.html#call-12"><i class="fa fa-check"></i><b>3.312</b> Call:</a></li>
<li class="chapter" data-level="3.313" data-path="linear-regression.html"><a href="linear-regression.html#lmformula-rtlexdec-writtenfrequency-lengthinletters"><i class="fa fa-check"></i><b>3.313</b> lm(formula = RTlexdec ~ WrittenFrequency + LengthInLetters +</a></li>
<li class="chapter" data-level="3.314" data-path="linear-regression.html"><a href="linear-regression.html#agesubject-data-english"><i class="fa fa-check"></i><b>3.314</b> AgeSubject, data = english)</a></li>
<li class="chapter" data-level="3.315" data-path="linear-regression.html"><a href="linear-regression.html#section-122"><i class="fa fa-check"></i><b>3.315</b> </a></li>
<li class="chapter" data-level="3.316" data-path="linear-regression.html"><a href="linear-regression.html#residuals-11"><i class="fa fa-check"></i><b>3.316</b> Residuals:</a></li>
<li class="chapter" data-level="3.317" data-path="linear-regression.html"><a href="linear-regression.html#min-1q-median-3q-max-11"><i class="fa fa-check"></i><b>3.317</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="3.318" data-path="linear-regression.html"><a href="linear-regression.html#section-123"><i class="fa fa-check"></i><b>3.318</b> -0.34438 -0.06041 -0.00695 0.05241 0.45157</a></li>
<li class="chapter" data-level="3.319" data-path="linear-regression.html"><a href="linear-regression.html#section-124"><i class="fa fa-check"></i><b>3.319</b> </a></li>
<li class="chapter" data-level="3.320" data-path="linear-regression.html"><a href="linear-regression.html#coefficients-9"><i class="fa fa-check"></i><b>3.320</b> Coefficients:</a></li>
<li class="chapter" data-level="3.321" data-path="linear-regression.html"><a href="linear-regression.html#estimate-std.-error-t-value-prt-10"><i class="fa fa-check"></i><b>3.321</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="3.322" data-path="linear-regression.html"><a href="linear-regression.html#intercept-6.8293072-0.0079946-854.245-2e-16-writtenfrequency--0.0368919-0.0007045--52.366-2e-16"><i class="fa fa-check"></i><b>3.322</b> (Intercept) 6.8293072 0.0079946 854.245 &lt;2e-16 <strong><em> ## WrittenFrequency -0.0368919 0.0007045 -52.366 &lt;2e-16 </em></strong></a></li>
<li><a href="linear-regression.html#lengthinletters-0.0038897-0.0015428-2.521-0.0117-agesubjectyoung--0.2217215-0.0025915--85.556-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.08758-on-4564-degrees-of-freedom-multiple-r-squared-0.6887-adjusted-r-squared-0.6885-f-statistic-3366-on-3-and-4564-df-p-value-2.2e-16-solutions-example---call-lmformula-rtlexdec-writtenfrequency-lengthinletters-agesubject-data-english-residuals-min-1q-median-3q-max--0.34438--0.06041--0.00695-0.05241-0.45157-coefficients-estimate-std.-error-t-value-prt-intercept-6.8293072-0.0079946-854.245-2e-16"><span class="toc-section-number">3.323</span> LengthInLetters 0.0038897 0.0015428 2.521 0.0117 *<br />
## AgeSubjectyoung -0.2217215 0.0025915 -85.556 &lt;2e-16 <strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Residual standard error: 0.08758 on 4564 degrees of freedom ## Multiple R-squared: 0.6887, Adjusted R-squared: 0.6885 ## F-statistic: 3366 on 3 and 4564 DF, p-value: &lt; 2.2e-16 #### Solutions #### Example {-} ## ## Call: ## lm(formula = RTlexdec ~ WrittenFrequency + LengthInLetters + ## AgeSubject, data = english) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.34438 -0.06041 -0.00695 0.05241 0.45157 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 6.8293072 0.0079946 854.245 &lt;2e-16 </em></strong></a></li>
<li><a href="linear-regression.html#writtenfrequency--0.0368919-0.0007045--52.366-2e-16-lengthinletters-0.0038897-0.0015428-2.521-0.0117-agesubjectyoung--0.2217215-0.0025915--85.556-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.08758-on-4564-degrees-of-freedom-multiple-r-squared-0.6887-adjusted-r-squared-0.6885-f-statistic-3366-on-3-and-4564-df-p-value-2.2e-16-call-lmformula-rtlexdec-writtenfrequency-lengthinletters-agesubject-data-english2-residuals-min-1q-median-3q-max--0.34438--0.06041--0.00695-0.05241-0.45157-coefficients-estimate-std.-error-t-value-prt-intercept-6.550097-0.001296-5055.020-2e-16-writtenfrequency--0.136025-0.002598--52.366-2e-16-lengthinletters-0.006549-0.002598-2.521-0.0117"><span class="toc-section-number">3.324</span> WrittenFrequency -0.0368919 0.0007045 -52.366 &lt;2e-16 <strong><em> ## LengthInLetters 0.0038897 0.0015428 2.521 0.0117 </em><br />
## AgeSubjectyoung -0.2217215 0.0025915 -85.556 &lt;2e-16 </strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Residual standard error: 0.08758 on 4564 degrees of freedom ## Multiple R-squared: 0.6887, Adjusted R-squared: 0.6885 ## F-statistic: 3366 on 3 and 4564 DF, p-value: &lt; 2.2e-16 ## ## Call: ## lm(formula = RTlexdec ~ WrittenFrequency + LengthInLetters + ## AgeSubject, data = english2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.34438 -0.06041 -0.00695 0.05241 0.45157 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 6.550097 0.001296 5055.020 &lt;2e-16 </em><strong> ## WrittenFrequency -0.136025 0.002598 -52.366 &lt;2e-16 </strong><em> ## LengthInLetters 0.006549 0.002598 2.521 0.0117 </em></a></li>
<li><a href="linear-regression.html#agesubject--0.221721-0.002592--85.556-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-0.08758-on-4564-degrees-of-freedom-multiple-r-squared-0.6887-adjusted-r-squared-0.6885-f-statistic-3366-on-3-and-4564-df-p-value-2.2e-16-interim-recipe-building-a-multiple-linear-regression-model-solutions-c2solns-multiple-linear-regression-solutions-regression-equation-1---c2sol1-regression-equation-2---c2sol2-linear-regression-assumptions-solutions-model-comparison-solutions-call-lmformula-rtlexdec-writtenfrequency-agesubject-lengthinletters-data-english-residuals-min-1q-median-3q-max--0.34438--0.06041--0.00695-0.05241-0.45157-coefficients-estimate-std.-error-t-value-prt-intercept-6.8293072-0.0079946-854.245-2e-16"><span class="toc-section-number">3.325</span> AgeSubject -0.221721 0.002592 -85.556 &lt;2e-16 <strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Residual standard error: 0.08758 on 4564 degrees of freedom ## Multiple R-squared: 0.6887, Adjusted R-squared: 0.6885 ## F-statistic: 3366 on 3 and 4564 DF, p-value: &lt; 2.2e-16 ### Interim recipe: Building a multiple linear regression model ## Solutions {#c2solns} ### Multiple linear regression: Solutions #### Regression equation 1 {- #c2sol1} #### Regression equation 2 {- #c2sol2} ### Linear regression assumptions: Solutions ### Model comparison: Solutions ## ## Call: ## lm(formula = RTlexdec ~ WrittenFrequency + AgeSubject + LengthInLetters, ## data = english) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.34438 -0.06041 -0.00695 0.05241 0.45157 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|)<br />
## (Intercept) 6.8293072 0.0079946 854.245 &lt;2e-16 </em></strong></a></li>
<li class="chapter" data-level="3.326" data-path="linear-regression.html"><a href="linear-regression.html#writtenfrequency--0.0368919-0.0007045--52.366-2e-16-agesubjectyoung--0.2217215-0.0025915--85.556-2e-16"><i class="fa fa-check"></i><b>3.326</b> WrittenFrequency -0.0368919 0.0007045 -52.366 &lt;2e-16 <strong><em> ## AgeSubjectyoung -0.2217215 0.0025915 -85.556 &lt;2e-16 </em></strong></a></li>
<li><a href="linear-regression.html#lengthinletters-0.0038897-0.0015428-2.521-0.0117"><span class="toc-section-number">3.327</span> LengthInLetters 0.0038897 0.0015428 2.521 0.0117 *<br />
## —</a></li>
<li class="chapter" data-level="3.328" data-path="linear-regression.html"><a href="linear-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-11"><i class="fa fa-check"></i><b>3.328</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="3.329" data-path="linear-regression.html"><a href="linear-regression.html#section-125"><i class="fa fa-check"></i><b>3.329</b> </a></li>
<li class="chapter" data-level="3.330" data-path="linear-regression.html"><a href="linear-regression.html#residual-standard-error-0.08758-on-4564-degrees-of-freedom"><i class="fa fa-check"></i><b>3.330</b> Residual standard error: 0.08758 on 4564 degrees of freedom</a></li>
<li class="chapter" data-level="3.331" data-path="linear-regression.html"><a href="linear-regression.html#multiple-r-squared-0.6887-adjusted-r-squared-0.6885"><i class="fa fa-check"></i><b>3.331</b> Multiple R-squared: 0.6887, Adjusted R-squared: 0.6885</a></li>
<li class="chapter" data-level="3.332" data-path="linear-regression.html"><a href="linear-regression.html#f-statistic-3366-on-3-and-4564-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>3.332</b> F-statistic: 3366 on 3 and 4564 DF, p-value: &lt; 2.2e-16</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="cda.html"><a href="cda.html"><i class="fa fa-check"></i><b>4</b> Categorical data analysis: Preliminaries</a><ul>
<li class="chapter" data-level="4.1" data-path="cda.html"><a href="cda.html#loads-alternativesmcgillling620.csv-from-osf-project-for-wagner-2016"><i class="fa fa-check"></i><b>4.1</b> loads alternativesMcGillLing620.csv from OSF project for Wagner (2016)</a></li>
<li class="chapter" data-level="4.2" data-path="cda.html"><a href="cda.html#information-structure-and-production-planning"><i class="fa fa-check"></i><b>4.2</b> “Information structure and production planning”</a></li>
<li class="chapter" data-level="4.3" data-path="cda.html"><a href="cda.html#introduction"><i class="fa fa-check"></i><b>4.3</b> Introduction</a><ul>
<li class="chapter" data-level="4.3.1" data-path="cda.html"><a href="cda.html#x2-contingency-tables"><i class="fa fa-check"></i><b>4.3.1</b> 2x2 contingency tables</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="cda.html"><a href="cda.html#warning-package-bindrcpp-was-built-under-r-version-3.4.4"><i class="fa fa-check"></i><b>4.4</b> Warning: package ‘bindrcpp’ was built under R version 3.4.4</a></li>
<li class="chapter" data-level="4.5" data-path="cda.html"><a href="cda.html#context"><i class="fa fa-check"></i><b>4.5</b> context</a></li>
<li class="chapter" data-level="4.6" data-path="cda.html"><a href="cda.html#prominence-alternative-noalternative"><i class="fa fa-check"></i><b>4.6</b> prominence Alternative NoAlternative</a></li>
<li class="chapter" data-level="4.7" data-path="cda.html"><a href="cda.html#adjective-120-55"><i class="fa fa-check"></i><b>4.7</b> Adjective 120 55</a></li>
<li class="chapter" data-level="4.8" data-path="cda.html"><a href="cda.html#noun-85-155"><i class="fa fa-check"></i><b>4.8</b> Noun 85 155</a></li>
<li class="chapter" data-level="4.9" data-path="cda.html"><a href="cda.html#total-number-of-observations"><i class="fa fa-check"></i><b>4.9</b> total number of observations</a></li>
<li class="chapter" data-level="4.10" data-path="cda.html"><a href="cda.html#pcontext-alternative"><i class="fa fa-check"></i><b>4.10</b> P(context = alternative)</a></li>
<li class="chapter" data-level="4.11" data-path="cda.html"><a href="cda.html#pprominence-adjective"><i class="fa fa-check"></i><b>4.11</b> p(prominence = adjective)</a></li>
<li class="chapter" data-level="4.12" data-path="cda.html"><a href="cda.html#print-these-probabilities"><i class="fa fa-check"></i><b>4.12</b> print these probabilities</a></li>
<li class="chapter" data-level="4.13" data-path="cda.html"><a href="cda.html#section-126"><i class="fa fa-check"></i><b>4.13</b> [1] 0.4939759</a></li>
<li class="chapter" data-level="4.14" data-path="cda.html"><a href="cda.html#section-127"><i class="fa fa-check"></i><b>4.14</b> [1] 0.4216867</a><ul>
<li class="chapter" data-level="4.14.1" data-path="cda.html"><a href="cda.html#the-chi-squared-test"><i class="fa fa-check"></i><b>4.14.1</b> The chi-squared test</a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="cda.html"><a href="cda.html#section-128"><i class="fa fa-check"></i><b>4.15</b> </a></li>
<li class="chapter" data-level="4.16" data-path="cda.html"><a href="cda.html#pearsons-chi-squared-test-with-yates-continuity-correction"><i class="fa fa-check"></i><b>4.16</b> Pearson’s Chi-squared test with Yates’ continuity correction</a></li>
<li class="chapter" data-level="4.17" data-path="cda.html"><a href="cda.html#section-129"><i class="fa fa-check"></i><b>4.17</b> </a></li>
<li class="chapter" data-level="4.18" data-path="cda.html"><a href="cda.html#data-tab"><i class="fa fa-check"></i><b>4.18</b> data: tab</a></li>
<li class="chapter" data-level="4.19" data-path="cda.html"><a href="cda.html#x-squared-43.189-df-1-p-value-4.969e-11"><i class="fa fa-check"></i><b>4.19</b> X-squared = 43.189, df = 1, p-value = 4.969e-11</a></li>
<li class="chapter" data-level="4.20" data-path="cda.html"><a href="cda.html#regularity"><i class="fa fa-check"></i><b>4.20</b> Regularity</a></li>
<li class="chapter" data-level="4.21" data-path="cda.html"><a href="cda.html#auxiliary-irregular-regular"><i class="fa fa-check"></i><b>4.21</b> Auxiliary irregular regular</a></li>
<li class="chapter" data-level="4.22" data-path="cda.html"><a href="cda.html#hebben-108-469"><i class="fa fa-check"></i><b>4.22</b> hebben 108 469</a></li>
<li class="chapter" data-level="4.23" data-path="cda.html"><a href="cda.html#zijn-12-8"><i class="fa fa-check"></i><b>4.23</b> zijn 12 8</a></li>
<li class="chapter" data-level="4.24" data-path="cda.html"><a href="cda.html#zijnheb-39-64"><i class="fa fa-check"></i><b>4.24</b> zijnheb 39 64</a></li>
<li class="chapter" data-level="4.25" data-path="cda.html"><a href="cda.html#warning-in-chisq.testxtabsauxiliary-regularity-regularity-chi-"><i class="fa fa-check"></i><b>4.25</b> Warning in chisq.test(xtabs(~Auxiliary + Regularity, regularity)): Chi-</a></li>
<li class="chapter" data-level="4.26" data-path="cda.html"><a href="cda.html#squared-approximation-may-be-incorrect"><i class="fa fa-check"></i><b>4.26</b> squared approximation may be incorrect</a></li>
<li class="chapter" data-level="4.27" data-path="cda.html"><a href="cda.html#section-130"><i class="fa fa-check"></i><b>4.27</b> </a></li>
<li class="chapter" data-level="4.28" data-path="cda.html"><a href="cda.html#pearsons-chi-squared-test"><i class="fa fa-check"></i><b>4.28</b> Pearson’s Chi-squared test</a></li>
<li class="chapter" data-level="4.29" data-path="cda.html"><a href="cda.html#section-131"><i class="fa fa-check"></i><b>4.29</b> </a></li>
<li class="chapter" data-level="4.30" data-path="cda.html"><a href="cda.html#data-xtabsauxiliary-regularity-regularity"><i class="fa fa-check"></i><b>4.30</b> data: xtabs(~Auxiliary + Regularity, regularity)</a></li>
<li class="chapter" data-level="4.31" data-path="cda.html"><a href="cda.html#x-squared-34.555-df-2-p-value-3.136e-08"><i class="fa fa-check"></i><b>4.31</b> X-squared = 34.555, df = 2, p-value = 3.136e-08</a></li>
<li class="chapter" data-level="4.32" data-path="cda.html"><a href="cda.html#section-132"><i class="fa fa-check"></i><b>4.32</b> </a></li>
<li class="chapter" data-level="4.33" data-path="cda.html"><a href="cda.html#pearsons-chi-squared-test-with-simulated-p-value-based-on-2000"><i class="fa fa-check"></i><b>4.33</b> Pearson’s Chi-squared test with simulated p-value (based on 2000</a></li>
<li class="chapter" data-level="4.34" data-path="cda.html"><a href="cda.html#replicates"><i class="fa fa-check"></i><b>4.34</b> replicates)</a></li>
<li class="chapter" data-level="4.35" data-path="cda.html"><a href="cda.html#section-133"><i class="fa fa-check"></i><b>4.35</b> </a></li>
<li class="chapter" data-level="4.36" data-path="cda.html"><a href="cda.html#data-xtabsauxiliary-regularity-regularity-1"><i class="fa fa-check"></i><b>4.36</b> data: xtabs(~Auxiliary + Regularity, regularity)</a></li>
<li class="chapter" data-level="4.37" data-path="cda.html"><a href="cda.html#x-squared-34.555-df-na-p-value-0.0004998"><i class="fa fa-check"></i><b>4.37</b> X-squared = 34.555, df = NA, p-value = 0.0004998</a><ul>
<li class="chapter" data-level="4.37.1" data-path="cda.html"><a href="cda.html#fishers-exact-test"><i class="fa fa-check"></i><b>4.37.1</b> Fisher’s exact test</a></li>
</ul></li>
<li class="chapter" data-level="4.38" data-path="cda.html"><a href="cda.html#regularity-1"><i class="fa fa-check"></i><b>4.38</b> Regularity</a></li>
<li class="chapter" data-level="4.39" data-path="cda.html"><a href="cda.html#auxiliary-irregular-regular-1"><i class="fa fa-check"></i><b>4.39</b> Auxiliary irregular regular</a></li>
<li class="chapter" data-level="4.40" data-path="cda.html"><a href="cda.html#hebben-108-469-1"><i class="fa fa-check"></i><b>4.40</b> hebben 108 469</a></li>
<li class="chapter" data-level="4.41" data-path="cda.html"><a href="cda.html#zijn-12-8-1"><i class="fa fa-check"></i><b>4.41</b> zijn 12 8</a></li>
<li class="chapter" data-level="4.42" data-path="cda.html"><a href="cda.html#zijnheb-39-64-1"><i class="fa fa-check"></i><b>4.42</b> zijnheb 39 64</a></li>
<li class="chapter" data-level="4.43" data-path="cda.html"><a href="cda.html#section-134"><i class="fa fa-check"></i><b>4.43</b> </a></li>
<li class="chapter" data-level="4.44" data-path="cda.html"><a href="cda.html#fishers-exact-test-for-count-data"><i class="fa fa-check"></i><b>4.44</b> Fisher’s Exact Test for Count Data</a></li>
<li class="chapter" data-level="4.45" data-path="cda.html"><a href="cda.html#section-135"><i class="fa fa-check"></i><b>4.45</b> </a></li>
<li class="chapter" data-level="4.46" data-path="cda.html"><a href="cda.html#data-xtabsauxiliary-regularity-regularity-2"><i class="fa fa-check"></i><b>4.46</b> data: xtabs(~Auxiliary + Regularity, regularity)</a></li>
<li class="chapter" data-level="4.47" data-path="cda.html"><a href="cda.html#p-value-1.52e-07"><i class="fa fa-check"></i><b>4.47</b> p-value = 1.52e-07</a></li>
<li class="chapter" data-level="4.48" data-path="cda.html"><a href="cda.html#alternative-hypothesis-two.sided"><i class="fa fa-check"></i><b>4.48</b> alternative hypothesis: two.sided</a></li>
<li class="chapter" data-level="4.49" data-path="cda.html"><a href="cda.html#towards-logistic-regression"><i class="fa fa-check"></i><b>4.49</b> Towards logistic regression</a><ul>
<li class="chapter" data-level="4.49.1" data-path="cda.html"><a href="cda.html#odds"><i class="fa fa-check"></i><b>4.49.1</b> Odds</a></li>
<li class="chapter" data-level="4.49.2" data-path="cda.html"><a href="cda.html#log-odds"><i class="fa fa-check"></i><b>4.49.2</b> Log-odds</a></li>
</ul></li>
<li class="chapter" data-level="4.50" data-path="cda.html"><a href="cda.html#section-136"><i class="fa fa-check"></i><b>4.50</b> [1] 0</a></li>
<li class="chapter" data-level="4.51" data-path="cda.html"><a href="cda.html#section-137"><i class="fa fa-check"></i><b>4.51</b> [1] 0.9946226</a></li>
<li class="chapter" data-level="4.52" data-path="cda.html"><a href="cda.html#section-138"><i class="fa fa-check"></i><b>4.52</b> [1] 1.99243</a></li>
<li class="chapter" data-level="4.53" data-path="cda.html"><a href="cda.html#section-139"><i class="fa fa-check"></i><b>4.53</b> [1] 3.009467</a></li>
<li class="chapter" data-level="4.54" data-path="cda.html"><a href="cda.html#section-140"><i class="fa fa-check"></i><b>4.54</b> [1] 0.01798621</a><ul>
<li class="chapter" data-level="4.54.1" data-path="cda.html"><a href="cda.html#odds-ratios"><i class="fa fa-check"></i><b>4.54.1</b> Odds ratios</a></li>
<li class="chapter" data-level="4.54.2" data-path="cda.html"><a href="cda.html#log-odds-sample-and-population"><i class="fa fa-check"></i><b>4.54.2</b> Log odds: sample and population</a></li>
</ul></li>
<li class="chapter" data-level="4.55" data-path="cda.html"><a href="cda.html#section-141"><i class="fa fa-check"></i><b>4.55</b> [1] 9</a></li>
<li class="chapter" data-level="4.56" data-path="cda.html"><a href="cda.html#section-142"><i class="fa fa-check"></i><b>4.56</b> [1] 2.333333</a></li>
<li class="chapter" data-level="4.57" data-path="cda.html"><a href="cda.html#section-143"><i class="fa fa-check"></i><b>4.57</b> [1] 3.857143</a></li>
<li class="chapter" data-level="4.58" data-path="cda.html"><a href="cda.html#section-144"><i class="fa fa-check"></i><b>4.58</b> [1] 1.349927</a></li>
<li class="chapter" data-level="4.59" data-path="cda.html"><a href="cda.html#cda-other-readings"><i class="fa fa-check"></i><b>4.59</b> Other readings</a></li>
<li class="chapter" data-level="4.60" data-path="cda.html"><a href="cda.html#c3solns"><i class="fa fa-check"></i><b>4.60</b> Solutions</a><ul>
<li class="chapter" data-level="4.60.1" data-path="cda.html"><a href="cda.html#solutions-to-exercise-1"><i class="fa fa-check"></i><b>4.60.1</b> Solutions to Exercise 1:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>5</b> Logistic regression</a><ul>
<li class="chapter" data-level="5.1" data-path="logistic-regression.html"><a href="logistic-regression.html#loads-givennessmcgillling620.csv-from-osf-project-for-wagner-2012-data"><i class="fa fa-check"></i><b>5.1</b> loads givennessMcGillLing620.csv from OSF project for Wagner (2012) data</a></li>
<li class="chapter" data-level="5.2" data-path="logistic-regression.html"><a href="logistic-regression.html#make-standardized-numericcenteredscaled-versions-of-givenness-dataset-predictors"><i class="fa fa-check"></i><b>5.2</b> make standardized (numeric/centered/scaled) versions of ‘givenness’ dataset predictors:</a></li>
<li class="chapter" data-level="5.3" data-path="logistic-regression.html"><a href="logistic-regression.html#simple-logistic-regression"><i class="fa fa-check"></i><b>5.3</b> Simple logistic regression</a><ul>
<li class="chapter" data-level="5.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#log-reg-hyp-test"><i class="fa fa-check"></i><b>5.3.1</b> Hypothesis testing</a></li>
<li class="chapter" data-level="5.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#interpreting-the-coefficients-logit-odds-and-probability"><i class="fa fa-check"></i><b>5.3.2</b> Interpreting the coefficients: Logit, odds, and probability</a></li>
<li class="chapter" data-level="5.3.3" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression-as-a-glm"><i class="fa fa-check"></i><b>5.3.3</b> Logistic regression as a GLM</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="logistic-regression.html"><a href="logistic-regression.html#section-145"><i class="fa fa-check"></i><b>5.4</b> </a></li>
<li class="chapter" data-level="5.5" data-path="logistic-regression.html"><a href="logistic-regression.html#call-13"><i class="fa fa-check"></i><b>5.5</b> Call:</a></li>
<li class="chapter" data-level="5.6" data-path="logistic-regression.html"><a href="logistic-regression.html#glmformula-stressshift-acoustics.std-family-binomial"><i class="fa fa-check"></i><b>5.6</b> glm(formula = stressshift ~ acoustics.std, family = “binomial”,</a></li>
<li class="chapter" data-level="5.7" data-path="logistic-regression.html"><a href="logistic-regression.html#data-givenness"><i class="fa fa-check"></i><b>5.7</b> data = givenness)</a></li>
<li class="chapter" data-level="5.8" data-path="logistic-regression.html"><a href="logistic-regression.html#section-146"><i class="fa fa-check"></i><b>5.8</b> </a></li>
<li class="chapter" data-level="5.9" data-path="logistic-regression.html"><a href="logistic-regression.html#deviance-residuals"><i class="fa fa-check"></i><b>5.9</b> Deviance Residuals:</a></li>
<li class="chapter" data-level="5.10" data-path="logistic-regression.html"><a href="logistic-regression.html#min-1q-median-3q-max-12"><i class="fa fa-check"></i><b>5.10</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="5.11" data-path="logistic-regression.html"><a href="logistic-regression.html#section-147"><i class="fa fa-check"></i><b>5.11</b> -1.6271 -0.8924 -0.6532 1.1213 2.2418</a></li>
<li class="chapter" data-level="5.12" data-path="logistic-regression.html"><a href="logistic-regression.html#section-148"><i class="fa fa-check"></i><b>5.12</b> </a></li>
<li class="chapter" data-level="5.13" data-path="logistic-regression.html"><a href="logistic-regression.html#coefficients-10"><i class="fa fa-check"></i><b>5.13</b> Coefficients:</a></li>
<li class="chapter" data-level="5.14" data-path="logistic-regression.html"><a href="logistic-regression.html#estimate-std.-error-z-value-prz"><i class="fa fa-check"></i><b>5.14</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li class="chapter" data-level="5.15" data-path="logistic-regression.html"><a href="logistic-regression.html#intercept--0.6897-0.1167--5.908-3.47e-09-acoustics.std-1.6371-0.2588-6.325-2.54e-10"><i class="fa fa-check"></i><b>5.15</b> (Intercept) -0.6897 0.1167 -5.908 3.47e-09 <strong><em> ## acoustics.std 1.6371 0.2588 6.325 2.54e-10 </em></strong></a></li>
<li class="chapter" data-level="5.16" data-path="logistic-regression.html"><a href="logistic-regression.html#section-149"><i class="fa fa-check"></i><b>5.16</b> —</a></li>
<li class="chapter" data-level="5.17" data-path="logistic-regression.html"><a href="logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-12"><i class="fa fa-check"></i><b>5.17</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="5.18" data-path="logistic-regression.html"><a href="logistic-regression.html#section-150"><i class="fa fa-check"></i><b>5.18</b> </a></li>
<li class="chapter" data-level="5.19" data-path="logistic-regression.html"><a href="logistic-regression.html#dispersion-parameter-for-binomial-family-taken-to-be-1"><i class="fa fa-check"></i><b>5.19</b> (Dispersion parameter for binomial family taken to be 1)</a></li>
<li class="chapter" data-level="5.20" data-path="logistic-regression.html"><a href="logistic-regression.html#section-151"><i class="fa fa-check"></i><b>5.20</b> </a></li>
<li class="chapter" data-level="5.21" data-path="logistic-regression.html"><a href="logistic-regression.html#null-deviance-496.24-on-381-degrees-of-freedom"><i class="fa fa-check"></i><b>5.21</b> Null deviance: 496.24 on 381 degrees of freedom</a></li>
<li class="chapter" data-level="5.22" data-path="logistic-regression.html"><a href="logistic-regression.html#residual-deviance-448.07-on-380-degrees-of-freedom"><i class="fa fa-check"></i><b>5.22</b> Residual deviance: 448.07 on 380 degrees of freedom</a></li>
<li class="chapter" data-level="5.23" data-path="logistic-regression.html"><a href="logistic-regression.html#aic-452.07"><i class="fa fa-check"></i><b>5.23</b> AIC: 452.07</a></li>
<li class="chapter" data-level="5.24" data-path="logistic-regression.html"><a href="logistic-regression.html#section-152"><i class="fa fa-check"></i><b>5.24</b> </a></li>
<li class="chapter" data-level="5.25" data-path="logistic-regression.html"><a href="logistic-regression.html#number-of-fisher-scoring-iterations-3"><i class="fa fa-check"></i><b>5.25</b> Number of Fisher Scoring iterations: 3</a></li>
<li class="chapter" data-level="5.26" data-path="logistic-regression.html"><a href="logistic-regression.html#section-153"><i class="fa fa-check"></i><b>5.26</b> [1] -0.6896608</a></li>
<li class="chapter" data-level="5.27" data-path="logistic-regression.html"><a href="logistic-regression.html#section-154"><i class="fa fa-check"></i><b>5.27</b> [1] 0.3341085</a></li>
<li class="chapter" data-level="5.28" data-path="logistic-regression.html"><a href="logistic-regression.html#section-155"><i class="fa fa-check"></i><b>5.28</b> [1] 1.637052</a></li>
<li class="chapter" data-level="5.29" data-path="logistic-regression.html"><a href="logistic-regression.html#section-156"><i class="fa fa-check"></i><b>5.29</b> [1] 5.139996</a></li>
<li class="chapter" data-level="5.30" data-path="logistic-regression.html"><a href="logistic-regression.html#set-up-dataframe-with-range-of-acoustics.std-we-want-to-predict-over"><i class="fa fa-check"></i><b>5.30</b> set up dataframe with range of acoustics.std we want to predict over</a></li>
<li class="chapter" data-level="5.31" data-path="logistic-regression.html"><a href="logistic-regression.html#get-the-models-predictions-in-log-odds-space"><i class="fa fa-check"></i><b>5.31</b> get the model’s predictions in log-odds space</a></li>
<li class="chapter" data-level="5.32" data-path="logistic-regression.html"><a href="logistic-regression.html#transform-those-preditions-to-probability-space"><i class="fa fa-check"></i><b>5.32</b> transform those preditions to probability space</a></li>
<li class="chapter" data-level="5.33" data-path="logistic-regression.html"><a href="logistic-regression.html#section-157"><i class="fa fa-check"></i><b>5.33</b> </a></li>
<li class="chapter" data-level="5.34" data-path="logistic-regression.html"><a href="logistic-regression.html#call-14"><i class="fa fa-check"></i><b>5.34</b> Call:</a></li>
<li class="chapter" data-level="5.35" data-path="logistic-regression.html"><a href="logistic-regression.html#glmformula-stressshift-nptype-family-binomial-data-givenness"><i class="fa fa-check"></i><b>5.35</b> glm(formula = stressshift ~ npType, family = “binomial”, data = givenness)</a></li>
<li class="chapter" data-level="5.36" data-path="logistic-regression.html"><a href="logistic-regression.html#section-158"><i class="fa fa-check"></i><b>5.36</b> </a></li>
<li class="chapter" data-level="5.37" data-path="logistic-regression.html"><a href="logistic-regression.html#deviance-residuals-1"><i class="fa fa-check"></i><b>5.37</b> Deviance Residuals:</a></li>
<li class="chapter" data-level="5.38" data-path="logistic-regression.html"><a href="logistic-regression.html#min-1q-median-3q-max-13"><i class="fa fa-check"></i><b>5.38</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="5.39" data-path="logistic-regression.html"><a href="logistic-regression.html#section-159"><i class="fa fa-check"></i><b>5.39</b> -1.014 -1.014 -0.850 1.350 1.545</a></li>
<li class="chapter" data-level="5.40" data-path="logistic-regression.html"><a href="logistic-regression.html#section-160"><i class="fa fa-check"></i><b>5.40</b> </a></li>
<li class="chapter" data-level="5.41" data-path="logistic-regression.html"><a href="logistic-regression.html#coefficients-11"><i class="fa fa-check"></i><b>5.41</b> Coefficients:</a></li>
<li class="chapter" data-level="5.42" data-path="logistic-regression.html"><a href="logistic-regression.html#estimate-std.-error-z-value-prz-1"><i class="fa fa-check"></i><b>5.42</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li><a href="logistic-regression.html#intercept--0.8321-0.1587--5.244-1.57e-07-nptypepronoun-0.4353-0.2159-2.016-0.0438-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-496.24-on-381-degrees-of-freedom-residual-deviance-492.14-on-380-degrees-of-freedom-aic-496.14-number-of-fisher-scoring-iterations-4-observed-condtion-means-stressshift-nptype-noshift-shift-full-0.6968085-0.3031915-pronoun-0.5979381-0.4020619-differences-from-linear-regression-fitting-and-interpretation-c4differences-fitting-a-logistic-regression-model-interpretation-warning-glm.fit-algorithm-did-not-converge-evaluating-logistic-regression-models-evaluating-logistic-regression-models-likelihood-ratio-test-c4lrt-lr-test-of-the-effect-of-acoustics.std-in-mod1-analysis-of-deviance-table-model-1-stressshift-1-model-2-stressshift-acoustics.std-resid.-df-resid.-dev-df-deviance-prchi-1-381-496.24-2-380-448.07-1-48.17-3.909e-12-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-call-glmformula-stressshift-acoustics.std-family-binomial-data-givenness-deviance-residuals-min-1q-median-3q-max--1.6271--0.8924--0.6532-1.1213-2.2418-coefficients-estimate-std.-error-z-value-prz-intercept--0.6897-0.1167--5.908-3.47e-09-acoustics.std-1.6371-0.2588-6.325-2.54e-10-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-496.24-on-381-degrees-of-freedom-residual-deviance-448.07-on-380-degrees-of-freedom-aic-452.07-number-of-fisher-scoring-iterations-3-classification-accuracy-function-for-computing-accuracy-of-a-logistic-regression-model-on-the-dataset-used-to-fit-the-model-lrmod-fitted-model-responsevar-name-of-response-variable-for-lrmod-adapted-from-httpswww.r-bloggers.comevaluating-logistic-regression-models-baseline-accuracy-for-a-logisitic-regression-model-lrmod-with-a-given-response-variable-baseline-accuracy-1-0.7015707-pseudo-r2-logistic-regression-pseudo-r2-example---lr-test-of-the-effect-of-nptype-in-mod2-analysis-of-deviance-table-model-1-stressshift-nptype-model-2-stressshift-1-resid.-df-resid.-dev-df-deviance-prchi-1-380-492.14-2-381-496.24--1--4.0972-0.04295"><span class="toc-section-number">5.43</span> (Intercept) -0.8321 0.1587 -5.244 1.57e-07 <strong><em> ## npTypepronoun 0.4353 0.2159 2.016 0.0438 </em><br />
## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 496.24 on 381 degrees of freedom ## Residual deviance: 492.14 on 380 degrees of freedom ## AIC: 496.14 ## ## Number of Fisher Scoring iterations: 4 ## Observed condtion means: ## stressshift ## npType noshift shift ## full 0.6968085 0.3031915 ## pronoun 0.5979381 0.4020619 ### Differences from linear regression: Fitting and interpretation {#c4differences} ### Fitting a logistic regression model ### Interpretation ## Warning: glm.fit: algorithm did not converge ## Evaluating logistic regression models {#evaluating-logistic-regression-models} ### Likelihood ratio test {#c4lrt} ## LR test of the effect of acoustics.std in mod1 ## Analysis of Deviance Table ## ## Model 1: stressshift ~ 1 ## Model 2: stressshift ~ acoustics.std ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 381 496.24<br />
## 2 380 448.07 1 48.17 3.909e-12 </strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Call: ## glm(formula = stressshift ~ acoustics.std, family = “binomial”, ## data = givenness) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max<br />
## -1.6271 -0.8924 -0.6532 1.1213 2.2418<br />
## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -0.6897 0.1167 -5.908 3.47e-09 </em><strong> ## acoustics.std 1.6371 0.2588 6.325 2.54e-10 </strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 496.24 on 381 degrees of freedom ## Residual deviance: 448.07 on 380 degrees of freedom ## AIC: 452.07 ## ## Number of Fisher Scoring iterations: 3 ### Classification accuracy ## function for computing accuracy of a logistic regression model ## (on the dataset used to fit the model) ## lrMod = fitted model ## responseVar = name of response variable for lrMod ## adapted from: <a href="https://www.r-bloggers.com/evaluating-logistic-regression-models/" class="uri">https://www.r-bloggers.com/evaluating-logistic-regression-models/</a> ## baseline accuracy for a logisitic regression model lrMod ## with a given response variable ## baseline accuracy ## [1] 0.7015707 ### Pseudo-<span class="math inline">\(R^2\)</span> {#logistic-regression-pseudo-r2} #### Example {-} ## LR test of the effect of npType in mod2 ## Analysis of Deviance Table ## ## Model 1: stressshift ~ npType ## Model 2: stressshift ~ 1 ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 380 492.14<br />
## 2 381 496.24 -1 -4.0972 0.04295 </em></a></li>
<li class="chapter" data-level="5.44" data-path="logistic-regression.html"><a href="logistic-regression.html#section-161"><i class="fa fa-check"></i><b>5.44</b> —</a></li>
<li class="chapter" data-level="5.45" data-path="logistic-regression.html"><a href="logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-13"><i class="fa fa-check"></i><b>5.45</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="5.46" data-path="logistic-regression.html"><a href="logistic-regression.html#accuracy-of-mod2"><i class="fa fa-check"></i><b>5.46</b> accuracy of mod2</a></li>
<li class="chapter" data-level="5.47" data-path="logistic-regression.html"><a href="logistic-regression.html#section-162"><i class="fa fa-check"></i><b>5.47</b> [1] 0.6465969</a></li>
<li class="chapter" data-level="5.48" data-path="logistic-regression.html"><a href="logistic-regression.html#its-the-same-as-the-baselines-accuracy"><i class="fa fa-check"></i><b>5.48</b> it’s the same as the baseline’s accuracy</a></li>
<li class="chapter" data-level="5.49" data-path="logistic-regression.html"><a href="logistic-regression.html#section-163"><i class="fa fa-check"></i><b>5.49</b> [1] 0.6465969</a></li>
<li class="chapter" data-level="5.50" data-path="logistic-regression.html"><a href="logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>5.50</b> Multiple logistic regression</a><ul>
<li class="chapter" data-level="5.50.1" data-path="logistic-regression.html"><a href="logistic-regression.html#likelihood-ratio-test-general-case"><i class="fa fa-check"></i><b>5.50.1</b> Likelihood ratio test: General case</a></li>
<li class="chapter" data-level="5.50.2" data-path="logistic-regression.html"><a href="logistic-regression.html#log-reg-worked-example"><i class="fa fa-check"></i><b>5.50.2</b> Worked example</a></li>
</ul></li>
<li class="chapter" data-level="5.51" data-path="logistic-regression.html"><a href="logistic-regression.html#stressshift"><i class="fa fa-check"></i><b>5.51</b> stressshift</a></li>
<li class="chapter" data-level="5.52" data-path="logistic-regression.html"><a href="logistic-regression.html#conditionlabel-noshift-shift"><i class="fa fa-check"></i><b>5.52</b> conditionLabel noshift shift</a></li>
<li class="chapter" data-level="5.53" data-path="logistic-regression.html"><a href="logistic-regression.html#contrast-0.91919192-0.08080808"><i class="fa fa-check"></i><b>5.53</b> Contrast 0.91919192 0.08080808</a></li>
<li class="chapter" data-level="5.54" data-path="logistic-regression.html"><a href="logistic-regression.html#williams-0.35326087-0.64673913"><i class="fa fa-check"></i><b>5.54</b> Williams 0.35326087 0.64673913</a></li>
<li class="chapter" data-level="5.55" data-path="logistic-regression.html"><a href="logistic-regression.html#stressshift-1"><i class="fa fa-check"></i><b>5.55</b> stressshift</a></li>
<li class="chapter" data-level="5.56" data-path="logistic-regression.html"><a href="logistic-regression.html#nptype-noshift-shift"><i class="fa fa-check"></i><b>5.56</b> npType noshift shift</a></li>
<li class="chapter" data-level="5.57" data-path="logistic-regression.html"><a href="logistic-regression.html#full-0.6968085-0.3031915"><i class="fa fa-check"></i><b>5.57</b> full 0.6968085 0.3031915</a></li>
<li class="chapter" data-level="5.58" data-path="logistic-regression.html"><a href="logistic-regression.html#pronoun-0.5979381-0.4020619"><i class="fa fa-check"></i><b>5.58</b> pronoun 0.5979381 0.4020619</a></li>
<li class="chapter" data-level="5.59" data-path="logistic-regression.html"><a href="logistic-regression.html#stressshift-2"><i class="fa fa-check"></i><b>5.59</b> stressshift</a></li>
<li class="chapter" data-level="5.60" data-path="logistic-regression.html"><a href="logistic-regression.html#voice-noshift-shift"><i class="fa fa-check"></i><b>5.60</b> voice noshift shift</a></li>
<li class="chapter" data-level="5.61" data-path="logistic-regression.html"><a href="logistic-regression.html#active-0.7005348-0.2994652"><i class="fa fa-check"></i><b>5.61</b> active 0.7005348 0.2994652</a></li>
<li class="chapter" data-level="5.62" data-path="logistic-regression.html"><a href="logistic-regression.html#passive-0.5948718-0.4051282"><i class="fa fa-check"></i><b>5.62</b> passive 0.5948718 0.4051282</a></li>
<li class="chapter" data-level="5.63" data-path="logistic-regression.html"><a href="logistic-regression.html#section-164"><i class="fa fa-check"></i><b>5.63</b> </a></li>
<li class="chapter" data-level="5.64" data-path="logistic-regression.html"><a href="logistic-regression.html#call-15"><i class="fa fa-check"></i><b>5.64</b> Call:</a></li>
<li class="chapter" data-level="5.65" data-path="logistic-regression.html"><a href="logistic-regression.html#glmformula-stressshift-nptype.pron-clabel.williams-voice.passive"><i class="fa fa-check"></i><b>5.65</b> glm(formula = stressshift ~ npType.pron + clabel.williams + voice.passive +</a></li>
<li class="chapter" data-level="5.66" data-path="logistic-regression.html"><a href="logistic-regression.html#order.std-family-binomial-data-givenness"><i class="fa fa-check"></i><b>5.66</b> order.std, family = “binomial”, data = givenness)</a></li>
<li class="chapter" data-level="5.67" data-path="logistic-regression.html"><a href="logistic-regression.html#section-165"><i class="fa fa-check"></i><b>5.67</b> </a></li>
<li class="chapter" data-level="5.68" data-path="logistic-regression.html"><a href="logistic-regression.html#deviance-residuals-2"><i class="fa fa-check"></i><b>5.68</b> Deviance Residuals:</a></li>
<li class="chapter" data-level="5.69" data-path="logistic-regression.html"><a href="logistic-regression.html#min-1q-median-3q-max-14"><i class="fa fa-check"></i><b>5.69</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="5.70" data-path="logistic-regression.html"><a href="logistic-regression.html#section-166"><i class="fa fa-check"></i><b>5.70</b> -1.8358 -0.5249 -0.3509 0.7644 2.6344</a></li>
<li class="chapter" data-level="5.71" data-path="logistic-regression.html"><a href="logistic-regression.html#section-167"><i class="fa fa-check"></i><b>5.71</b> </a></li>
<li class="chapter" data-level="5.72" data-path="logistic-regression.html"><a href="logistic-regression.html#coefficients-12"><i class="fa fa-check"></i><b>5.72</b> Coefficients:</a></li>
<li class="chapter" data-level="5.73" data-path="logistic-regression.html"><a href="logistic-regression.html#estimate-std.-error-z-value-prz-2"><i class="fa fa-check"></i><b>5.73</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li><a href="logistic-regression.html#intercept--1.0092-0.1580--6.389-1.67e-10-nptype.pron-0.5985-0.2746-2.179-0.0293-clabel.williams-3.1848-0.3179-10.018-2e-16-voice.passive-0.8026-0.2803-2.863-0.0042-order.std-0.3044-0.2742-1.110-0.2669-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-496.24-on-381-degrees-of-freedom-residual-deviance-335.90-on-377-degrees-of-freedom-aic-345.9-number-of-fisher-scoring-iterations-5-1-0.6818186-model-evaluation---analysis-of-deviance-table-model-1-stressshift-nptype.pron-clabel.williams-voice.passive-order.std-model-2-stressshift-1-resid.-df-resid.-dev-df-deviance-prchi-1-377-335.90-2-381-496.24--4--160.34-2.2e-16"><span class="toc-section-number">5.74</span> (Intercept) -1.0092 0.1580 -6.389 1.67e-10 <strong><em> ## npType.pron 0.5985 0.2746 2.179 0.0293 </em><br />
## clabel.williams 3.1848 0.3179 10.018 &lt; 2e-16 </strong><em> ## voice.passive 0.8026 0.2803 2.863 0.0042 <strong> ## order.std 0.3044 0.2742 1.110 0.2669<br />
## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 496.24 on 381 degrees of freedom ## Residual deviance: 335.90 on 377 degrees of freedom ## AIC: 345.9 ## ## Number of Fisher Scoring iterations: 5 ## [1] 0.6818186 #### Model evaluation {-} ## Analysis of Deviance Table ## ## Model 1: stressshift ~ npType.pron + clabel.williams + voice.passive + ## order.std ## Model 2: stressshift ~ 1 ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 377 335.90<br />
## 2 381 496.24 -4 -160.34 &lt; 2.2e-16 </strong></em></a></li>
<li class="chapter" data-level="5.75" data-path="logistic-regression.html"><a href="logistic-regression.html#section-168"><i class="fa fa-check"></i><b>5.75</b> —</a></li>
<li class="chapter" data-level="5.76" data-path="logistic-regression.html"><a href="logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-14"><i class="fa fa-check"></i><b>5.76</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="5.77" data-path="logistic-regression.html"><a href="logistic-regression.html#classification-accuracy"><i class="fa fa-check"></i><b>5.77</b> classification accuracy</a></li>
<li class="chapter" data-level="5.78" data-path="logistic-regression.html"><a href="logistic-regression.html#section-169"><i class="fa fa-check"></i><b>5.78</b> [1] 0.8089005</a></li>
<li class="chapter" data-level="5.79" data-path="logistic-regression.html"><a href="logistic-regression.html#baseline-accuracy"><i class="fa fa-check"></i><b>5.79</b> baseline accuracy</a></li>
<li class="chapter" data-level="5.80" data-path="logistic-regression.html"><a href="logistic-regression.html#section-170"><i class="fa fa-check"></i><b>5.80</b> [1] 0.6465969</a></li>
<li class="chapter" data-level="5.81" data-path="logistic-regression.html"><a href="logistic-regression.html#analysis-of-deviance-table"><i class="fa fa-check"></i><b>5.81</b> Analysis of Deviance Table</a></li>
<li class="chapter" data-level="5.82" data-path="logistic-regression.html"><a href="logistic-regression.html#section-171"><i class="fa fa-check"></i><b>5.82</b> </a></li>
<li class="chapter" data-level="5.83" data-path="logistic-regression.html"><a href="logistic-regression.html#model-1-stressshift-nptype.pron-clabel.williams-voice.passive"><i class="fa fa-check"></i><b>5.83</b> Model 1: stressshift ~ npType.pron + clabel.williams + voice.passive +</a></li>
<li class="chapter" data-level="5.84" data-path="logistic-regression.html"><a href="logistic-regression.html#order.std"><i class="fa fa-check"></i><b>5.84</b> order.std</a></li>
<li class="chapter" data-level="5.85" data-path="logistic-regression.html"><a href="logistic-regression.html#model-2-stressshift-nptype.pron-clabel.williams-voice.passive"><i class="fa fa-check"></i><b>5.85</b> Model 2: stressshift ~ npType.pron + clabel.williams * voice.passive +</a></li>
<li class="chapter" data-level="5.86" data-path="logistic-regression.html"><a href="logistic-regression.html#order.std-1"><i class="fa fa-check"></i><b>5.86</b> order.std</a></li>
<li class="chapter" data-level="5.87" data-path="logistic-regression.html"><a href="logistic-regression.html#resid.-df-resid.-dev-df-deviance-prchi"><i class="fa fa-check"></i><b>5.87</b> Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)</a></li>
<li class="chapter" data-level="5.88" data-path="logistic-regression.html"><a href="logistic-regression.html#section-172"><i class="fa fa-check"></i><b>5.88</b> 1 377 335.90</a></li>
<li><a href="logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-analysis-of-deviance-table-model-1-stressshift-nptype.pron-clabel.williams-voice.passive-order.std-model-2-stressshift-nptype.pron-clabel.williams-voice.passive-order.std-nptype.pron-clabel.williams-resid.-df-resid.-dev-df-deviance-prchi-1-377-335.90-2-376-335.31-1-0.5867-0.4437-analysis-of-deviance-table-model-1-stressshift-nptype.pron-clabel.williams-voice.passive-order.std-model-2-stressshift-nptype.pron-clabel.williams-voice.passive-order.std-voice.passive-nptype.pron-resid.-df-resid.-dev-df-deviance-prchi-1-377-335.90-2-376-334.99-1-0.9108-0.3399-call-glmformula-stressshift-nptype.pron-clabel.williams-voice.passive-order.std-family-binomial-data-givenness-deviance-residuals-min-1q-median-3q-max--1.9933--0.4987--0.3543-0.6757-2.6080-coefficients-estimate-std.-error-z-value-prz-intercept--0.9742-0.1625--5.993-2.06e-09-nptype.pron-0.6302-0.2810-2.242-0.02493"><span class="toc-section-number">5.89</span> 2 376 325.81 1 10.085 0.001495 <strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## Analysis of Deviance Table ## ## Model 1: stressshift ~ npType.pron + clabel.williams + voice.passive + ## order.std ## Model 2: stressshift ~ npType.pron + clabel.williams + voice.passive + ## order.std + npType.pron * clabel.williams ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) ## 1 377 335.90<br />
## 2 376 335.31 1 0.5867 0.4437 ## Analysis of Deviance Table ## ## Model 1: stressshift ~ npType.pron + clabel.williams + voice.passive + ## order.std ## Model 2: stressshift ~ npType.pron + clabel.williams + voice.passive + ## order.std + voice.passive * npType.pron ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) ## 1 377 335.90<br />
## 2 376 334.99 1 0.9108 0.3399 ## ## Call: ## glm(formula = stressshift ~ npType.pron + clabel.williams * voice.passive + ## order.std, family = “binomial”, data = givenness) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max<br />
## -1.9933 -0.4987 -0.3543 0.6757 2.6080<br />
## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -0.9742 0.1625 -5.993 2.06e-09 </strong><em> ## npType.pron 0.6302 0.2810 2.242 0.02493 </em></a></li>
<li><a href="logistic-regression.html#clabel.williams-3.2054-0.3230-9.923-2e-16-voice.passive-0.3209-0.3239-0.991-0.32172-order.std-0.3650-0.2876-1.269-0.20437-clabel.williamsvoice.passive-1.9850-0.6370-3.116-0.00183-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-496.24-on-381-degrees-of-freedom-residual-deviance-325.81-on-376-degrees-of-freedom-aic-337.81-number-of-fisher-scoring-iterations-5-1-0.8062827-1-0.8089005-model-criticism-for-logistic-regression-model-criticism-logistic-regression-residual-plots-residual-plots-example-binned-residuals-versus-expected-values---binned-residual-plot-cooks-distance-logistic-regression-cooks-distance-add-a-column-showing-cooks-distance-values-to-dataframe-other-readings-solutions-c4solns-appendix-other-generalized-linear-models-c4appendix2"><span class="toc-section-number">5.90</span> clabel.williams 3.2054 0.3230 9.923 &lt; 2e-16 *<strong> ## voice.passive 0.3209 0.3239 0.991 0.32172<br />
## order.std 0.3650 0.2876 1.269 0.20437<br />
## clabel.williams:voice.passive 1.9850 0.6370 3.116 0.00183 </strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 496.24 on 381 degrees of freedom ## Residual deviance: 325.81 on 376 degrees of freedom ## AIC: 337.81 ## ## Number of Fisher Scoring iterations: 5 ## [1] 0.8062827 ## [1] 0.8089005 ## Model criticism for logistic regression {#model-criticism-logistic-regression} ### Residual plots {#residual-plots} #### Example: Binned residuals versus expected values {-} ## binned residual plot ### Cook’s distance {#logistic-regression-cooks-distance} ## add a column showing Cook’s distance values to dataframe ## Other readings ## Solutions {#c4solns} ## Appendix: Other Generalized Linear Models {#c4appendix2}</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><i class="fa fa-check"></i><b>6</b> Practical Regression Topics 1: Multi-level factors, contrast coding, interactions</a><ul>
<li class="chapter" data-level="6.1" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#loads-givennessmcgillling620.csv-from-osf-project-for-wagner-2012-data-1"><i class="fa fa-check"></i><b>6.1</b> loads givennessMcGillLing620.csv from OSF project for Wagner (2012) data</a></li>
<li class="chapter" data-level="6.2" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#note-stress-shift-generally-called-prominence-shift-etc.-in-the-text"><i class="fa fa-check"></i><b>6.2</b> note: “stress shift” generally called “prominence shift” etc. in the text</a></li>
<li class="chapter" data-level="6.3" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#loads-alternativesmcgillling620.csv-from-osf-project-for-wagner-2016-data-1"><i class="fa fa-check"></i><b>6.3</b> loads alternativesMcGillLing620.csv from OSF project for Wagner (2016) data</a></li>
<li class="chapter" data-level="6.4" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#loads-french_medial_vowel_devoicing.txt-from-osf-project-for-torreira-ernestus-2010-data-1"><i class="fa fa-check"></i><b>6.4</b> loads french_medial_vowel_devoicing.txt from OSF project for Torreira &amp; Ernestus (2010) data</a></li>
<li class="chapter" data-level="6.5" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#multi-level-factors-introduction"><i class="fa fa-check"></i><b>6.5</b> Multi-level factors: Introduction</a></li>
<li class="chapter" data-level="6.6" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#contrast-coding"><i class="fa fa-check"></i><b>6.6</b> Contrast coding</a><ul>
<li class="chapter" data-level="6.6.1" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#first-examples"><i class="fa fa-check"></i><b>6.6.1</b> First examples</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-173"><i class="fa fa-check"></i><b>6.7</b> </a></li>
<li class="chapter" data-level="6.8" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#call-16"><i class="fa fa-check"></i><b>6.8</b> Call:</a></li>
<li class="chapter" data-level="6.9" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#lmformula-acoustics-conditionlabel-data-givenness"><i class="fa fa-check"></i><b>6.9</b> lm(formula = acoustics ~ conditionLabel, data = givenness)</a></li>
<li class="chapter" data-level="6.10" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-174"><i class="fa fa-check"></i><b>6.10</b> </a></li>
<li class="chapter" data-level="6.11" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residuals-12"><i class="fa fa-check"></i><b>6.11</b> Residuals:</a></li>
<li class="chapter" data-level="6.12" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#min-1q-median-3q-max-15"><i class="fa fa-check"></i><b>6.12</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="6.13" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-175"><i class="fa fa-check"></i><b>6.13</b> -2.31843 -0.56264 0.01977 0.53651 2.50851</a></li>
<li class="chapter" data-level="6.14" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-176"><i class="fa fa-check"></i><b>6.14</b> </a></li>
<li class="chapter" data-level="6.15" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#coefficients-13"><i class="fa fa-check"></i><b>6.15</b> Coefficients:</a></li>
<li class="chapter" data-level="6.16" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#estimate-std.-error-t-value-prt-11"><i class="fa fa-check"></i><b>6.16</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="6.17" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept--0.87510-0.05708--15.331-2e-16-conditionlabelwilliams-0.31774-0.08224-3.863-0.000131"><i class="fa fa-check"></i><b>6.17</b> (Intercept) -0.87510 0.05708 -15.331 &lt; 2e-16 <strong><em> ## conditionLabelWilliams 0.31774 0.08224 3.863 0.000131 </em></strong></a></li>
<li class="chapter" data-level="6.18" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-177"><i class="fa fa-check"></i><b>6.18</b> —</a></li>
<li class="chapter" data-level="6.19" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-15"><i class="fa fa-check"></i><b>6.19</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="6.20" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-178"><i class="fa fa-check"></i><b>6.20</b> </a></li>
<li class="chapter" data-level="6.21" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residual-standard-error-0.8032-on-380-degrees-of-freedom"><i class="fa fa-check"></i><b>6.21</b> Residual standard error: 0.8032 on 380 degrees of freedom</a></li>
<li class="chapter" data-level="6.22" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#multiple-r-squared-0.03779-adjusted-r-squared-0.03526"><i class="fa fa-check"></i><b>6.22</b> Multiple R-squared: 0.03779, Adjusted R-squared: 0.03526</a></li>
<li class="chapter" data-level="6.23" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#f-statistic-14.93-on-1-and-380-df-p-value-0.0001315"><i class="fa fa-check"></i><b>6.23</b> F-statistic: 14.93 on 1 and 380 DF, p-value: 0.0001315</a></li>
<li class="chapter" data-level="6.24" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#williams"><i class="fa fa-check"></i><b>6.24</b> Williams</a></li>
<li class="chapter" data-level="6.25" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#contrast-0"><i class="fa fa-check"></i><b>6.25</b> Contrast 0</a></li>
<li class="chapter" data-level="6.26" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#williams-1"><i class="fa fa-check"></i><b>6.26</b> Williams 1</a></li>
<li class="chapter" data-level="6.27" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-179"><i class="fa fa-check"></i><b>6.27</b> </a></li>
<li class="chapter" data-level="6.28" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#call-17"><i class="fa fa-check"></i><b>6.28</b> Call:</a></li>
<li class="chapter" data-level="6.29" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#lmformula-acoustics-clabel.williams-data-givenness"><i class="fa fa-check"></i><b>6.29</b> lm(formula = acoustics ~ clabel.williams, data = givenness)</a></li>
<li class="chapter" data-level="6.30" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-180"><i class="fa fa-check"></i><b>6.30</b> </a></li>
<li class="chapter" data-level="6.31" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residuals-13"><i class="fa fa-check"></i><b>6.31</b> Residuals:</a></li>
<li class="chapter" data-level="6.32" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#min-1q-median-3q-max-16"><i class="fa fa-check"></i><b>6.32</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="6.33" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-181"><i class="fa fa-check"></i><b>6.33</b> -2.31843 -0.56264 0.01977 0.53651 2.50851</a></li>
<li class="chapter" data-level="6.34" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-182"><i class="fa fa-check"></i><b>6.34</b> </a></li>
<li class="chapter" data-level="6.35" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#coefficients-14"><i class="fa fa-check"></i><b>6.35</b> Coefficients:</a></li>
<li class="chapter" data-level="6.36" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#estimate-std.-error-t-value-prt-12"><i class="fa fa-check"></i><b>6.36</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="6.37" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept--0.72205-0.04109--17.570-2e-16-clabel.williams-0.31774-0.08224-3.863-0.000131"><i class="fa fa-check"></i><b>6.37</b> (Intercept) -0.72205 0.04109 -17.570 &lt; 2e-16 <strong><em> ## clabel.williams 0.31774 0.08224 3.863 0.000131 </em></strong></a></li>
<li class="chapter" data-level="6.38" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-183"><i class="fa fa-check"></i><b>6.38</b> —</a></li>
<li class="chapter" data-level="6.39" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-16"><i class="fa fa-check"></i><b>6.39</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="6.40" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-184"><i class="fa fa-check"></i><b>6.40</b> </a></li>
<li class="chapter" data-level="6.41" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residual-standard-error-0.8032-on-380-degrees-of-freedom-1"><i class="fa fa-check"></i><b>6.41</b> Residual standard error: 0.8032 on 380 degrees of freedom</a></li>
<li class="chapter" data-level="6.42" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#multiple-r-squared-0.03779-adjusted-r-squared-0.03526-1"><i class="fa fa-check"></i><b>6.42</b> Multiple R-squared: 0.03779, Adjusted R-squared: 0.03526</a></li>
<li class="chapter" data-level="6.43" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#f-statistic-14.93-on-1-and-380-df-p-value-0.0001315-1"><i class="fa fa-check"></i><b>6.43</b> F-statistic: 14.93 on 1 and 380 DF, p-value: 0.0001315</a></li>
<li class="chapter" data-level="6.44" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#sets-contrast-levels-to--0.5-and-0.5"><i class="fa fa-check"></i><b>6.44</b> sets contrast levels to -0.5 and 0.5</a></li>
<li class="chapter" data-level="6.45" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#carry-out-the-regression-and-see-results"><i class="fa fa-check"></i><b>6.45</b> carry out the regression and see results</a></li>
<li class="chapter" data-level="6.46" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-185"><i class="fa fa-check"></i><b>6.46</b> </a></li>
<li class="chapter" data-level="6.47" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#call-18"><i class="fa fa-check"></i><b>6.47</b> Call:</a></li>
<li class="chapter" data-level="6.48" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#lmformula-acoustics-conditionlabel-data-givenness-1"><i class="fa fa-check"></i><b>6.48</b> lm(formula = acoustics ~ conditionLabel, data = givenness)</a></li>
<li class="chapter" data-level="6.49" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-186"><i class="fa fa-check"></i><b>6.49</b> </a></li>
<li class="chapter" data-level="6.50" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residuals-14"><i class="fa fa-check"></i><b>6.50</b> Residuals:</a></li>
<li class="chapter" data-level="6.51" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#min-1q-median-3q-max-17"><i class="fa fa-check"></i><b>6.51</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="6.52" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-187"><i class="fa fa-check"></i><b>6.52</b> -2.31843 -0.56264 0.01977 0.53651 2.50851</a></li>
<li class="chapter" data-level="6.53" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-188"><i class="fa fa-check"></i><b>6.53</b> </a></li>
<li class="chapter" data-level="6.54" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#coefficients-15"><i class="fa fa-check"></i><b>6.54</b> Coefficients:</a></li>
<li class="chapter" data-level="6.55" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#estimate-std.-error-t-value-prt-13"><i class="fa fa-check"></i><b>6.55</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="6.56" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept--0.71623-0.04112--17.417-2e-16-conditionlabel1--0.31774-0.08224--3.863-0.000131"><i class="fa fa-check"></i><b>6.56</b> (Intercept) -0.71623 0.04112 -17.417 &lt; 2e-16 <strong><em> ## conditionLabel1 -0.31774 0.08224 -3.863 0.000131 </em></strong></a></li>
<li class="chapter" data-level="6.57" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-189"><i class="fa fa-check"></i><b>6.57</b> —</a></li>
<li class="chapter" data-level="6.58" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-17"><i class="fa fa-check"></i><b>6.58</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="6.59" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-190"><i class="fa fa-check"></i><b>6.59</b> </a></li>
<li class="chapter" data-level="6.60" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residual-standard-error-0.8032-on-380-degrees-of-freedom-2"><i class="fa fa-check"></i><b>6.60</b> Residual standard error: 0.8032 on 380 degrees of freedom</a></li>
<li class="chapter" data-level="6.61" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#multiple-r-squared-0.03779-adjusted-r-squared-0.03526-2"><i class="fa fa-check"></i><b>6.61</b> Multiple R-squared: 0.03779, Adjusted R-squared: 0.03526</a></li>
<li class="chapter" data-level="6.62" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#f-statistic-14.93-on-1-and-380-df-p-value-0.0001315-2"><i class="fa fa-check"></i><b>6.62</b> F-statistic: 14.93 on 1 and 380 DF, p-value: 0.0001315</a></li>
<li class="chapter" data-level="6.63" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-191"><i class="fa fa-check"></i><b>6.63</b> </a></li>
<li class="chapter" data-level="6.64" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#call-19"><i class="fa fa-check"></i><b>6.64</b> Call:</a></li>
<li class="chapter" data-level="6.65" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#lmformula-syldur-v-data-devoicing"><i class="fa fa-check"></i><b>6.65</b> lm(formula = syldur ~ v, data = devoicing)</a></li>
<li class="chapter" data-level="6.66" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-192"><i class="fa fa-check"></i><b>6.66</b> </a></li>
<li class="chapter" data-level="6.67" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residuals-15"><i class="fa fa-check"></i><b>6.67</b> Residuals:</a></li>
<li class="chapter" data-level="6.68" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#min-1q-median-3q-max-18"><i class="fa fa-check"></i><b>6.68</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="6.69" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-193"><i class="fa fa-check"></i><b>6.69</b> -108.006 -26.925 1.075 23.055 115.994</a></li>
<li class="chapter" data-level="6.70" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-194"><i class="fa fa-check"></i><b>6.70</b> </a></li>
<li class="chapter" data-level="6.71" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#coefficients-16"><i class="fa fa-check"></i><b>6.71</b> Coefficients:</a></li>
<li class="chapter" data-level="6.72" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#estimate-std.-error-t-value-prt-14"><i class="fa fa-check"></i><b>6.72</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept-123.006-2.050-59.999-2e-16-vu-15.963-6.686-2.388-0.0173-vy--4.082-3.304--1.235-0.2173-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-36.56-on-547-degrees-of-freedom-multiple-r-squared-0.01559-adjusted-r-squared-0.01199-f-statistic-4.331-on-2-and-547-df-p-value-0.01361-u-y-i-0-0-u-1-0-y-0-1-basic-interpretation-of-contrasts-basic-interpretation-of-contrasts-example---c5ex1-reorder-factor-levels-to-make-conceptual-sense-noalternative-is-conceptually-between-alternative-and-new-remove-rows-where-response-is-na-this-is-just-due-to-an-issue-with-this-dataset-add-a-01-variable-where-1-adj-prominence-shifted-0-n-prominence-plot-of-the-basic-pattern-1-0.585-1-0.262-1-0.15-empirical-p-and-log-odds-of-shifting-prominence-a-tibble-3-x-3-context-p-logodds-1-alternative-0.585-0.345-2-noalternative-0.262--1.04-3-new-0.150--1.74-contrast-coding-schemes-dummy-coding-2-3-4-1-0-0-0-2-1-0-0-3-0-1-0-4-0-0-1-2-3-4-5-1-0-0-0-0-2-1-0-0-0-3-0-1-0-0-4-0-0-1-0-5-0-0-0-1-call-glmformula-shifted-context-family-binomial-data-alternatives-deviance-residuals-min-1q-median-3q-max--1.3269--0.7793--0.5696-1.0349-1.9487-coefficients-estimate-std.-error-z-value-prz-intercept-0.3448-0.1418-2.432-0.015-contextnoalternative--1.3809-0.2115--6.529-6.61e-11-contextnew--2.0813-0.2409--8.639-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-789.96-on-621-degrees-of-freedom-residual-deviance-694.53-on-619-degrees-of-freedom-aic-700.53-number-of-fisher-scoring-iterations-4-contrast-matrix-rightarrow-interpretation-1-2-3-1-0-1-0-2-0-0-1-sum-coding-1-2-3-1-1-0-0-2-0-1-0-3-0-0-1-4--1--1--1-1-2-3-4-1-1-0-0-0-2-0-1-0-0-3-0-0-1-0-4-0-0-0-1-5--1--1--1--1-1-2-3-1-0.6666667--0.3333333--0.3333333-2--0.3333333-0.6666667--0.3333333-example---sum-coded-version-of-context-call-glmformula-shifted-context.sum-family-binomial-data-alternatives-deviance-residuals-min-1q-median-3q-max--1.3269--0.7793--0.5696-1.0349-1.9487-coefficients-estimate-std.-error-z-value-prz-intercept--0.80925-0.09584--8.444-2e-16-context.sum1-1.15409-0.12604-9.157-2e-16-context.sum2--0.22684-0.13190--1.720-0.0855-.-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-789.96-on-621-degrees-of-freedom-residual-deviance-694.53-on-619-degrees-of-freedom-aic-700.53-number-of-fisher-scoring-iterations-4-helmert-coding-1-2-3-1--1--1--1-2-1--1--1-3-0-2--1-4-0-0-3-1-2-3-4-1--1--1--1--1-2-1--1--1--1-3-0-2--1--1-4-0-0-3--1-5-0-0-0-4-1-2-3-1--0.5000000-0.5000000-0.0000000-2--0.1666667--0.1666667-0.3333333-example---helmert-coded-version-of-context-call-glmformula-shifted-context.helm-family-binomial-data-alternatives-deviance-residuals-min-1q-median-3q-max--1.3269--0.7793--0.5696-1.0349-1.9487-coefficients-estimate-std.-error-z-value-prz-intercept--0.80925-0.09584--8.444-2e-16-context.helm1--0.69047-0.10575--6.529-6.61e-11-context.helm2--0.46362-0.07388--6.275-3.49e-10-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-dispersion-parameter-for-binomial-family-taken-to-be-1-null-deviance-789.96-on-621-degrees-of-freedom-residual-deviance-694.53-on-619-degrees-of-freedom-aic-700.53-number-of-fisher-scoring-iterations-4-other-coding-schemes-practical-advice-assessing-a-multi-level-factors-contribution-c5mlf-example---likelihood-ratio-test-to-check-whether-context-significantly-affects-prominence-shift-analysis-of-deviance-table-model-1-shifted-1-model-2-shifted-context-resid.-df-resid.-dev-df-deviance-prchi-1-621-789.96-2-619-694.53-2-95.432-2.2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-the-regression-coefficients-are-very-different-for-the-two-contrasts-for-context-under-different-coding-schemes-analysis-of-deviance-table-model-1-shifted-1-model-2-shifted-context-resid.-df-resid.-dev-df-deviance-prchi-1-621-789.96-2-619-694.53-2-95.432-2.2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-analysis-of-deviance-table-model-1-shifted-1-model-2-shifted-context.helm-resid.-df-resid.-dev-df-deviance-prchi-1-621-789.96-2-619-694.53-2-95.432-2.2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-analysis-of-deviance-table-model-1-shifted-1-model-2-shifted-context.sum-resid.-df-resid.-dev-df-deviance-prchi-1-621-789.96-2-619-694.53-2-95.432-2.2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-practice-with-interactions-example-1-two-way-interaction-with-multi-level-factor---we-should-choose-helmert-contrasts-contrast-1-difference-between-3-and-2-contrast-2-difference-between---and-23-change-factor-levels-for-folbound-so-highestlowest-choose-a-contrast-scheme-for-folbound-so-that-one-contrast-is-21-vs---the-distinction-seen-in-the-plot-call-lmformula-syldur-speechrate-folbound-data-devoicing"><span class="toc-section-number">6.73</span> (Intercept) 123.006 2.050 59.999 &lt;2e-16 <strong><em> ## vu 15.963 6.686 2.388 0.0173 </em><br />
## vy -4.082 3.304 -1.235 0.2173<br />
## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Residual standard error: 36.56 on 547 degrees of freedom ## Multiple R-squared: 0.01559, Adjusted R-squared: 0.01199 ## F-statistic: 4.331 on 2 and 547 DF, p-value: 0.01361 ## u y ## i 0 0 ## u 1 0 ## y 0 1 ### Basic interpretation of contrasts {#basic-interpretation-of-contrasts} #### Example {- #c5ex1} ## reorder factor levels to make conceptual sense: “NoAlternative” is conceptually between “Alternative” and “New” ## remove rows where response is NA (this is just due to an issue with this dataset) ## add a 0/1 variable where 1 = adj prominence (shifted), 0 = N prominence ## plot of the basic pattern ## [1] 0.585 ## [1] 0.262 ## [1] 0.15 ## empirical p and log-odds of shifting prominence: ## # A tibble: 3 x 3 ## context p logOdds ## <fct> <dbl> <dbl> ## 1 Alternative 0.585 0.345 ## 2 NoAlternative 0.262 -1.04 ## 3 New 0.150 -1.74 ### Contrast coding schemes #### Dummy coding ## 2 3 4 ## 1 0 0 0 ## 2 1 0 0 ## 3 0 1 0 ## 4 0 0 1 ## 2 3 4 5 ## 1 0 0 0 0 ## 2 1 0 0 0 ## 3 0 1 0 0 ## 4 0 0 1 0 ## 5 0 0 0 1 ## ## Call: ## glm(formula = shifted ~ context, family = “binomial”, data = alternatives) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max<br />
## -1.3269 -0.7793 -0.5696 1.0349 1.9487<br />
## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) 0.3448 0.1418 2.432 0.015 *<br />
## contextNoAlternative -1.3809 0.2115 -6.529 6.61e-11 </strong><em> ## contextNew -2.0813 0.2409 -8.639 &lt; 2e-16 </em><strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 789.96 on 621 degrees of freedom ## Residual deviance: 694.53 on 619 degrees of freedom ## AIC: 700.53 ## ## Number of Fisher Scoring iterations: 4 #### Contrast matrix <span class="math inline">\(\rightarrow\)</span> interpretation ## [,1] [,2] [,3] ## [1,] 0 1 0 ## [2,] 0 0 1 #### Sum coding ## [,1] [,2] [,3] ## 1 1 0 0 ## 2 0 1 0 ## 3 0 0 1 ## 4 -1 -1 -1 ## [,1] [,2] [,3] [,4] ## 1 1 0 0 0 ## 2 0 1 0 0 ## 3 0 0 1 0 ## 4 0 0 0 1 ## 5 -1 -1 -1 -1 ## [,1] [,2] [,3] ## [1,] 0.6666667 -0.3333333 -0.3333333 ## [2,] -0.3333333 0.6666667 -0.3333333 #### Example {-} ## sum-coded version of context ## ## Call: ## glm(formula = shifted ~ context.sum, family = “binomial”, data = alternatives) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max<br />
## -1.3269 -0.7793 -0.5696 1.0349 1.9487<br />
## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -0.80925 0.09584 -8.444 &lt;2e-16 </strong><em> ## context.sum1 1.15409 0.12604 9.157 &lt;2e-16 </em><strong> ## context.sum2 -0.22684 0.13190 -1.720 0.0855 .<br />
## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 789.96 on 621 degrees of freedom ## Residual deviance: 694.53 on 619 degrees of freedom ## AIC: 700.53 ## ## Number of Fisher Scoring iterations: 4 #### Helmert coding ## [,1] [,2] [,3] ## 1 -1 -1 -1 ## 2 1 -1 -1 ## 3 0 2 -1 ## 4 0 0 3 ## [,1] [,2] [,3] [,4] ## 1 -1 -1 -1 -1 ## 2 1 -1 -1 -1 ## 3 0 2 -1 -1 ## 4 0 0 3 -1 ## 5 0 0 0 4 ## [,1] [,2] [,3] ## [1,] -0.5000000 0.5000000 0.0000000 ## [2,] -0.1666667 -0.1666667 0.3333333 #### Example {-} ## Helmert-coded version of context ## ## Call: ## glm(formula = shifted ~ context.helm, family = “binomial”, data = alternatives) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max<br />
## -1.3269 -0.7793 -0.5696 1.0349 1.9487<br />
## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -0.80925 0.09584 -8.444 &lt; 2e-16 </strong><em> ## context.helm1 -0.69047 0.10575 -6.529 6.61e-11 </em><strong> ## context.helm2 -0.46362 0.07388 -6.275 3.49e-10 </strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 789.96 on 621 degrees of freedom ## Residual deviance: 694.53 on 619 degrees of freedom ## AIC: 700.53 ## ## Number of Fisher Scoring iterations: 4 #### Other coding schemes #### Practical advice ## Assessing a multi-level factor’s contribution {#c5mlf} #### Example {-} ## likelihood ratio test to check whether context significantly affects prominence shift ## Analysis of Deviance Table ## ## Model 1: shifted ~ 1 ## Model 2: shifted ~ context ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 621 789.96<br />
## 2 619 694.53 2 95.432 &lt; 2.2e-16 </em><strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## the regression coefficients are very different for the two contrasts for context ## under different coding schemes… ## Analysis of Deviance Table ## ## Model 1: shifted ~ 1 ## Model 2: shifted ~ context ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 621 789.96<br />
## 2 619 694.53 2 95.432 &lt; 2.2e-16 </strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## Analysis of Deviance Table ## ## Model 1: shifted ~ 1 ## Model 2: shifted ~ context.helm ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 621 789.96<br />
## 2 619 694.53 2 95.432 &lt; 2.2e-16 </em><strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## Analysis of Deviance Table ## ## Model 1: shifted ~ 1 ## Model 2: shifted ~ context.sum ## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)<br />
## 1 621 789.96<br />
## 2 619 694.53 2 95.432 &lt; 2.2e-16 </strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## Practice with interactions #### Example 1: Two-way interaction with multi-level factor {-} ## we should choose </em>Helmert contrasts<em>: ## contrast 1: difference between 3 and 2 ## contrast 2: difference between - and 2/3 ## change factor levels for folbound so highest&gt;lowest ## Choose a contrast scheme for folbound so that one contrast is 2/1 vs - (the distinction seen in the plot) ## ## Call: ## lm(formula = syldur ~ speechrate </em> folbound, data = devoicing)</a></li>
<li class="chapter" data-level="6.74" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-195"><i class="fa fa-check"></i><b>6.74</b> </a></li>
<li class="chapter" data-level="6.75" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residuals-16"><i class="fa fa-check"></i><b>6.75</b> Residuals:</a></li>
<li class="chapter" data-level="6.76" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#min-1q-median-3q-max-19"><i class="fa fa-check"></i><b>6.76</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="6.77" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-196"><i class="fa fa-check"></i><b>6.77</b> -109.769 -21.641 0.858 21.919 111.630</a></li>
<li class="chapter" data-level="6.78" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-197"><i class="fa fa-check"></i><b>6.78</b> </a></li>
<li class="chapter" data-level="6.79" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#coefficients-17"><i class="fa fa-check"></i><b>6.79</b> Coefficients:</a></li>
<li class="chapter" data-level="6.80" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#estimate-std.-error-t-value-prt-15"><i class="fa fa-check"></i><b>6.80</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="6.81" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept-204.4614-8.6510-23.635-2e-16-speechrate--10.8602-1.2524--8.671-2e-16"><i class="fa fa-check"></i><b>6.81</b> (Intercept) 204.4614 8.6510 23.635 &lt; 2e-16 <strong><em> ## speechrate -10.8602 1.2524 -8.671 &lt; 2e-16 </em></strong></a></li>
<li class="chapter" data-level="6.82" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#folbound1-0.4630-12.2837-0.038-0.96995"><i class="fa fa-check"></i><b>6.82</b> folbound1 0.4630 12.2837 0.038 0.96995</a></li>
<li><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#folbound2--20.9193-4.9541--4.223-2.83e-05-speechratefolbound1-0.2153-1.7835-0.121-0.90398-speechratefolbound2-1.9173-0.7130-2.689-0.00739-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-residual-standard-error-32.47-on-544-degrees-of-freedom-multiple-r-squared-0.2276-adjusted-r-squared-0.2205-f-statistic-32.06-on-5-and-544-df-p-value-2.2e-16-example-2-three-way-interaction---call-glmformula-stressshift-conditionlabel.williams-nptype.pron"><span class="toc-section-number">6.83</span> folbound2 -20.9193 4.9541 -4.223 2.83e-05 <em><strong> ## speechrate:folbound1 0.2153 1.7835 0.121 0.90398<br />
## speechrate:folbound2 1.9173 0.7130 2.689 0.00739 </strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Residual standard error: 32.47 on 544 degrees of freedom ## Multiple R-squared: 0.2276, Adjusted R-squared: 0.2205 ## F-statistic: 32.06 on 5 and 544 DF, p-value: &lt; 2.2e-16 #### Example 2: Three-way interaction {-} ## ## Call: ## glm(formula = stressshift ~ conditionLabel.williams </em> npType.pron *</a></li>
<li class="chapter" data-level="6.84" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#voice.passive-family-binomial-data-givenness"><i class="fa fa-check"></i><b>6.84</b> voice.passive, family = “binomial”, data = givenness)</a></li>
<li class="chapter" data-level="6.85" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-198"><i class="fa fa-check"></i><b>6.85</b> </a></li>
<li class="chapter" data-level="6.86" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#deviance-residuals-3"><i class="fa fa-check"></i><b>6.86</b> Deviance Residuals:</a></li>
<li class="chapter" data-level="6.87" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#min-1q-median-3q-max-20"><i class="fa fa-check"></i><b>6.87</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="6.88" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-199"><i class="fa fa-check"></i><b>6.88</b> -1.9728 -0.5746 -0.3518 0.5553 2.5601</a></li>
<li class="chapter" data-level="6.89" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-200"><i class="fa fa-check"></i><b>6.89</b> </a></li>
<li class="chapter" data-level="6.90" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#coefficients-18"><i class="fa fa-check"></i><b>6.90</b> Coefficients:</a></li>
<li class="chapter" data-level="6.91" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#estimate-std.-error-1"><i class="fa fa-check"></i><b>6.91</b> Estimate Std. Error</a></li>
<li class="chapter" data-level="6.92" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept--0.9807-0.1704"><i class="fa fa-check"></i><b>6.92</b> (Intercept) -0.9807 0.1704</a></li>
<li class="chapter" data-level="6.93" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williams-3.2322-0.3347"><i class="fa fa-check"></i><b>6.93</b> conditionLabel.williams 3.2322 0.3347</a></li>
<li class="chapter" data-level="6.94" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#nptype.pron-0.4295-0.3403"><i class="fa fa-check"></i><b>6.94</b> npType.pron 0.4295 0.3403</a></li>
<li class="chapter" data-level="6.95" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#voice.passive-0.3168-0.3392"><i class="fa fa-check"></i><b>6.95</b> voice.passive 0.3168 0.3392</a></li>
<li class="chapter" data-level="6.96" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williamsnptype.pron-0.7082-0.6684"><i class="fa fa-check"></i><b>6.96</b> conditionLabel.williams:npType.pron 0.7082 0.6684</a></li>
<li class="chapter" data-level="6.97" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williamsvoice.passive-1.9230-0.6662"><i class="fa fa-check"></i><b>6.97</b> conditionLabel.williams:voice.passive 1.9230 0.6662</a></li>
<li class="chapter" data-level="6.98" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#nptype.pronvoice.passive--0.8359-0.6776"><i class="fa fa-check"></i><b>6.98</b> npType.pron:voice.passive -0.8359 0.6776</a></li>
<li class="chapter" data-level="6.99" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williamsnptype.pronvoice.passive-2.1099-1.3308"><i class="fa fa-check"></i><b>6.99</b> conditionLabel.williams:npType.pron:voice.passive 2.1099 1.3308</a></li>
<li class="chapter" data-level="6.100" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#z-value-prz"><i class="fa fa-check"></i><b>6.100</b> z value Pr(&gt;|z|)</a></li>
<li class="chapter" data-level="6.101" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#intercept--5.756-8.61e-09-conditionlabel.williams-9.658-2e-16"><i class="fa fa-check"></i><b>6.101</b> (Intercept) -5.756 8.61e-09 <strong><em> ## conditionLabel.williams 9.658 &lt; 2e-16 </em></strong></a></li>
<li class="chapter" data-level="6.102" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#nptype.pron-1.262-0.20691"><i class="fa fa-check"></i><b>6.102</b> npType.pron 1.262 0.20691</a></li>
<li class="chapter" data-level="6.103" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#voice.passive-0.934-0.35028"><i class="fa fa-check"></i><b>6.103</b> voice.passive 0.934 0.35028</a></li>
<li class="chapter" data-level="6.104" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williamsnptype.pron-1.060-0.28937"><i class="fa fa-check"></i><b>6.104</b> conditionLabel.williams:npType.pron 1.060 0.28937</a></li>
<li class="chapter" data-level="6.105" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williamsvoice.passive-2.887-0.00389"><i class="fa fa-check"></i><b>6.105</b> conditionLabel.williams:voice.passive 2.887 0.00389 **</a></li>
<li class="chapter" data-level="6.106" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#nptype.pronvoice.passive--1.234-0.21731"><i class="fa fa-check"></i><b>6.106</b> npType.pron:voice.passive -1.234 0.21731</a></li>
<li class="chapter" data-level="6.107" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#conditionlabel.williamsnptype.pronvoice.passive-1.585-0.11289"><i class="fa fa-check"></i><b>6.107</b> conditionLabel.williams:npType.pron:voice.passive 1.585 0.11289</a></li>
<li class="chapter" data-level="6.108" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-201"><i class="fa fa-check"></i><b>6.108</b> —</a></li>
<li class="chapter" data-level="6.109" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-18"><i class="fa fa-check"></i><b>6.109</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="6.110" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-202"><i class="fa fa-check"></i><b>6.110</b> </a></li>
<li class="chapter" data-level="6.111" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#dispersion-parameter-for-binomial-family-taken-to-be-1-1"><i class="fa fa-check"></i><b>6.111</b> (Dispersion parameter for binomial family taken to be 1)</a></li>
<li class="chapter" data-level="6.112" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-203"><i class="fa fa-check"></i><b>6.112</b> </a></li>
<li class="chapter" data-level="6.113" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#null-deviance-496.24-on-381-degrees-of-freedom-1"><i class="fa fa-check"></i><b>6.113</b> Null deviance: 496.24 on 381 degrees of freedom</a></li>
<li class="chapter" data-level="6.114" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#residual-deviance-323.94-on-374-degrees-of-freedom"><i class="fa fa-check"></i><b>6.114</b> Residual deviance: 323.94 on 374 degrees of freedom</a></li>
<li class="chapter" data-level="6.115" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#aic-339.94"><i class="fa fa-check"></i><b>6.115</b> AIC: 339.94</a></li>
<li class="chapter" data-level="6.116" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#section-204"><i class="fa fa-check"></i><b>6.116</b> </a></li>
<li class="chapter" data-level="6.117" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#number-of-fisher-scoring-iterations-5"><i class="fa fa-check"></i><b>6.117</b> Number of Fisher Scoring iterations: 5</a></li>
<li class="chapter" data-level="6.118" data-path="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html"><a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#c5solns"><i class="fa fa-check"></i><b>6.118</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lmem.html"><a href="lmem.html"><i class="fa fa-check"></i><b>7</b> Linear mixed models</a><ul>
<li class="chapter" data-level="7.1" data-path="lmem.html"><a href="lmem.html#loads-givennessmcgillling620.csv-from-osf-project-for-wagner-2012-data-2"><i class="fa fa-check"></i><b>7.1</b> loads givennessMcGillLing620.csv from OSF project for Wagner (2012) data</a></li>
<li class="chapter" data-level="7.2" data-path="lmem.html"><a href="lmem.html#define-numeric-versions-of-factors-for-convenience"><i class="fa fa-check"></i><b>7.2</b> define numeric versions of factors, for convenience</a></li>
<li class="chapter" data-level="7.3" data-path="lmem.html"><a href="lmem.html#make-non-mixed-effect-model-prediction-for-examples-below-just-one-prediction-per"><i class="fa fa-check"></i><b>7.3</b> make non-mixed-effect model prediction for examples below (just one prediction per</a></li>
<li class="chapter" data-level="7.4" data-path="lmem.html"><a href="lmem.html#level-of-conditionlabel"><i class="fa fa-check"></i><b>7.4</b> level of conditionLabel)</a></li>
<li class="chapter" data-level="7.5" data-path="lmem.html"><a href="lmem.html#loads-halfrhymemcgillling620.csv-from-osf-project-for-harder-2013-data-1"><i class="fa fa-check"></i><b>7.5</b> loads halfrhymeMcGillLing620.csv from OSF project for Harder (2013) data</a></li>
<li class="chapter" data-level="7.6" data-path="lmem.html"><a href="lmem.html#need-to-do-this-because-the-relduration-variable-is-only-defined-when-conditionlabel-is-voice"><i class="fa fa-check"></i><b>7.6</b> need to do this because the relDuration variable is only defined when conditionLabel is ‘voice’</a></li>
<li class="chapter" data-level="7.7" data-path="lmem.html"><a href="lmem.html#mixed-effects-models-motivation"><i class="fa fa-check"></i><b>7.7</b> Mixed-effects models: Motivation</a><ul>
<li class="chapter" data-level="7.7.1" data-path="lmem.html"><a href="lmem.html#simpsons-paradox"><i class="fa fa-check"></i><b>7.7.1</b> Simpson’s paradox</a></li>
<li class="chapter" data-level="7.7.2" data-path="lmem.html"><a href="lmem.html#repeated-measure-anovas"><i class="fa fa-check"></i><b>7.7.2</b> Repeated-measure ANOVAs</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="lmem.html"><a href="lmem.html#linear-mixed-models-1-one-grouping-factor-random-intercepts"><i class="fa fa-check"></i><b>7.8</b> Linear mixed models 1: One grouping factor, random intercepts</a><ul>
<li class="chapter" data-level="7.8.1" data-path="lmem.html"><a href="lmem.html#c6model1A"><i class="fa fa-check"></i><b>7.8.1</b> Model 1A: Simple linear regression</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="lmem.html"><a href="lmem.html#section-205"><i class="fa fa-check"></i><b>7.9</b> </a></li>
<li class="chapter" data-level="7.10" data-path="lmem.html"><a href="lmem.html#call-20"><i class="fa fa-check"></i><b>7.10</b> Call:</a></li>
<li class="chapter" data-level="7.11" data-path="lmem.html"><a href="lmem.html#lmformula-acoustics-conditionlabel.williams-data-givenness"><i class="fa fa-check"></i><b>7.11</b> lm(formula = acoustics ~ conditionLabel.williams, data = givenness)</a></li>
<li class="chapter" data-level="7.12" data-path="lmem.html"><a href="lmem.html#section-206"><i class="fa fa-check"></i><b>7.12</b> </a></li>
<li class="chapter" data-level="7.13" data-path="lmem.html"><a href="lmem.html#residuals-17"><i class="fa fa-check"></i><b>7.13</b> Residuals:</a></li>
<li class="chapter" data-level="7.14" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-21"><i class="fa fa-check"></i><b>7.14</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.15" data-path="lmem.html"><a href="lmem.html#section-207"><i class="fa fa-check"></i><b>7.15</b> -2.31843 -0.56264 0.01977 0.53651 2.50851</a></li>
<li class="chapter" data-level="7.16" data-path="lmem.html"><a href="lmem.html#section-208"><i class="fa fa-check"></i><b>7.16</b> </a></li>
<li class="chapter" data-level="7.17" data-path="lmem.html"><a href="lmem.html#coefficients-19"><i class="fa fa-check"></i><b>7.17</b> Coefficients:</a></li>
<li class="chapter" data-level="7.18" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-t-value-prt-16"><i class="fa fa-check"></i><b>7.18</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="7.19" data-path="lmem.html"><a href="lmem.html#intercept--0.72205-0.04109--17.570-2e-16-conditionlabel.williams-0.31774-0.08224-3.863-0.000131"><i class="fa fa-check"></i><b>7.19</b> (Intercept) -0.72205 0.04109 -17.570 &lt; 2e-16 <strong><em> ## conditionLabel.williams 0.31774 0.08224 3.863 0.000131 </em></strong></a></li>
<li class="chapter" data-level="7.20" data-path="lmem.html"><a href="lmem.html#section-209"><i class="fa fa-check"></i><b>7.20</b> —</a></li>
<li class="chapter" data-level="7.21" data-path="lmem.html"><a href="lmem.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-19"><i class="fa fa-check"></i><b>7.21</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="7.22" data-path="lmem.html"><a href="lmem.html#section-210"><i class="fa fa-check"></i><b>7.22</b> </a></li>
<li class="chapter" data-level="7.23" data-path="lmem.html"><a href="lmem.html#residual-standard-error-0.8032-on-380-degrees-of-freedom-3"><i class="fa fa-check"></i><b>7.23</b> Residual standard error: 0.8032 on 380 degrees of freedom</a></li>
<li class="chapter" data-level="7.24" data-path="lmem.html"><a href="lmem.html#multiple-r-squared-0.03779-adjusted-r-squared-0.03526-3"><i class="fa fa-check"></i><b>7.24</b> Multiple R-squared: 0.03779, Adjusted R-squared: 0.03526</a></li>
<li class="chapter" data-level="7.25" data-path="lmem.html"><a href="lmem.html#f-statistic-14.93-on-1-and-380-df-p-value-0.0001315-3"><i class="fa fa-check"></i><b>7.25</b> F-statistic: 14.93 on 1 and 380 DF, p-value: 0.0001315</a><ul>
<li class="chapter" data-level="7.25.1" data-path="lmem.html"><a href="lmem.html#c6model1b"><i class="fa fa-check"></i><b>7.25.1</b> Model 1B: Random intercept only</a></li>
</ul></li>
<li class="chapter" data-level="7.26" data-path="lmem.html"><a href="lmem.html#linear-mixed-model-fit-by-reml-lmermod"><i class="fa fa-check"></i><b>7.26</b> Linear mixed model fit by REML [‘lmerMod’]</a></li>
<li class="chapter" data-level="7.27" data-path="lmem.html"><a href="lmem.html#formula-acoustics-conditionlabel.williams-1-participant"><i class="fa fa-check"></i><b>7.27</b> Formula: acoustics ~ conditionLabel.williams + (1 | participant)</a></li>
<li class="chapter" data-level="7.28" data-path="lmem.html"><a href="lmem.html#data-givenness-1"><i class="fa fa-check"></i><b>7.28</b> Data: givenness</a></li>
<li class="chapter" data-level="7.29" data-path="lmem.html"><a href="lmem.html#section-211"><i class="fa fa-check"></i><b>7.29</b> </a></li>
<li class="chapter" data-level="7.30" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence-897.9"><i class="fa fa-check"></i><b>7.30</b> REML criterion at convergence: 897.9</a></li>
<li class="chapter" data-level="7.31" data-path="lmem.html"><a href="lmem.html#section-212"><i class="fa fa-check"></i><b>7.31</b> </a></li>
<li class="chapter" data-level="7.32" data-path="lmem.html"><a href="lmem.html#scaled-residuals"><i class="fa fa-check"></i><b>7.32</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.33" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-22"><i class="fa fa-check"></i><b>7.33</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.34" data-path="lmem.html"><a href="lmem.html#section-213"><i class="fa fa-check"></i><b>7.34</b> -3.0538 -0.7129 0.0083 0.6540 3.3136</a></li>
<li class="chapter" data-level="7.35" data-path="lmem.html"><a href="lmem.html#section-214"><i class="fa fa-check"></i><b>7.35</b> </a></li>
<li class="chapter" data-level="7.36" data-path="lmem.html"><a href="lmem.html#random-effects"><i class="fa fa-check"></i><b>7.36</b> Random effects:</a></li>
<li class="chapter" data-level="7.37" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev."><i class="fa fa-check"></i><b>7.37</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.38" data-path="lmem.html"><a href="lmem.html#participant-intercept-0.08937-0.299"><i class="fa fa-check"></i><b>7.38</b> participant (Intercept) 0.08937 0.299</a></li>
<li class="chapter" data-level="7.39" data-path="lmem.html"><a href="lmem.html#residual-0.55800-0.747"><i class="fa fa-check"></i><b>7.39</b> Residual 0.55800 0.747</a></li>
<li class="chapter" data-level="7.40" data-path="lmem.html"><a href="lmem.html#number-of-obs-382-groups-participant-27"><i class="fa fa-check"></i><b>7.40</b> Number of obs: 382, groups: participant, 27</a></li>
<li class="chapter" data-level="7.41" data-path="lmem.html"><a href="lmem.html#section-215"><i class="fa fa-check"></i><b>7.41</b> </a></li>
<li class="chapter" data-level="7.42" data-path="lmem.html"><a href="lmem.html#fixed-effects"><i class="fa fa-check"></i><b>7.42</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.43" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-t-value"><i class="fa fa-check"></i><b>7.43</b> Estimate Std. Error t value</a></li>
<li class="chapter" data-level="7.44" data-path="lmem.html"><a href="lmem.html#intercept--0.71856-0.06916--10.39"><i class="fa fa-check"></i><b>7.44</b> (Intercept) -0.71856 0.06916 -10.39</a></li>
<li class="chapter" data-level="7.45" data-path="lmem.html"><a href="lmem.html#conditionlabel.williams-0.32626-0.07677-4.25"><i class="fa fa-check"></i><b>7.45</b> conditionLabel.williams 0.32626 0.07677 4.25</a></li>
<li class="chapter" data-level="7.46" data-path="lmem.html"><a href="lmem.html#section-216"><i class="fa fa-check"></i><b>7.46</b> </a></li>
<li class="chapter" data-level="7.47" data-path="lmem.html"><a href="lmem.html#correlation-of-fixed-effects"><i class="fa fa-check"></i><b>7.47</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="7.48" data-path="lmem.html"><a href="lmem.html#intr"><i class="fa fa-check"></i><b>7.48</b> (Intr)</a></li>
<li class="chapter" data-level="7.49" data-path="lmem.html"><a href="lmem.html#cndtnlbl.wl-0.002"><i class="fa fa-check"></i><b>7.49</b> cndtnLbl.wl 0.002</a></li>
<li class="chapter" data-level="7.50" data-path="lmem.html"><a href="lmem.html#intercept"><i class="fa fa-check"></i><b>7.50</b> (Intercept)</a></li>
<li class="chapter" data-level="7.51" data-path="lmem.html"><a href="lmem.html#section-217"><i class="fa fa-check"></i><b>7.51</b> 24 0.085333501</a></li>
<li class="chapter" data-level="7.52" data-path="lmem.html"><a href="lmem.html#section-218"><i class="fa fa-check"></i><b>7.52</b> 297 0.036820472</a></li>
<li class="chapter" data-level="7.53" data-path="lmem.html"><a href="lmem.html#section-219"><i class="fa fa-check"></i><b>7.53</b> 432 -0.411839925</a></li>
<li class="chapter" data-level="7.54" data-path="lmem.html"><a href="lmem.html#section-220"><i class="fa fa-check"></i><b>7.54</b> 524 0.116659623</a></li>
<li class="chapter" data-level="7.55" data-path="lmem.html"><a href="lmem.html#section-221"><i class="fa fa-check"></i><b>7.55</b> 529 -0.485395105</a></li>
<li class="chapter" data-level="7.56" data-path="lmem.html"><a href="lmem.html#section-222"><i class="fa fa-check"></i><b>7.56</b> 530 -0.077424563</a></li>
<li class="chapter" data-level="7.57" data-path="lmem.html"><a href="lmem.html#section-223"><i class="fa fa-check"></i><b>7.57</b> 540 0.244536341</a></li>
<li class="chapter" data-level="7.58" data-path="lmem.html"><a href="lmem.html#section-224"><i class="fa fa-check"></i><b>7.58</b> 541 0.193392070</a></li>
<li class="chapter" data-level="7.59" data-path="lmem.html"><a href="lmem.html#section-225"><i class="fa fa-check"></i><b>7.59</b> 542 -0.126468368</a></li>
<li class="chapter" data-level="7.60" data-path="lmem.html"><a href="lmem.html#section-226"><i class="fa fa-check"></i><b>7.60</b> 544 0.012462384</a></li>
<li class="chapter" data-level="7.61" data-path="lmem.html"><a href="lmem.html#section-227"><i class="fa fa-check"></i><b>7.61</b> 547 -0.335559107</a></li>
<li class="chapter" data-level="7.62" data-path="lmem.html"><a href="lmem.html#section-228"><i class="fa fa-check"></i><b>7.62</b> 548 0.489860310</a></li>
<li class="chapter" data-level="7.63" data-path="lmem.html"><a href="lmem.html#section-229"><i class="fa fa-check"></i><b>7.63</b> 549 -0.135853392</a></li>
<li class="chapter" data-level="7.64" data-path="lmem.html"><a href="lmem.html#section-230"><i class="fa fa-check"></i><b>7.64</b> 550 -0.047183013</a></li>
<li class="chapter" data-level="7.65" data-path="lmem.html"><a href="lmem.html#section-231"><i class="fa fa-check"></i><b>7.65</b> 552 -0.032362240</a></li>
<li class="chapter" data-level="7.66" data-path="lmem.html"><a href="lmem.html#section-232"><i class="fa fa-check"></i><b>7.66</b> 553 0.239715782</a></li>
<li class="chapter" data-level="7.67" data-path="lmem.html"><a href="lmem.html#section-233"><i class="fa fa-check"></i><b>7.67</b> 554 -0.045139278</a></li>
<li class="chapter" data-level="7.68" data-path="lmem.html"><a href="lmem.html#section-234"><i class="fa fa-check"></i><b>7.68</b> 555 -0.204230783</a></li>
<li class="chapter" data-level="7.69" data-path="lmem.html"><a href="lmem.html#section-235"><i class="fa fa-check"></i><b>7.69</b> 556 -0.104644687</a></li>
<li class="chapter" data-level="7.70" data-path="lmem.html"><a href="lmem.html#section-236"><i class="fa fa-check"></i><b>7.70</b> 557 0.199844627</a></li>
<li class="chapter" data-level="7.71" data-path="lmem.html"><a href="lmem.html#section-237"><i class="fa fa-check"></i><b>7.71</b> 558 0.004117646</a></li>
<li class="chapter" data-level="7.72" data-path="lmem.html"><a href="lmem.html#section-238"><i class="fa fa-check"></i><b>7.72</b> 559 -0.336348686</a></li>
<li class="chapter" data-level="7.73" data-path="lmem.html"><a href="lmem.html#section-239"><i class="fa fa-check"></i><b>7.73</b> 560 0.307842484</a></li>
<li class="chapter" data-level="7.74" data-path="lmem.html"><a href="lmem.html#section-240"><i class="fa fa-check"></i><b>7.74</b> 561 0.530048433</a></li>
<li class="chapter" data-level="7.75" data-path="lmem.html"><a href="lmem.html#section-241"><i class="fa fa-check"></i><b>7.75</b> 562 -0.163493454</a></li>
<li class="chapter" data-level="7.76" data-path="lmem.html"><a href="lmem.html#section-242"><i class="fa fa-check"></i><b>7.76</b> 563 -0.072168272</a></li>
<li class="chapter" data-level="7.77" data-path="lmem.html"><a href="lmem.html#section-243"><i class="fa fa-check"></i><b>7.77</b> 564 0.117477201</a></li>
<li class="chapter" data-level="7.78" data-path="lmem.html"><a href="lmem.html#intercept-1"><i class="fa fa-check"></i><b>7.78</b> (Intercept)</a></li>
<li class="chapter" data-level="7.79" data-path="lmem.html"><a href="lmem.html#section-244"><i class="fa fa-check"></i><b>7.79</b> 24 0.1583862</a></li>
<li class="chapter" data-level="7.80" data-path="lmem.html"><a href="lmem.html#section-245"><i class="fa fa-check"></i><b>7.80</b> 297 0.1620712</a></li>
<li class="chapter" data-level="7.81" data-path="lmem.html"><a href="lmem.html#section-246"><i class="fa fa-check"></i><b>7.81</b> 432 0.1620712</a></li>
<li class="chapter" data-level="7.82" data-path="lmem.html"><a href="lmem.html#section-247"><i class="fa fa-check"></i><b>7.82</b> 524 0.1853443</a></li>
<li class="chapter" data-level="7.83" data-path="lmem.html"><a href="lmem.html#section-248"><i class="fa fa-check"></i><b>7.83</b> 529 0.1660260</a></li>
<li class="chapter" data-level="7.84" data-path="lmem.html"><a href="lmem.html#section-249"><i class="fa fa-check"></i><b>7.84</b> 530 0.1620712</a></li>
<li class="chapter" data-level="7.85" data-path="lmem.html"><a href="lmem.html#section-250"><i class="fa fa-check"></i><b>7.85</b> 540 0.1660260</a></li>
<li class="chapter" data-level="7.86" data-path="lmem.html"><a href="lmem.html#section-251"><i class="fa fa-check"></i><b>7.86</b> 541 0.1660260</a></li>
<li class="chapter" data-level="7.87" data-path="lmem.html"><a href="lmem.html#section-252"><i class="fa fa-check"></i><b>7.87</b> 542 0.1583862</a></li>
<li class="chapter" data-level="7.88" data-path="lmem.html"><a href="lmem.html#section-253"><i class="fa fa-check"></i><b>7.88</b> 544 0.1748900</a></li>
<li class="chapter" data-level="7.89" data-path="lmem.html"><a href="lmem.html#section-254"><i class="fa fa-check"></i><b>7.89</b> 547 0.1620712</a></li>
<li class="chapter" data-level="7.90" data-path="lmem.html"><a href="lmem.html#section-255"><i class="fa fa-check"></i><b>7.90</b> 548 0.1660260</a></li>
<li class="chapter" data-level="7.91" data-path="lmem.html"><a href="lmem.html#section-256"><i class="fa fa-check"></i><b>7.91</b> 549 0.1583862</a></li>
<li class="chapter" data-level="7.92" data-path="lmem.html"><a href="lmem.html#section-257"><i class="fa fa-check"></i><b>7.92</b> 550 0.1620712</a></li>
<li class="chapter" data-level="7.93" data-path="lmem.html"><a href="lmem.html#section-258"><i class="fa fa-check"></i><b>7.93</b> 552 0.1748900</a></li>
<li class="chapter" data-level="7.94" data-path="lmem.html"><a href="lmem.html#section-259"><i class="fa fa-check"></i><b>7.94</b> 553 0.1660260</a></li>
<li class="chapter" data-level="7.95" data-path="lmem.html"><a href="lmem.html#section-260"><i class="fa fa-check"></i><b>7.95</b> 554 0.1620712</a></li>
<li class="chapter" data-level="7.96" data-path="lmem.html"><a href="lmem.html#section-261"><i class="fa fa-check"></i><b>7.96</b> 555 0.1620712</a></li>
<li class="chapter" data-level="7.97" data-path="lmem.html"><a href="lmem.html#section-262"><i class="fa fa-check"></i><b>7.97</b> 556 0.1620712</a></li>
<li class="chapter" data-level="7.98" data-path="lmem.html"><a href="lmem.html#section-263"><i class="fa fa-check"></i><b>7.98</b> 557 0.1660260</a></li>
<li class="chapter" data-level="7.99" data-path="lmem.html"><a href="lmem.html#section-264"><i class="fa fa-check"></i><b>7.99</b> 558 0.1660260</a></li>
<li class="chapter" data-level="7.100" data-path="lmem.html"><a href="lmem.html#section-265"><i class="fa fa-check"></i><b>7.100</b> 559 0.1702852</a></li>
<li class="chapter" data-level="7.101" data-path="lmem.html"><a href="lmem.html#section-266"><i class="fa fa-check"></i><b>7.101</b> 560 0.1660260</a></li>
<li class="chapter" data-level="7.102" data-path="lmem.html"><a href="lmem.html#section-267"><i class="fa fa-check"></i><b>7.102</b> 561 0.1620712</a></li>
<li class="chapter" data-level="7.103" data-path="lmem.html"><a href="lmem.html#section-268"><i class="fa fa-check"></i><b>7.103</b> 562 0.1583862</a></li>
<li class="chapter" data-level="7.104" data-path="lmem.html"><a href="lmem.html#section-269"><i class="fa fa-check"></i><b>7.104</b> 563 0.1798897</a></li>
<li class="chapter" data-level="7.105" data-path="lmem.html"><a href="lmem.html#section-270"><i class="fa fa-check"></i><b>7.105</b> 564 0.1702852</a></li>
<li class="chapter" data-level="7.106" data-path="lmem.html"><a href="lmem.html#model-1b-random-intercept-only"><i class="fa fa-check"></i><b>7.106</b> MODEL 1B: random intercept only</a></li>
<li class="chapter" data-level="7.107" data-path="lmem.html"><a href="lmem.html#set-up-a-dataframe-for-which-the-model-should-predict-new-values"><i class="fa fa-check"></i><b>7.107</b> set up a dataframe for which the model should predict new values:</a></li>
<li class="chapter" data-level="7.108" data-path="lmem.html"><a href="lmem.html#each-level-of-conditionlabel-for-each-participant."><i class="fa fa-check"></i><b>7.108</b> each level of conditionLabel, for each participant.</a></li>
<li class="chapter" data-level="7.109" data-path="lmem.html"><a href="lmem.html#its-easiest-to-understand-this-if-we-first-refit-a-version-of-mod1b-using-the-factor-version-of-conditionlabel-rather-than-the-numeric-conditionlabel.williams-version"><i class="fa fa-check"></i><b>7.109</b> it’s easiest to understand this if we first refit a version of mod1b using the <em>factor</em> version of conditionLabel (rather than the numeric conditionLabel.williams version)</a></li>
<li class="chapter" data-level="7.110" data-path="lmem.html"><a href="lmem.html#set-up-a-dataframe-to-predict-values-for-one-row-per-participantcond-label-pair"><i class="fa fa-check"></i><b>7.110</b> set up a dataframe to predict values for: one row per participant/cond label pair</a></li>
<li class="chapter" data-level="7.111" data-path="lmem.html"><a href="lmem.html#get-the-predicted-value-for-each-case"><i class="fa fa-check"></i><b>7.111</b> get the predicted value for each case</a></li>
<li class="chapter" data-level="7.112" data-path="lmem.html"><a href="lmem.html#plot-the-models-prediction-for-each-participant"><i class="fa fa-check"></i><b>7.112</b> plot the model’s prediction for each participant:</a></li>
<li class="chapter" data-level="7.113" data-path="lmem.html"><a href="lmem.html#get-the-same-predictions-but-for-model-1.-first-fit-a-version-with-the-factor-for-conditionlabel"><i class="fa fa-check"></i><b>7.113</b> get the same predictions but for model 1. first fit a version with the factor for conditionlabel:</a></li>
<li class="chapter" data-level="7.114" data-path="lmem.html"><a href="lmem.html#empirical-mean-acoustic-values-by-participant"><i class="fa fa-check"></i><b>7.114</b> empirical mean acoustic values by participant</a></li>
<li class="chapter" data-level="7.115" data-path="lmem.html"><a href="lmem.html#participant-random-effects"><i class="fa fa-check"></i><b>7.115</b> participant random effects</a></li>
<li class="chapter" data-level="7.116" data-path="lmem.html"><a href="lmem.html#c6lmm2"><i class="fa fa-check"></i><b>7.116</b> Linear mixed models 2: One grouping factor, random intercepts and slopes</a><ul>
<li class="chapter" data-level="7.116.1" data-path="lmem.html"><a href="lmem.html#c6model1c"><i class="fa fa-check"></i><b>7.116.1</b> Model 1C</a></li>
<li class="chapter" data-level="7.116.2" data-path="lmem.html"><a href="lmem.html#fitting-model-1c"><i class="fa fa-check"></i><b>7.116.2</b> Fitting Model 1C</a></li>
</ul></li>
<li class="chapter" data-level="7.117" data-path="lmem.html"><a href="lmem.html#linear-mixed-model-fit-by-reml-lmermod-1"><i class="fa fa-check"></i><b>7.117</b> Linear mixed model fit by REML [‘lmerMod’]</a></li>
<li class="chapter" data-level="7.118" data-path="lmem.html"><a href="lmem.html#formula"><i class="fa fa-check"></i><b>7.118</b> Formula:</a></li>
<li class="chapter" data-level="7.119" data-path="lmem.html"><a href="lmem.html#rhymerating-relduration-1-participant-0-relduration"><i class="fa fa-check"></i><b>7.119</b> rhymeRating ~ relDuration + ((1 | participant) + (0 + relDuration |</a></li>
<li class="chapter" data-level="7.120" data-path="lmem.html"><a href="lmem.html#participant"><i class="fa fa-check"></i><b>7.120</b> participant))</a></li>
<li class="chapter" data-level="7.121" data-path="lmem.html"><a href="lmem.html#data-halfrhyme"><i class="fa fa-check"></i><b>7.121</b> Data: halfrhyme</a></li>
<li class="chapter" data-level="7.122" data-path="lmem.html"><a href="lmem.html#section-271"><i class="fa fa-check"></i><b>7.122</b> </a></li>
<li class="chapter" data-level="7.123" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence-2578.7"><i class="fa fa-check"></i><b>7.123</b> REML criterion at convergence: 2578.7</a></li>
<li class="chapter" data-level="7.124" data-path="lmem.html"><a href="lmem.html#section-272"><i class="fa fa-check"></i><b>7.124</b> </a></li>
<li class="chapter" data-level="7.125" data-path="lmem.html"><a href="lmem.html#scaled-residuals-1"><i class="fa fa-check"></i><b>7.125</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.126" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-23"><i class="fa fa-check"></i><b>7.126</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.127" data-path="lmem.html"><a href="lmem.html#section-273"><i class="fa fa-check"></i><b>7.127</b> -2.4022 -0.6091 -0.1126 0.6138 3.5726</a></li>
<li class="chapter" data-level="7.128" data-path="lmem.html"><a href="lmem.html#section-274"><i class="fa fa-check"></i><b>7.128</b> </a></li>
<li class="chapter" data-level="7.129" data-path="lmem.html"><a href="lmem.html#random-effects-1"><i class="fa fa-check"></i><b>7.129</b> Random effects:</a></li>
<li class="chapter" data-level="7.130" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev.-1"><i class="fa fa-check"></i><b>7.130</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.131" data-path="lmem.html"><a href="lmem.html#participant-intercept-1.267-1.126"><i class="fa fa-check"></i><b>7.131</b> participant (Intercept) 1.267 1.126</a></li>
<li class="chapter" data-level="7.132" data-path="lmem.html"><a href="lmem.html#participant.1-relduration-4.482-2.117"><i class="fa fa-check"></i><b>7.132</b> participant.1 relDuration 4.482 2.117</a></li>
<li class="chapter" data-level="7.133" data-path="lmem.html"><a href="lmem.html#residual-1.552-1.246"><i class="fa fa-check"></i><b>7.133</b> Residual 1.552 1.246</a></li>
<li class="chapter" data-level="7.134" data-path="lmem.html"><a href="lmem.html#number-of-obs-756-groups-participant-31"><i class="fa fa-check"></i><b>7.134</b> Number of obs: 756, groups: participant, 31</a></li>
<li class="chapter" data-level="7.135" data-path="lmem.html"><a href="lmem.html#section-275"><i class="fa fa-check"></i><b>7.135</b> </a></li>
<li class="chapter" data-level="7.136" data-path="lmem.html"><a href="lmem.html#fixed-effects-1"><i class="fa fa-check"></i><b>7.136</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.137" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-t-value-1"><i class="fa fa-check"></i><b>7.137</b> Estimate Std. Error t value</a></li>
<li class="chapter" data-level="7.138" data-path="lmem.html"><a href="lmem.html#intercept-3.3003-0.2125-15.533"><i class="fa fa-check"></i><b>7.138</b> (Intercept) 3.3003 0.2125 15.533</a></li>
<li class="chapter" data-level="7.139" data-path="lmem.html"><a href="lmem.html#relduration-2.7249-0.7816-3.486"><i class="fa fa-check"></i><b>7.139</b> relDuration 2.7249 0.7816 3.486</a></li>
<li class="chapter" data-level="7.140" data-path="lmem.html"><a href="lmem.html#section-276"><i class="fa fa-check"></i><b>7.140</b> </a></li>
<li class="chapter" data-level="7.141" data-path="lmem.html"><a href="lmem.html#correlation-of-fixed-effects-1"><i class="fa fa-check"></i><b>7.141</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="7.142" data-path="lmem.html"><a href="lmem.html#intr-1"><i class="fa fa-check"></i><b>7.142</b> (Intr)</a></li>
<li class="chapter" data-level="7.143" data-path="lmem.html"><a href="lmem.html#relduration-0.192"><i class="fa fa-check"></i><b>7.143</b> relDuration 0.192</a></li>
<li class="chapter" data-level="7.144" data-path="lmem.html"><a href="lmem.html#get-model-predictions-for-mod1c-for-each-participant"><i class="fa fa-check"></i><b>7.144</b> get model predictions for mod1c for each participant</a></li>
<li class="chapter" data-level="7.145" data-path="lmem.html"><a href="lmem.html#first-set-up-a-prediction-frame-say-from-min-to-max-values-of-relduration-in-the-data-for-each-participant"><i class="fa fa-check"></i><b>7.145</b> first, set up a prediction frame, say from min to max values of relDuration in the data, for each participant</a></li>
<li class="chapter" data-level="7.146" data-path="lmem.html"><a href="lmem.html#get-the-predicted-value-for-each-case-1"><i class="fa fa-check"></i><b>7.146</b> get the predicted value for each case</a></li>
<li class="chapter" data-level="7.147" data-path="lmem.html"><a href="lmem.html#plot-the-models-prediction-for-each-participant-1"><i class="fa fa-check"></i><b>7.147</b> plot the model’s prediction for each participant:</a></li>
<li class="chapter" data-level="7.148" data-path="lmem.html"><a href="lmem.html#linear-mixed-models-3-two-grouping-factors"><i class="fa fa-check"></i><b>7.148</b> Linear mixed models 3: Two grouping factors</a><ul>
<li class="chapter" data-level="7.148.1" data-path="lmem.html"><a href="lmem.html#c6model2A"><i class="fa fa-check"></i><b>7.148.1</b> Model 2A: By-participant and by-item random intercepts</a></li>
</ul></li>
<li class="chapter" data-level="7.149" data-path="lmem.html"><a href="lmem.html#linear-mixed-model-fit-by-reml-lmermod-2"><i class="fa fa-check"></i><b>7.149</b> Linear mixed model fit by REML [‘lmerMod’]</a></li>
<li class="chapter" data-level="7.150" data-path="lmem.html"><a href="lmem.html#formula-acoustics-conditionlabel.williams-1-participant-1"><i class="fa fa-check"></i><b>7.150</b> Formula: acoustics ~ conditionLabel.williams + (1 | participant) + (1 |</a></li>
<li class="chapter" data-level="7.151" data-path="lmem.html"><a href="lmem.html#item"><i class="fa fa-check"></i><b>7.151</b> item)</a></li>
<li class="chapter" data-level="7.152" data-path="lmem.html"><a href="lmem.html#data-givenness-2"><i class="fa fa-check"></i><b>7.152</b> Data: givenness</a></li>
<li class="chapter" data-level="7.153" data-path="lmem.html"><a href="lmem.html#section-277"><i class="fa fa-check"></i><b>7.153</b> </a></li>
<li class="chapter" data-level="7.154" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence-887"><i class="fa fa-check"></i><b>7.154</b> REML criterion at convergence: 887</a></li>
<li class="chapter" data-level="7.155" data-path="lmem.html"><a href="lmem.html#section-278"><i class="fa fa-check"></i><b>7.155</b> </a></li>
<li class="chapter" data-level="7.156" data-path="lmem.html"><a href="lmem.html#scaled-residuals-2"><i class="fa fa-check"></i><b>7.156</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.157" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-24"><i class="fa fa-check"></i><b>7.157</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.158" data-path="lmem.html"><a href="lmem.html#section-279"><i class="fa fa-check"></i><b>7.158</b> -2.7608 -0.6026 -0.0187 0.6293 3.2908</a></li>
<li class="chapter" data-level="7.159" data-path="lmem.html"><a href="lmem.html#section-280"><i class="fa fa-check"></i><b>7.159</b> </a></li>
<li class="chapter" data-level="7.160" data-path="lmem.html"><a href="lmem.html#random-effects-2"><i class="fa fa-check"></i><b>7.160</b> Random effects:</a></li>
<li class="chapter" data-level="7.161" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev.-2"><i class="fa fa-check"></i><b>7.161</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.162" data-path="lmem.html"><a href="lmem.html#participant-intercept-0.09266-0.3044"><i class="fa fa-check"></i><b>7.162</b> participant (Intercept) 0.09266 0.3044</a></li>
<li class="chapter" data-level="7.163" data-path="lmem.html"><a href="lmem.html#item-intercept-0.04108-0.2027"><i class="fa fa-check"></i><b>7.163</b> item (Intercept) 0.04108 0.2027</a></li>
<li class="chapter" data-level="7.164" data-path="lmem.html"><a href="lmem.html#residual-0.51732-0.7192"><i class="fa fa-check"></i><b>7.164</b> Residual 0.51732 0.7192</a></li>
<li class="chapter" data-level="7.165" data-path="lmem.html"><a href="lmem.html#number-of-obs-382-groups-participant-27-item-16"><i class="fa fa-check"></i><b>7.165</b> Number of obs: 382, groups: participant, 27; item, 16</a></li>
<li class="chapter" data-level="7.166" data-path="lmem.html"><a href="lmem.html#section-281"><i class="fa fa-check"></i><b>7.166</b> </a></li>
<li class="chapter" data-level="7.167" data-path="lmem.html"><a href="lmem.html#fixed-effects-2"><i class="fa fa-check"></i><b>7.167</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.168" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-t-value-2"><i class="fa fa-check"></i><b>7.168</b> Estimate Std. Error t value</a></li>
<li class="chapter" data-level="7.169" data-path="lmem.html"><a href="lmem.html#intercept--0.71655-0.08585--8.347"><i class="fa fa-check"></i><b>7.169</b> (Intercept) -0.71655 0.08585 -8.347</a></li>
<li class="chapter" data-level="7.170" data-path="lmem.html"><a href="lmem.html#conditionlabel.williams-0.33771-0.07406-4.560"><i class="fa fa-check"></i><b>7.170</b> conditionLabel.williams 0.33771 0.07406 4.560</a></li>
<li class="chapter" data-level="7.171" data-path="lmem.html"><a href="lmem.html#section-282"><i class="fa fa-check"></i><b>7.171</b> </a></li>
<li class="chapter" data-level="7.172" data-path="lmem.html"><a href="lmem.html#correlation-of-fixed-effects-2"><i class="fa fa-check"></i><b>7.172</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="7.173" data-path="lmem.html"><a href="lmem.html#intr-2"><i class="fa fa-check"></i><b>7.173</b> (Intr)</a></li>
<li class="chapter" data-level="7.174" data-path="lmem.html"><a href="lmem.html#cndtnlbl.wl-0.001"><i class="fa fa-check"></i><b>7.174</b> cndtnLbl.wl 0.001</a></li>
<li class="chapter" data-level="7.175" data-path="lmem.html"><a href="lmem.html#evaluating-lmms"><i class="fa fa-check"></i><b>7.175</b> Evaluating LMMs</a><ul>
<li class="chapter" data-level="7.175.1" data-path="lmem.html"><a href="lmem.html#hypothesis-testing-2"><i class="fa fa-check"></i><b>7.175.1</b> Hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="7.176" data-path="lmem.html"><a href="lmem.html#linear-mixed-model-fit-by-reml-lmermod-3"><i class="fa fa-check"></i><b>7.176</b> Linear mixed model fit by REML [‘lmerMod’]</a></li>
<li class="chapter" data-level="7.177" data-path="lmem.html"><a href="lmem.html#formula-acoustics-conditionlabel.williams-1-participant-1-1"><i class="fa fa-check"></i><b>7.177</b> Formula: acoustics ~ conditionLabel.williams + (1 | participant) + (1 |</a></li>
<li class="chapter" data-level="7.178" data-path="lmem.html"><a href="lmem.html#item-1"><i class="fa fa-check"></i><b>7.178</b> item)</a></li>
<li class="chapter" data-level="7.179" data-path="lmem.html"><a href="lmem.html#data-givenness-3"><i class="fa fa-check"></i><b>7.179</b> Data: givenness</a></li>
<li class="chapter" data-level="7.180" data-path="lmem.html"><a href="lmem.html#section-283"><i class="fa fa-check"></i><b>7.180</b> </a></li>
<li class="chapter" data-level="7.181" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence-887-1"><i class="fa fa-check"></i><b>7.181</b> REML criterion at convergence: 887</a></li>
<li class="chapter" data-level="7.182" data-path="lmem.html"><a href="lmem.html#section-284"><i class="fa fa-check"></i><b>7.182</b> </a></li>
<li class="chapter" data-level="7.183" data-path="lmem.html"><a href="lmem.html#scaled-residuals-3"><i class="fa fa-check"></i><b>7.183</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.184" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-25"><i class="fa fa-check"></i><b>7.184</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.185" data-path="lmem.html"><a href="lmem.html#section-285"><i class="fa fa-check"></i><b>7.185</b> -2.7608 -0.6026 -0.0187 0.6293 3.2908</a></li>
<li class="chapter" data-level="7.186" data-path="lmem.html"><a href="lmem.html#section-286"><i class="fa fa-check"></i><b>7.186</b> </a></li>
<li class="chapter" data-level="7.187" data-path="lmem.html"><a href="lmem.html#random-effects-3"><i class="fa fa-check"></i><b>7.187</b> Random effects:</a></li>
<li class="chapter" data-level="7.188" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev.-3"><i class="fa fa-check"></i><b>7.188</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.189" data-path="lmem.html"><a href="lmem.html#participant-intercept-0.09266-0.3044-1"><i class="fa fa-check"></i><b>7.189</b> participant (Intercept) 0.09266 0.3044</a></li>
<li class="chapter" data-level="7.190" data-path="lmem.html"><a href="lmem.html#item-intercept-0.04108-0.2027-1"><i class="fa fa-check"></i><b>7.190</b> item (Intercept) 0.04108 0.2027</a></li>
<li class="chapter" data-level="7.191" data-path="lmem.html"><a href="lmem.html#residual-0.51732-0.7192-1"><i class="fa fa-check"></i><b>7.191</b> Residual 0.51732 0.7192</a></li>
<li class="chapter" data-level="7.192" data-path="lmem.html"><a href="lmem.html#number-of-obs-382-groups-participant-27-item-16-1"><i class="fa fa-check"></i><b>7.192</b> Number of obs: 382, groups: participant, 27; item, 16</a></li>
<li class="chapter" data-level="7.193" data-path="lmem.html"><a href="lmem.html#section-287"><i class="fa fa-check"></i><b>7.193</b> </a></li>
<li class="chapter" data-level="7.194" data-path="lmem.html"><a href="lmem.html#fixed-effects-3"><i class="fa fa-check"></i><b>7.194</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.195" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-t-value-3"><i class="fa fa-check"></i><b>7.195</b> Estimate Std. Error t value</a></li>
<li class="chapter" data-level="7.196" data-path="lmem.html"><a href="lmem.html#intercept--0.71655-0.08585--8.347-1"><i class="fa fa-check"></i><b>7.196</b> (Intercept) -0.71655 0.08585 -8.347</a></li>
<li class="chapter" data-level="7.197" data-path="lmem.html"><a href="lmem.html#conditionlabel.williams-0.33771-0.07406-4.560-1"><i class="fa fa-check"></i><b>7.197</b> conditionLabel.williams 0.33771 0.07406 4.560</a></li>
<li class="chapter" data-level="7.198" data-path="lmem.html"><a href="lmem.html#section-288"><i class="fa fa-check"></i><b>7.198</b> </a></li>
<li class="chapter" data-level="7.199" data-path="lmem.html"><a href="lmem.html#correlation-of-fixed-effects-3"><i class="fa fa-check"></i><b>7.199</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="7.200" data-path="lmem.html"><a href="lmem.html#intr-3"><i class="fa fa-check"></i><b>7.200</b> (Intr)</a></li>
<li class="chapter" data-level="7.201" data-path="lmem.html"><a href="lmem.html#cndtnlbl.wl-0.001-1"><i class="fa fa-check"></i><b>7.201</b> cndtnLbl.wl 0.001</a><ul>
<li class="chapter" data-level="7.201.1" data-path="lmem.html"><a href="lmem.html#significance-of-a-random-effect-term"><i class="fa fa-check"></i><b>7.201.1</b> Significance of a random effect term</a></li>
</ul></li>
<li class="chapter" data-level="7.202" data-path="lmem.html"><a href="lmem.html#refitting-models-with-ml-instead-of-reml"><i class="fa fa-check"></i><b>7.202</b> refitting model(s) with ML (instead of REML)</a></li>
<li class="chapter" data-level="7.203" data-path="lmem.html"><a href="lmem.html#data-givenness-4"><i class="fa fa-check"></i><b>7.203</b> Data: givenness</a></li>
<li class="chapter" data-level="7.204" data-path="lmem.html"><a href="lmem.html#models"><i class="fa fa-check"></i><b>7.204</b> Models:</a></li>
<li class="chapter" data-level="7.205" data-path="lmem.html"><a href="lmem.html#mod2a.1-acoustics-conditionlabel.williams-1-participant"><i class="fa fa-check"></i><b>7.205</b> mod2a.1: acoustics ~ conditionLabel.williams + (1 | participant)</a></li>
<li class="chapter" data-level="7.206" data-path="lmem.html"><a href="lmem.html#mod2a-acoustics-conditionlabel.williams-1-participant-1"><i class="fa fa-check"></i><b>7.206</b> mod2a: acoustics ~ conditionLabel.williams + (1 | participant) + (1 |</a></li>
<li class="chapter" data-level="7.207" data-path="lmem.html"><a href="lmem.html#mod2a-item"><i class="fa fa-check"></i><b>7.207</b> mod2a: item)</a></li>
<li class="chapter" data-level="7.208" data-path="lmem.html"><a href="lmem.html#df-aic-bic-loglik-deviance-chisq-chi-df-prchisq"><i class="fa fa-check"></i><b>7.208</b> Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)</a></li>
<li class="chapter" data-level="7.209" data-path="lmem.html"><a href="lmem.html#mod2a.1-4-899.07-914.86--445.54-891.07"><i class="fa fa-check"></i><b>7.209</b> mod2a.1 4 899.07 914.86 -445.54 891.07</a></li>
<li><a href="lmem.html#mod2a-5-890.58-910.31--440.29-880.58-10.49-1-0.0012-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-significance-of-fixed-effects-c6fixedp-t-statistic-1-0.04262085-likelihood-ratio-tests-refitting-models-with-ml-instead-of-reml-data-givenness-models-mod2a.1-acoustics-1-1-participant-1-item-mod2a-acoustics-conditionlabel.williams-1-participant-1-mod2a-item-df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-mod2a.1-4-908.69-924.48--450.35-900.69-mod2a-5-890.58-910.31--440.29-880.58-20.11-1-7.313e-06-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-satterthwaite-approximation-c6sattapprox-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-acoustics-conditionlabel.williams-1-participant-1-item-data-givenness-reml-criterion-at-convergence-887-scaled-residuals-min-1q-median-3q-max--2.7608--0.6026--0.0187-0.6293-3.2908-random-effects-groups-name-variance-std.dev.-participant-intercept-0.09266-0.3044-item-intercept-0.04108-0.2027-residual-0.51732-0.7192-number-of-obs-382-groups-participant-27-item-16-fixed-effects-estimate-std.-error-df-t-value-prt-intercept--0.71655-0.08585-27.88067--8.347-4.57e-09-conditionlabel.williams-0.33771-0.07406-342.45831-4.560-7.14e-06-intercept-conditionlabel.williams-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtnlbl.wl-0.001-parametric-bootstrap-fitting-2-glmer-models-..-obtaining-1-p-values-.-mixed-model-anova-table-type-3-tests-pb-method-model-acoustics-conditionlabel.williams-1-participant-1-model-item-data-givenness-effect-df-chisq-p.value-1-conditionlabel.williams-1-20.11-.0010"><span class="toc-section-number">7.210</span> mod2a 5 890.58 910.31 -440.29 880.58 10.49 1 0.0012 <strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ### Significance of fixed effects {#c6fixedp} #### <span class="math inline">\(t\)</span>-statistic ## [1] 0.04262085 #### Likelihood ratio tests ## refitting model(s) with ML (instead of REML) ## Data: givenness ## Models: ## mod2a.1: acoustics ~ 1 + (1 | participant) + (1 | item) ## mod2a: acoustics ~ conditionLabel.williams + (1 | participant) + (1 | ## mod2a: item) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)<br />
## mod2a.1 4 908.69 924.48 -450.35 900.69<br />
## mod2a 5 890.58 910.31 -440.29 880.58 20.11 1 7.313e-06 </strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 #### Satterthwaite approximation {#c6sattapprox} ## Linear mixed model fit by REML. t-tests use Satterthwaite’s method [ ## lmerModLmerTest] ## Formula: acoustics ~ conditionLabel.williams + (1 | participant) + (1 |<br />
## item) ## Data: givenness ## ## REML criterion at convergence: 887 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.7608 -0.6026 -0.0187 0.6293 3.2908 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 0.09266 0.3044<br />
## item (Intercept) 0.04108 0.2027<br />
## Residual 0.51732 0.7192<br />
## Number of obs: 382, groups: participant, 27; item, 16 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) -0.71655 0.08585 27.88067 -8.347 4.57e-09 ## conditionLabel.williams 0.33771 0.07406 342.45831 4.560 7.14e-06 ##<br />
## (Intercept) </em><strong> ## conditionLabel.williams </strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Correlation of Fixed Effects: ## (Intr) ## cndtnLbl.wl 0.001 #### Parametric bootstrap ## Fitting 2 (g)lmer() models: ## [..] ## Obtaining 1 p-values: ## [.] ## Mixed Model Anova Table (Type 3 tests, PB-method) ## ## Model: acoustics ~ conditionLabel.williams + (1 | participant) + (1 | ## Model: item) ## Data: givenness ## Effect df Chisq p.value ## 1 conditionLabel.williams 1 20.11 </em>** .0010</a></li>
<li class="chapter" data-level="7.211" data-path="lmem.html"><a href="lmem.html#section-289"><i class="fa fa-check"></i><b>7.211</b> —</a></li>
<li class="chapter" data-level="7.212" data-path="lmem.html"><a href="lmem.html#signif.-codes-0-0.001-0.01-0.05-0.1-1"><i class="fa fa-check"></i><b>7.212</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘+’ 0.1 ‘’ 1</a><ul>
<li class="chapter" data-level="7.212.1" data-path="lmem.html"><a href="lmem.html#evaluating-goodness-of-fit"><i class="fa fa-check"></i><b>7.212.1</b> Evaluating goodness of fit</a></li>
</ul></li>
<li class="chapter" data-level="7.213" data-path="lmem.html"><a href="lmem.html#section-290"><i class="fa fa-check"></i><b>7.213</b> [1] 0.03779243</a></li>
<li class="chapter" data-level="7.214" data-path="lmem.html"><a href="lmem.html#section-291"><i class="fa fa-check"></i><b>7.214</b> [1] 0.2192169</a></li>
<li class="chapter" data-level="7.215" data-path="lmem.html"><a href="lmem.html#section-292"><i class="fa fa-check"></i><b>7.215</b> [1] 0.3054109</a></li>
<li class="chapter" data-level="7.216" data-path="lmem.html"><a href="lmem.html#linear-mixed-models-4-multiple-predictors"><i class="fa fa-check"></i><b>7.216</b> Linear mixed models 4: Multiple predictors</a><ul>
<li class="chapter" data-level="7.216.1" data-path="lmem.html"><a href="lmem.html#types-of-predictors"><i class="fa fa-check"></i><b>7.216.1</b> Types of predictors</a></li>
<li class="chapter" data-level="7.216.2" data-path="lmem.html"><a href="lmem.html#c6model3A"><i class="fa fa-check"></i><b>7.216.2</b> Model 3A: Random intercepts only</a></li>
</ul></li>
<li class="chapter" data-level="7.217" data-path="lmem.html"><a href="lmem.html#model-3a-multiple-predictors-by-item-and-by-partic-random-effects"><i class="fa fa-check"></i><b>7.217</b> Model 3A: multiple predictors, by-item and by-partic random effects</a></li>
<li class="chapter" data-level="7.218" data-path="lmem.html"><a href="lmem.html#p-values-from-lmertest"><i class="fa fa-check"></i><b>7.218</b> (p-values from lmerTest)</a></li>
<li class="chapter" data-level="7.219" data-path="lmem.html"><a href="lmem.html#linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest"><i class="fa fa-check"></i><b>7.219</b> Linear mixed model fit by REML. t-tests use Satterthwaite’s method [ ## lmerModLmerTest]</a></li>
<li class="chapter" data-level="7.220" data-path="lmem.html"><a href="lmem.html#formula-1"><i class="fa fa-check"></i><b>7.220</b> Formula:</a></li>
<li class="chapter" data-level="7.221" data-path="lmem.html"><a href="lmem.html#acoustics-conditionlabel.williams-nptype.pron-voice.passive"><i class="fa fa-check"></i><b>7.221</b> acoustics ~ conditionLabel.williams * npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="7.222" data-path="lmem.html"><a href="lmem.html#order.std-1-participant-1-item"><i class="fa fa-check"></i><b>7.222</b> order.std + (1 | participant) + (1 | item)</a></li>
<li class="chapter" data-level="7.223" data-path="lmem.html"><a href="lmem.html#data-givenness-5"><i class="fa fa-check"></i><b>7.223</b> Data: givenness</a></li>
<li class="chapter" data-level="7.224" data-path="lmem.html"><a href="lmem.html#section-293"><i class="fa fa-check"></i><b>7.224</b> </a></li>
<li class="chapter" data-level="7.225" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence-758.6"><i class="fa fa-check"></i><b>7.225</b> REML criterion at convergence: 758.6</a></li>
<li class="chapter" data-level="7.226" data-path="lmem.html"><a href="lmem.html#section-294"><i class="fa fa-check"></i><b>7.226</b> </a></li>
<li class="chapter" data-level="7.227" data-path="lmem.html"><a href="lmem.html#scaled-residuals-4"><i class="fa fa-check"></i><b>7.227</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.228" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-26"><i class="fa fa-check"></i><b>7.228</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.229" data-path="lmem.html"><a href="lmem.html#section-295"><i class="fa fa-check"></i><b>7.229</b> -2.7638 -0.6535 -0.0102 0.5750 3.5847</a></li>
<li class="chapter" data-level="7.230" data-path="lmem.html"><a href="lmem.html#section-296"><i class="fa fa-check"></i><b>7.230</b> </a></li>
<li class="chapter" data-level="7.231" data-path="lmem.html"><a href="lmem.html#random-effects-4"><i class="fa fa-check"></i><b>7.231</b> Random effects:</a></li>
<li class="chapter" data-level="7.232" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev.-4"><i class="fa fa-check"></i><b>7.232</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.233" data-path="lmem.html"><a href="lmem.html#participant-intercept-0.11624-0.3409"><i class="fa fa-check"></i><b>7.233</b> participant (Intercept) 0.11624 0.3409</a></li>
<li class="chapter" data-level="7.234" data-path="lmem.html"><a href="lmem.html#item-intercept-0.03825-0.1956"><i class="fa fa-check"></i><b>7.234</b> item (Intercept) 0.03825 0.1956</a></li>
<li class="chapter" data-level="7.235" data-path="lmem.html"><a href="lmem.html#residual-0.34715-0.5892"><i class="fa fa-check"></i><b>7.235</b> Residual 0.34715 0.5892</a></li>
<li class="chapter" data-level="7.236" data-path="lmem.html"><a href="lmem.html#number-of-obs-382-groups-participant-27-item-16-2"><i class="fa fa-check"></i><b>7.236</b> Number of obs: 382, groups: participant, 27; item, 16</a></li>
<li class="chapter" data-level="7.237" data-path="lmem.html"><a href="lmem.html#section-297"><i class="fa fa-check"></i><b>7.237</b> </a></li>
<li class="chapter" data-level="7.238" data-path="lmem.html"><a href="lmem.html#fixed-effects-4"><i class="fa fa-check"></i><b>7.238</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.239" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-df-t-value"><i class="fa fa-check"></i><b>7.239</b> Estimate Std. Error df t value</a></li>
<li class="chapter" data-level="7.240" data-path="lmem.html"><a href="lmem.html#intercept--0.71517-0.08728-29.38442--8.194"><i class="fa fa-check"></i><b>7.240</b> (Intercept) -0.71517 0.08728 29.38442 -8.194</a></li>
<li class="chapter" data-level="7.241" data-path="lmem.html"><a href="lmem.html#conditionlabel.williams-0.32769-0.06074-338.37005-5.395"><i class="fa fa-check"></i><b>7.241</b> conditionLabel.williams 0.32769 0.06074 338.37005 5.395</a></li>
<li class="chapter" data-level="7.242" data-path="lmem.html"><a href="lmem.html#nptype.pron-0.77529-0.06072-338.22707-12.768"><i class="fa fa-check"></i><b>7.242</b> npType.pron 0.77529 0.06072 338.22707 12.768</a></li>
<li class="chapter" data-level="7.243" data-path="lmem.html"><a href="lmem.html#voice.passive-0.05087-0.11572-12.11117-0.440"><i class="fa fa-check"></i><b>7.243</b> voice.passive 0.05087 0.11572 12.11117 0.440</a></li>
<li class="chapter" data-level="7.244" data-path="lmem.html"><a href="lmem.html#order.std--0.12730-0.10819-17.79197--1.177"><i class="fa fa-check"></i><b>7.244</b> order.std -0.12730 0.10819 17.79197 -1.177</a></li>
<li class="chapter" data-level="7.245" data-path="lmem.html"><a href="lmem.html#conditionlabel.williamsnptype.pron-0.31916-0.12126-337.32828-2.632"><i class="fa fa-check"></i><b>7.245</b> conditionLabel.williams:npType.pron 0.31916 0.12126 337.32828 2.632</a></li>
<li class="chapter" data-level="7.246" data-path="lmem.html"><a href="lmem.html#prt"><i class="fa fa-check"></i><b>7.246</b> Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="7.247" data-path="lmem.html"><a href="lmem.html#intercept-4.45e-09-conditionlabel.williams-1.29e-07"><i class="fa fa-check"></i><b>7.247</b> (Intercept) 4.45e-09 <strong><em> ## conditionLabel.williams 1.29e-07 </em></strong></a></li>
<li><a href="lmem.html#nptype.pron-2e-16-voice.passive-0.66795-order.std-0.25483-conditionlabel.williamsnptype.pron-0.00888-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtl.-nptyp.-vc.pss-ordr.s-cndtnlbl.wl-0.001-nptype.pron-0.001--0.015-voice.passv-0.009-0.005--0.023-order.std--0.004-0.015--0.032-0.107-cndtnlb.t.--0.006--0.004-0.003-0.003--0.021-call-lmformula-acoustics-conditionlabel.williams-nptype.pron"><span class="toc-section-number">7.248</span> npType.pron &lt; 2e-16 <em><strong> ## voice.passive 0.66795<br />
## order.std 0.25483<br />
## conditionLabel.williams:npType.pron 0.00888 </strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Correlation of Fixed Effects: ## (Intr) cndtL. npTyp. vc.pss ordr.s ## cndtnLbl.wl 0.001<br />
## npType.pron 0.001 -0.015<br />
## voice.passv 0.009 0.005 -0.023<br />
## order.std -0.004 0.015 -0.032 0.107<br />
## cndtnLb.:T. -0.006 -0.004 0.003 0.003 -0.021 ## ## Call: ## lm(formula = acoustics ~ conditionLabel.williams </em> npType.pron +</a></li>
<li class="chapter" data-level="7.249" data-path="lmem.html"><a href="lmem.html#voice.passive-order.std-data-givenness"><i class="fa fa-check"></i><b>7.249</b> voice.passive + order.std, data = givenness)</a></li>
<li class="chapter" data-level="7.250" data-path="lmem.html"><a href="lmem.html#section-298"><i class="fa fa-check"></i><b>7.250</b> </a></li>
<li class="chapter" data-level="7.251" data-path="lmem.html"><a href="lmem.html#residuals-18"><i class="fa fa-check"></i><b>7.251</b> Residuals:</a></li>
<li class="chapter" data-level="7.252" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-27"><i class="fa fa-check"></i><b>7.252</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.253" data-path="lmem.html"><a href="lmem.html#section-299"><i class="fa fa-check"></i><b>7.253</b> -1.94657 -0.49206 0.00032 0.46756 2.31921</a></li>
<li class="chapter" data-level="7.254" data-path="lmem.html"><a href="lmem.html#section-300"><i class="fa fa-check"></i><b>7.254</b> </a></li>
<li class="chapter" data-level="7.255" data-path="lmem.html"><a href="lmem.html#coefficients-20"><i class="fa fa-check"></i><b>7.255</b> Coefficients:</a></li>
<li class="chapter" data-level="7.256" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-t-value-prt-17"><i class="fa fa-check"></i><b>7.256</b> Estimate Std. Error t value Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="7.257" data-path="lmem.html"><a href="lmem.html#intercept--0.72335-0.03582--20.193-2e-16"><i class="fa fa-check"></i><b>7.257</b> (Intercept) -0.72335 0.03582 -20.193 &lt; 2e-16</a></li>
<li class="chapter" data-level="7.258" data-path="lmem.html"><a href="lmem.html#conditionlabel.williams-0.30626-0.07169-4.272-2.46e-05"><i class="fa fa-check"></i><b>7.258</b> conditionLabel.williams 0.30626 0.07169 4.272 2.46e-05</a></li>
<li class="chapter" data-level="7.259" data-path="lmem.html"><a href="lmem.html#nptype.pron-0.75743-0.07171-10.563-2e-16"><i class="fa fa-check"></i><b>7.259</b> npType.pron 0.75743 0.07171 10.563 &lt; 2e-16</a></li>
<li class="chapter" data-level="7.260" data-path="lmem.html"><a href="lmem.html#voice.passive-0.05866-0.07203-0.814-0.4159"><i class="fa fa-check"></i><b>7.260</b> voice.passive 0.05866 0.07203 0.814 0.4159</a></li>
<li class="chapter" data-level="7.261" data-path="lmem.html"><a href="lmem.html#order.std--0.19556-0.07211--2.712-0.0070"><i class="fa fa-check"></i><b>7.261</b> order.std -0.19556 0.07211 -2.712 0.0070</a></li>
<li class="chapter" data-level="7.262" data-path="lmem.html"><a href="lmem.html#conditionlabel.williamsnptype.pron-0.31954-0.14346-2.227-0.0265"><i class="fa fa-check"></i><b>7.262</b> conditionLabel.williams:npType.pron 0.31954 0.14346 2.227 0.0265</a></li>
<li class="chapter" data-level="7.263" data-path="lmem.html"><a href="lmem.html#section-301"><i class="fa fa-check"></i><b>7.263</b> </a></li>
<li class="chapter" data-level="7.264" data-path="lmem.html"><a href="lmem.html#intercept-conditionlabel.williams"><i class="fa fa-check"></i><b>7.264</b> (Intercept) <strong><em> ## conditionLabel.williams </em></strong></a></li>
<li><a href="lmem.html#nptype.pron-voice.passive-order.std-conditionlabel.williamsnptype.pron"><span class="toc-section-number">7.265</span> npType.pron <em><strong> ## voice.passive<br />
## order.std </strong> ## conditionLabel.williams:npType.pron </em></a></li>
<li class="chapter" data-level="7.266" data-path="lmem.html"><a href="lmem.html#section-302"><i class="fa fa-check"></i><b>7.266</b> —</a></li>
<li class="chapter" data-level="7.267" data-path="lmem.html"><a href="lmem.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-20"><i class="fa fa-check"></i><b>7.267</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="7.268" data-path="lmem.html"><a href="lmem.html#section-303"><i class="fa fa-check"></i><b>7.268</b> </a></li>
<li class="chapter" data-level="7.269" data-path="lmem.html"><a href="lmem.html#residual-standard-error-0.7-on-376-degrees-of-freedom"><i class="fa fa-check"></i><b>7.269</b> Residual standard error: 0.7 on 376 degrees of freedom</a></li>
<li class="chapter" data-level="7.270" data-path="lmem.html"><a href="lmem.html#multiple-r-squared-0.2768-adjusted-r-squared-0.2672"><i class="fa fa-check"></i><b>7.270</b> Multiple R-squared: 0.2768, Adjusted R-squared: 0.2672</a></li>
<li class="chapter" data-level="7.271" data-path="lmem.html"><a href="lmem.html#f-statistic-28.78-on-5-and-376-df-p-value-2.2e-16"><i class="fa fa-check"></i><b>7.271</b> F-statistic: 28.78 on 5 and 376 DF, p-value: &lt; 2.2e-16</a><ul>
<li class="chapter" data-level="7.271.1" data-path="lmem.html"><a href="lmem.html#c6model3B"><i class="fa fa-check"></i><b>7.271.1</b> Model 3B: Random intercepts and all possible random slopes</a></li>
</ul></li>
<li class="chapter" data-level="7.272" data-path="lmem.html"><a href="lmem.html#model-3b"><i class="fa fa-check"></i><b>7.272</b> Model 3B</a></li>
<li class="chapter" data-level="7.273" data-path="lmem.html"><a href="lmem.html#linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-1"><i class="fa fa-check"></i><b>7.273</b> Linear mixed model fit by REML. t-tests use Satterthwaite’s method [ ## lmerModLmerTest]</a></li>
<li class="chapter" data-level="7.274" data-path="lmem.html"><a href="lmem.html#formula-2"><i class="fa fa-check"></i><b>7.274</b> Formula:</a></li>
<li class="chapter" data-level="7.275" data-path="lmem.html"><a href="lmem.html#acoustics-conditionlabel.williams-nptype.pron-voice.passive-1"><i class="fa fa-check"></i><b>7.275</b> acoustics ~ conditionLabel.williams * npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="7.276" data-path="lmem.html"><a href="lmem.html#order.std-1-conditionlabel.williams-nptype.pron"><i class="fa fa-check"></i><b>7.276</b> order.std + (1 + conditionLabel.williams * npType.pron +</a></li>
<li><a href="lmem.html#voice.passive-participant-1-conditionlabel.williams-nptype.pron-item"><span class="toc-section-number">7.277</span> voice.passive || participant) + (1 + conditionLabel.williams *<br />
## npType.pron || item)</a></li>
<li class="chapter" data-level="7.278" data-path="lmem.html"><a href="lmem.html#data-givenness-6"><i class="fa fa-check"></i><b>7.278</b> Data: givenness</a></li>
<li class="chapter" data-level="7.279" data-path="lmem.html"><a href="lmem.html#section-304"><i class="fa fa-check"></i><b>7.279</b> </a></li>
<li class="chapter" data-level="7.280" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence-722.6"><i class="fa fa-check"></i><b>7.280</b> REML criterion at convergence: 722.6</a></li>
<li class="chapter" data-level="7.281" data-path="lmem.html"><a href="lmem.html#section-305"><i class="fa fa-check"></i><b>7.281</b> </a></li>
<li class="chapter" data-level="7.282" data-path="lmem.html"><a href="lmem.html#scaled-residuals-5"><i class="fa fa-check"></i><b>7.282</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.283" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-28"><i class="fa fa-check"></i><b>7.283</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.284" data-path="lmem.html"><a href="lmem.html#section-306"><i class="fa fa-check"></i><b>7.284</b> -2.97005 -0.61342 -0.00089 0.55381 2.98506</a></li>
<li class="chapter" data-level="7.285" data-path="lmem.html"><a href="lmem.html#section-307"><i class="fa fa-check"></i><b>7.285</b> </a></li>
<li class="chapter" data-level="7.286" data-path="lmem.html"><a href="lmem.html#random-effects-5"><i class="fa fa-check"></i><b>7.286</b> Random effects:</a></li>
<li class="chapter" data-level="7.287" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev.-5"><i class="fa fa-check"></i><b>7.287</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.288" data-path="lmem.html"><a href="lmem.html#participant-intercept-0.11589-0.3404"><i class="fa fa-check"></i><b>7.288</b> participant (Intercept) 0.11589 0.3404</a></li>
<li class="chapter" data-level="7.289" data-path="lmem.html"><a href="lmem.html#participant.1-conditionlabel.williams-0.01278-0.1131"><i class="fa fa-check"></i><b>7.289</b> participant.1 conditionLabel.williams 0.01278 0.1131</a></li>
<li class="chapter" data-level="7.290" data-path="lmem.html"><a href="lmem.html#participant.2-nptype.pron-0.01298-0.1139"><i class="fa fa-check"></i><b>7.290</b> participant.2 npType.pron 0.01298 0.1139</a></li>
<li class="chapter" data-level="7.291" data-path="lmem.html"><a href="lmem.html#participant.3-voice.passive-0.08281-0.2878"><i class="fa fa-check"></i><b>7.291</b> participant.3 voice.passive 0.08281 0.2878</a></li>
<li class="chapter" data-level="7.292" data-path="lmem.html"><a href="lmem.html#participant.4-conditionlabel.williamsnptype.pron-0.03131-0.1770"><i class="fa fa-check"></i><b>7.292</b> participant.4 conditionLabel.williams:npType.pron 0.03131 0.1770</a></li>
<li class="chapter" data-level="7.293" data-path="lmem.html"><a href="lmem.html#item-intercept-0.04089-0.2022"><i class="fa fa-check"></i><b>7.293</b> item (Intercept) 0.04089 0.2022</a></li>
<li class="chapter" data-level="7.294" data-path="lmem.html"><a href="lmem.html#item.1-conditionlabel.williams-0.00000-0.0000"><i class="fa fa-check"></i><b>7.294</b> item.1 conditionLabel.williams 0.00000 0.0000</a></li>
<li class="chapter" data-level="7.295" data-path="lmem.html"><a href="lmem.html#item.2-nptype.pron-0.20854-0.4567"><i class="fa fa-check"></i><b>7.295</b> item.2 npType.pron 0.20854 0.4567</a></li>
<li class="chapter" data-level="7.296" data-path="lmem.html"><a href="lmem.html#item.3-conditionlabel.williamsnptype.pron-0.00000-0.0000"><i class="fa fa-check"></i><b>7.296</b> item.3 conditionLabel.williams:npType.pron 0.00000 0.0000</a></li>
<li class="chapter" data-level="7.297" data-path="lmem.html"><a href="lmem.html#residual-0.26762-0.5173"><i class="fa fa-check"></i><b>7.297</b> Residual 0.26762 0.5173</a></li>
<li class="chapter" data-level="7.298" data-path="lmem.html"><a href="lmem.html#number-of-obs-382-groups-participant-27-item-16-3"><i class="fa fa-check"></i><b>7.298</b> Number of obs: 382, groups: participant, 27; item, 16</a></li>
<li class="chapter" data-level="7.299" data-path="lmem.html"><a href="lmem.html#section-308"><i class="fa fa-check"></i><b>7.299</b> </a></li>
<li class="chapter" data-level="7.300" data-path="lmem.html"><a href="lmem.html#fixed-effects-5"><i class="fa fa-check"></i><b>7.300</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.301" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-df-t-value-1"><i class="fa fa-check"></i><b>7.301</b> Estimate Std. Error df t value</a></li>
<li class="chapter" data-level="7.302" data-path="lmem.html"><a href="lmem.html#intercept--0.71909-0.08702-29.69336--8.263"><i class="fa fa-check"></i><b>7.302</b> (Intercept) -0.71909 0.08702 29.69336 -8.263</a></li>
<li class="chapter" data-level="7.303" data-path="lmem.html"><a href="lmem.html#conditionlabel.williams-0.30897-0.05894-19.87033-5.242"><i class="fa fa-check"></i><b>7.303</b> conditionLabel.williams 0.30897 0.05894 19.87033 5.242</a></li>
<li class="chapter" data-level="7.304" data-path="lmem.html"><a href="lmem.html#nptype.pron-0.78377-0.12831-15.26567-6.108"><i class="fa fa-check"></i><b>7.304</b> npType.pron 0.78377 0.12831 15.26567 6.108</a></li>
<li class="chapter" data-level="7.305" data-path="lmem.html"><a href="lmem.html#voice.passive-0.06037-0.12802-16.52472-0.472"><i class="fa fa-check"></i><b>7.305</b> voice.passive 0.06037 0.12802 16.52472 0.472</a></li>
<li class="chapter" data-level="7.306" data-path="lmem.html"><a href="lmem.html#order.std--0.12414-0.10625-18.30847--1.168"><i class="fa fa-check"></i><b>7.306</b> order.std -0.12414 0.10625 18.30847 -1.168</a></li>
<li class="chapter" data-level="7.307" data-path="lmem.html"><a href="lmem.html#conditionlabel.williamsnptype.pron-0.31522-0.11341-21.95021-2.780"><i class="fa fa-check"></i><b>7.307</b> conditionLabel.williams:npType.pron 0.31522 0.11341 21.95021 2.780</a></li>
<li class="chapter" data-level="7.308" data-path="lmem.html"><a href="lmem.html#prt-1"><i class="fa fa-check"></i><b>7.308</b> Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="7.309" data-path="lmem.html"><a href="lmem.html#intercept-3.45e-09-conditionlabel.williams-4.03e-05"><i class="fa fa-check"></i><b>7.309</b> (Intercept) 3.45e-09 <strong><em> ## conditionLabel.williams 4.03e-05 </em></strong></a></li>
<li><a href="lmem.html#nptype.pron-1.85e-05-voice.passive-0.6434-order.std-0.2576-conditionlabel.williamsnptype.pron-0.0109-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtl.-nptyp.-vc.pss-ordr.s-cndtnlbl.wl-0.002-nptype.pron-0.000--0.005-voice.passv-0.008-0.004--0.009-order.std--0.004-0.019--0.013-0.097-cndtnlb.t.--0.005-0.001-0.002-0.003--0.019-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-acoustics-conditionlabel.williams-nptype.pron-voice.passive-order.std-1-participant-1-item-data-givenness-reml-criterion-at-convergence-758.6-scaled-residuals-min-1q-median-3q-max--2.7638--0.6535--0.0102-0.5750-3.5847-random-effects-groups-name-variance-std.dev.-participant-intercept-0.11624-0.3409-item-intercept-0.03825-0.1956-residual-0.34715-0.5892-number-of-obs-382-groups-participant-27-item-16-fixed-effects-estimate-std.-error-df-t-value-intercept--0.71517-0.08728-29.38442--8.194-conditionlabel.williams-0.32769-0.06074-338.37005-5.395-nptype.pron-0.77529-0.06072-338.22707-12.768-voice.passive-0.05087-0.11572-12.11117-0.440-order.std--0.12730-0.10819-17.79197--1.177-conditionlabel.williamsnptype.pron-0.31916-0.12126-337.32828-2.632-prt-intercept-4.45e-09-conditionlabel.williams-1.29e-07-nptype.pron-2e-16-voice.passive-0.66795-order.std-0.25483-conditionlabel.williamsnptype.pron-0.00888-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtl.-nptyp.-vc.pss-ordr.s-cndtnlbl.wl-0.001-nptype.pron-0.001--0.015-voice.passv-0.009-0.005--0.023-order.std--0.004-0.015--0.032-0.107-cndtnlb.t.--0.006--0.004-0.003-0.003--0.021-assessing-variability-model-comparisons-to-check-whether-conditionlabel.williams-variability-by-participant-refitting-models-with-ml-instead-of-reml-data-givenness-models-mod3b.no.partic.slope-acoustics-conditionlabel.williams-nptype.pron-voice.passive-mod3b.no.partic.slope-order.std-1-participant-0-nptype.pron-participant-mod3b.no.partic.slope-0-voice.passive-participant-0-conditionlabel.williamsnptype.pron-mod3b.no.partic.slope-participant-1-item-0-conditionlabel.williams-mod3b.no.partic.slope-item-0-nptype.pron-item-0-conditionlabel.williamsnptype.pron-mod3b.no.partic.slope-item-conditionlabel.williamsnptype.pron-mod3b-acoustics-conditionlabel.williams-nptype.pron-voice.passive-mod3b-order.std-1-conditionlabel.williams-nptype.pron-mod3b-voice.passive-participant-1-conditionlabel.williams-mod3b-nptype.pron-item-df-aic-bic-loglik-deviance-chisq-chi-df-mod3b.no.partic.slope-15-735.9-795.08--352.95-705.9-mod3b-16-737.8-800.92--352.90-705.8-0.0993-1-prchisq-mod3b.no.partic.slope-mod3b-0.7527-by-item-refitting-models-with-ml-instead-of-reml-data-givenness-models-mod3b.no.item.slope-acoustics-conditionlabel.williams-nptype.pron-voice.passive-mod3b.no.item.slope-order.std-1-participant-0-conditionlabel.williams-mod3b.no.item.slope-participant-0-nptype.pron-participant-0-voice.passive-mod3b.no.item.slope-participant-0-conditionlabel.williamsnptype.pron-mod3b.no.item.slope-participant-1-item-0-nptype.pron-item-0-mod3b.no.item.slope-conditionlabel.williamsnptype.pron-item-conditionlabel.williamsnptype.pron-mod3b-acoustics-conditionlabel.williams-nptype.pron-voice.passive-mod3b-order.std-1-conditionlabel.williams-nptype.pron-mod3b-voice.passive-participant-1-conditionlabel.williams-mod3b-nptype.pron-item-df-aic-bic-loglik-deviance-chisq-chi-df-mod3b.no.item.slope-15-735.8-794.98--352.9-705.8-mod3b-16-737.8-800.92--352.9-705.8-0-1-prchisq-mod3b.no.item.slope-mod3b-1-examine-distibution-of-participant-clabel.wiliams-coefficents-fixed-effect-for-conditionlabel-each-participants-offset-more-on-random-slopes-what-does-adding-a-random-slope-term-do-model-1d-half-rhyme-data-model-of-1-var-with-by-partic-random-intercept-only-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-rhymerating-relduration-1-participant-data-halfrhyme-reml-criterion-at-convergence-2580-scaled-residuals-min-1q-median-3q-max--2.4624--0.6545--0.1025-0.6348-3.6438-random-effects-groups-name-variance-std.dev.-participant-intercept-1.222-1.106-residual-1.575-1.255-number-of-obs-756-groups-participant-31-fixed-effects-estimate-std.-error-df-t-value-prt-intercept-3.2918-0.2088-33.0815-15.765-2e-16"><span class="toc-section-number">7.310</span> npType.pron 1.85e-05 <strong><em> ## voice.passive 0.6434<br />
## order.std 0.2576<br />
## conditionLabel.williams:npType.pron 0.0109 </em><br />
## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Correlation of Fixed Effects: ## (Intr) cndtL. npTyp. vc.pss ordr.s ## cndtnLbl.wl 0.002<br />
## npType.pron 0.000 -0.005<br />
## voice.passv 0.008 0.004 -0.009<br />
## order.std -0.004 0.019 -0.013 0.097<br />
## cndtnLb.:T. -0.005 0.001 0.002 0.003 -0.019 ## Linear mixed model fit by REML. t-tests use Satterthwaite’s method [ ## lmerModLmerTest] ## Formula: ## acoustics ~ conditionLabel.williams * npType.pron + voice.passive +<br />
## order.std + (1 | participant) + (1 | item) ## Data: givenness ## ## REML criterion at convergence: 758.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.7638 -0.6535 -0.0102 0.5750 3.5847 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 0.11624 0.3409<br />
## item (Intercept) 0.03825 0.1956<br />
## Residual 0.34715 0.5892<br />
## Number of obs: 382, groups: participant, 27; item, 16 ## ## Fixed effects: ## Estimate Std. Error df t value ## (Intercept) -0.71517 0.08728 29.38442 -8.194 ## conditionLabel.williams 0.32769 0.06074 338.37005 5.395 ## npType.pron 0.77529 0.06072 338.22707 12.768 ## voice.passive 0.05087 0.11572 12.11117 0.440 ## order.std -0.12730 0.10819 17.79197 -1.177 ## conditionLabel.williams:npType.pron 0.31916 0.12126 337.32828 2.632 ## Pr(&gt;|t|)<br />
## (Intercept) 4.45e-09 </strong><em> ## conditionLabel.williams 1.29e-07 </em><strong> ## npType.pron &lt; 2e-16 </strong><em> ## voice.passive 0.66795<br />
## order.std 0.25483<br />
## conditionLabel.williams:npType.pron 0.00888 <strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Correlation of Fixed Effects: ## (Intr) cndtL. npTyp. vc.pss ordr.s ## cndtnLbl.wl 0.001<br />
## npType.pron 0.001 -0.015<br />
## voice.passv 0.009 0.005 -0.023<br />
## order.std -0.004 0.015 -0.032 0.107<br />
## cndtnLb.:T. -0.006 -0.004 0.003 0.003 -0.021 ### Assessing variability ## model comparisons to check whether conditionLabel.williams variability ## by-participant ## refitting model(s) with ML (instead of REML) ## Data: givenness ## Models: ## mod3b.no.partic.slope: acoustics ~ conditionLabel.williams + npType.pron + voice.passive + ## mod3b.no.partic.slope: order.std + (1 | participant) + (0 + npType.pron | participant) + ## mod3b.no.partic.slope: (0 + voice.passive | participant) + (0 + conditionLabel.williams:npType.pron | ## mod3b.no.partic.slope: participant) + (1 | item) + (0 + conditionLabel.williams | ## mod3b.no.partic.slope: item) + (0 + npType.pron | item) + (0 + conditionLabel.williams:npType.pron | ## mod3b.no.partic.slope: item) + conditionLabel.williams:npType.pron ## mod3b: acoustics ~ conditionLabel.williams * npType.pron + voice.passive + ## mod3b: order.std + (1 + conditionLabel.williams * npType.pron + ## mod3b: voice.passive || participant) + (1 + conditionLabel.williams * ## mod3b: npType.pron || item) ## Df AIC BIC logLik deviance Chisq Chi Df ## mod3b.no.partic.slope 15 735.9 795.08 -352.95 705.9<br />
## mod3b 16 737.8 800.92 -352.90 705.8 0.0993 1 ## Pr(&gt;Chisq) ## mod3b.no.partic.slope<br />
## mod3b 0.7527 ## by-item ## refitting model(s) with ML (instead of REML) ## Data: givenness ## Models: ## mod3b.no.item.slope: acoustics ~ conditionLabel.williams + npType.pron + voice.passive + ## mod3b.no.item.slope: order.std + (1 | participant) + (0 + conditionLabel.williams | ## mod3b.no.item.slope: participant) + (0 + npType.pron | participant) + (0 + voice.passive | ## mod3b.no.item.slope: participant) + (0 + conditionLabel.williams:npType.pron | ## mod3b.no.item.slope: participant) + (1 | item) + (0 + npType.pron | item) + (0 + ## mod3b.no.item.slope: conditionLabel.williams:npType.pron | item) + conditionLabel.williams:npType.pron ## mod3b: acoustics ~ conditionLabel.williams * npType.pron + voice.passive + ## mod3b: order.std + (1 + conditionLabel.williams * npType.pron + ## mod3b: voice.passive || participant) + (1 + conditionLabel.williams * ## mod3b: npType.pron || item) ## Df AIC BIC logLik deviance Chisq Chi Df ## mod3b.no.item.slope 15 735.8 794.98 -352.9 705.8<br />
## mod3b 16 737.8 800.92 -352.9 705.8 0 1 ## Pr(&gt;Chisq) ## mod3b.no.item.slope<br />
## mod3b 1 ## examine distibution of participant clabel.wiliams coefficents: ## fixed effect for conditionLabel ## each participant’s offset ## More on random slopes ### What does adding a random slope term do? ## Model 1D: half-rhyme data model of 1 var, with by-partic random intercept only ## Linear mixed model fit by REML. t-tests use Satterthwaite’s method [ ## lmerModLmerTest] ## Formula: rhymeRating ~ relDuration + (1 | participant) ## Data: halfrhyme ## ## REML criterion at convergence: 2580 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.4624 -0.6545 -0.1025 0.6348 3.6438 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 1.222 1.106<br />
## Residual 1.575 1.255<br />
## Number of obs: 756, groups: participant, 31 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|)<br />
## (Intercept) 3.2918 0.2088 33.0815 15.765 &lt; 2e-16 </strong></em></a></li>
<li><a href="lmem.html#relduration-2.6600-0.6703-728.5548-3.968-7.96e-05-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-relduration-0.219-linear-mixed-model-fit-by-reml-lmermod-formula-rhymerating-relduration-1-participant-0-relduration-participant-data-halfrhyme-reml-criterion-at-convergence-2578.7-scaled-residuals-min-1q-median-3q-max--2.4022--0.6091--0.1126-0.6138-3.5726-random-effects-groups-name-variance-std.dev.-participant-intercept-1.267-1.126-participant.1-relduration-4.482-2.117-residual-1.552-1.246-number-of-obs-756-groups-participant-31-fixed-effects-estimate-std.-error-t-value-intercept-3.3003-0.2125-15.533-relduration-2.7249-0.7816-3.486-correlation-of-fixed-effects-intr-relduration-0.192-discussion-adding-a-random-slope-adding-a-random-slope-extended-exercise-lmm-with-random-slopes---random-effect-correlations-random-effect-correlations-model-predictions-by-subject-for-model-1c-get-the-predicted-value-for-each-case-plot-the-models-prediction-for-each-participant-model-1e-correlated-random-slope-intercept-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-rhymerating-relduration-1-relduration-participant-data-halfrhyme-reml-criterion-at-convergence-2571.9-scaled-residuals-min-1q-median-3q-max--2.4723--0.6129--0.1562-0.5897-3.4874-random-effects-groups-name-variance-std.dev.-corr-participant-intercept-1.496-1.223-relduration-5.728-2.393-0.82-residual-1.548-1.244-number-of-obs-756-groups-participant-31-fixed-effects-estimate-std.-error-df-t-value-prt-intercept-3.3068-0.2291-30.4810-14.433-3.62e-15"><span class="toc-section-number">7.311</span> relDuration 2.6600 0.6703 728.5548 3.968 7.96e-05 <em><strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Correlation of Fixed Effects: ## (Intr) ## relDuration 0.219 ## Linear mixed model fit by REML [‘lmerMod’] ## Formula: ## rhymeRating ~ relDuration + ((1 | participant) + (0 + relDuration |<br />
## participant)) ## Data: halfrhyme ## ## REML criterion at convergence: 2578.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.4022 -0.6091 -0.1126 0.6138 3.5726 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 1.267 1.126<br />
## participant.1 relDuration 4.482 2.117<br />
## Residual 1.552 1.246<br />
## Number of obs: 756, groups: participant, 31 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 3.3003 0.2125 15.533 ## relDuration 2.7249 0.7816 3.486 ## ## Correlation of Fixed Effects: ## (Intr) ## relDuration 0.192 ### Discussion: Adding a random slope {#adding-a-random-slope} #### Extended exercise: LMM with random slopes {-} ## Random effect correlations {#random-effect-correlations} ## model predictions by-subject for Model 1C: ## get the predicted value for each case ## plot the model’s prediction for each participant: ### Model 1E: </strong>Correlated<strong> random slope &amp; intercept ## Linear mixed model fit by REML. t-tests use Satterthwaite’s method [ ## lmerModLmerTest] ## Formula: rhymeRating ~ relDuration + (1 + relDuration | participant) ## Data: halfrhyme ## ## REML criterion at convergence: 2571.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.4723 -0.6129 -0.1562 0.5897 3.4874 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## participant (Intercept) 1.496 1.223<br />
## relDuration 5.728 2.393 0.82 ## Residual 1.548 1.244<br />
## Number of obs: 756, groups: participant, 31 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|)<br />
## (Intercept) 3.3068 0.2291 30.4810 14.433 3.62e-15 </strong></em></a></li>
<li class="chapter" data-level="7.312" data-path="lmem.html"><a href="lmem.html#relduration-2.8161-0.8017-24.8569-3.513-0.00172"><i class="fa fa-check"></i><b>7.312</b> relDuration 2.8161 0.8017 24.8569 3.513 0.00172 **</a></li>
<li class="chapter" data-level="7.313" data-path="lmem.html"><a href="lmem.html#section-309"><i class="fa fa-check"></i><b>7.313</b> —</a></li>
<li class="chapter" data-level="7.314" data-path="lmem.html"><a href="lmem.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-21"><i class="fa fa-check"></i><b>7.314</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="7.315" data-path="lmem.html"><a href="lmem.html#section-310"><i class="fa fa-check"></i><b>7.315</b> </a></li>
<li class="chapter" data-level="7.316" data-path="lmem.html"><a href="lmem.html#correlation-of-fixed-effects-4"><i class="fa fa-check"></i><b>7.316</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="7.317" data-path="lmem.html"><a href="lmem.html#intr-4"><i class="fa fa-check"></i><b>7.317</b> (Intr)</a></li>
<li class="chapter" data-level="7.318" data-path="lmem.html"><a href="lmem.html#relduration-0.591"><i class="fa fa-check"></i><b>7.318</b> relDuration 0.591</a></li>
<li class="chapter" data-level="7.319" data-path="lmem.html"><a href="lmem.html#refitting-models-with-ml-instead-of-reml-1"><i class="fa fa-check"></i><b>7.319</b> refitting model(s) with ML (instead of REML)</a></li>
<li class="chapter" data-level="7.320" data-path="lmem.html"><a href="lmem.html#data-halfrhyme-1"><i class="fa fa-check"></i><b>7.320</b> Data: halfrhyme</a></li>
<li class="chapter" data-level="7.321" data-path="lmem.html"><a href="lmem.html#models-1"><i class="fa fa-check"></i><b>7.321</b> Models:</a></li>
<li class="chapter" data-level="7.322" data-path="lmem.html"><a href="lmem.html#mod1c-rhymerating-relduration-1-participant-0-relduration"><i class="fa fa-check"></i><b>7.322</b> mod1c: rhymeRating ~ relDuration + ((1 | participant) + (0 + relDuration |</a></li>
<li class="chapter" data-level="7.323" data-path="lmem.html"><a href="lmem.html#mod1c-participant"><i class="fa fa-check"></i><b>7.323</b> mod1c: participant))</a></li>
<li class="chapter" data-level="7.324" data-path="lmem.html"><a href="lmem.html#mod1e-rhymerating-relduration-1-relduration-participant"><i class="fa fa-check"></i><b>7.324</b> mod1e: rhymeRating ~ relDuration + (1 + relDuration | participant)</a></li>
<li class="chapter" data-level="7.325" data-path="lmem.html"><a href="lmem.html#df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-1"><i class="fa fa-check"></i><b>7.325</b> Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)</a></li>
<li class="chapter" data-level="7.326" data-path="lmem.html"><a href="lmem.html#mod1c-5-2588.7-2611.8--1289.3-2578.7"><i class="fa fa-check"></i><b>7.326</b> mod1c 5 2588.7 2611.8 -1289.3 2578.7</a></li>
<li><a href="lmem.html#mod1e-6-2583.7-2611.5--1285.8-2571.7-6.9728-1-0.008276-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-model-1c-no-correlation-estimate-std.-error-t-value-intercept-3.300261-0.2124740-15.532541-relduration-2.724922-0.7816163-3.486265-model-1e-correlation-estimate-std.-error-df-t-value-prt-intercept-3.306768-0.2291117-30.48098-14.432996-3.624195e-15-relduration-2.816111-0.8016868-24.85693-3.512732-1.720269e-03-dicussion-adding-a-correlation-c6discuss-model-criticism-for-linear-mixed-models-model-3b-residual-plots-qq-plot-for-model-3b-model-3b-random-effect-distribution-make-partiicpant-means-plot-random-slopes-for-factors-c6factorsissue-model-with-random-effect-correlations-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-rhymerating-conditionlabel-1-conditionlabel-participant-data-halfrhyme-reml-criterion-at-convergence-3826.5-scaled-residuals-min-1q-median-3q-max--4.6442--0.4262--0.0567-0.5333-3.8688-random-effects-groups-name-variance-std.dev.-corr-participant-intercept-0.26067-0.5106-conditionlabel1-0.20112-0.4485-0.91-conditionlabel2-0.05675-0.2382--0.73--0.55-residual-1.25335-1.1195-number-of-obs-1205-groups-participant-31-fixed-effects-estimate-std.-error-df-t-value-prt-intercept-3.63504-0.09918-30.04544-36.652-2e-16-conditionlabel1-0.89985-0.09086-29.89488-9.904-5.94e-11-conditionlabel2-1.42441-0.05166-30.13975-27.573-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtl1-conditnlbl1-0.677-conditnlbl2--0.511--0.335-models-without-random-effect-correlations-lmem-mwrec-warning-in-checkconvattropt-derivs-optpar-ctrl-controlcheckconv-model-is-nearly-unidentifiable-large-eigenvalue-ratio---rescale-variables-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-rhymerating-conditionlabel-1-conditionlabel-participant-data-halfrhyme-reml-criterion-at-convergence-3826.5-scaled-residuals-min-1q-median-3q-max--4.6442--0.4262--0.0567-0.5333-3.8688-random-effects-groups-name-variance-std.dev.-corr-participant-intercept-8.833e-05-0.009398-participant.1-conditionlabelbad-1.623e-01-0.402815-conditionlabelvoice-1.230e00-1.109149-0.66-conditionlabelgood-1.320e-01-0.363301--0.23-0.37-residual-1.253e00-1.119530-number-of-obs-1205-groups-participant-31-fixed-effects-estimate-std.-error-df-t-value-prt-intercept-3.63504-0.09918-30.04544-36.652-2e-16-conditionlabel1-0.89985-0.09086-29.89489-9.904-5.94e-11-conditionlabel2-1.42441-0.05166-30.13975-27.573-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtl1-conditnlbl1-0.677-conditnlbl2--0.511--0.335-convergence-code-0-model-is-nearly-unidentifiable-large-eigenvalue-ratio---rescale-variables-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-rhymerating-conditionlabel-1-clabel.c1-clabel.c2-participant-data-halfrhyme-reml-criterion-at-convergence-3860-scaled-residuals-min-1q-median-3q-max--4.2957--0.5188--0.0262-0.5393-3.8347-random-effects-groups-name-variance-std.dev.-participant-intercept-0.30396-0.5513-participant.1-clabel.c1-0.23903-0.4889-participant.2-clabel.c2-0.06519-0.2553-residual-1.24808-1.1172-number-of-obs-1205-groups-participant-31-fixed-effects-estimate-std.-error-df-t-value-prt-intercept-3.63410-0.10596-30.02772-34.297-2e-16-conditionlabel1-0.90151-0.09733-30.01033-9.262-2.63e-10-conditionlabel2-1.42488-0.05420-30.28367-26.289-2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtl1-conditnlbl1--0.061-conditnlbl2-0.043-0.059-other-readings-appendix-extra-examples-c6extraexamples-predicting-confidence-intervals-by-simulation-lmm-simulation-confint-a-simple-recipe-for-simulating-95-confidence-intervals-over-model-predictions-set-up-dataframe-to-predict-for-every-participant-every-value-of-the-predictor-simulate-10k-times-from-the-model-for-newdata-lower-and-upper-95-cis-newdata-now-contains-lower-and-upper-bounds-of-95-ci-with-prediction-median-from-simulations-random-intercept-and-slope-model-for-givenness-data-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-acoustics-conditionlabel.williams-1-conditionlabel.williams-participant-data-givenness-reml-criterion-at-convergence-897.9-scaled-residuals-min-1q-median-3q-max--3.0538--0.7129-0.0083-0.6540-3.3136-random-effects-groups-name-variance-std.dev.-participant-intercept-0.08937-0.299-participant.1-conditionlabel.williams-0.00000-0.000-residual-0.55800-0.747-number-of-obs-382-groups-participant-27-fixed-effects-estimate-std.-error-df-t-value-prt-intercept--0.71856-0.06916-26.21655--10.39-8.66e-11-conditionlabel.williams-0.32626-0.07677-356.75848-4.25-2.73e-05-intercept-conditionlabel.williams-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cndtnlbl.wl-0.002-appendix-extended-exercise-c6extendedexercise-linear-mixed-model-fit-by-reml.-t-tests-use-satterthwaites-method-lmermodlmertest-formula-vowelduration-syntax.trans-speechrate.slow-1-syntax.trans-speechrate.slow-item-1-syntax.trans-speechrate.slow"><span class="toc-section-number">7.327</span> mod1e 6 2583.7 2611.5 -1285.8 2571.7 6.9728 1 0.008276 <strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## model 1C (no correlation) ## Estimate Std. Error t value ## (Intercept) 3.300261 0.2124740 15.532541 ## relDuration 2.724922 0.7816163 3.486265 ## model 1E (correlation) ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 3.306768 0.2291117 30.48098 14.432996 3.624195e-15 ## relDuration 2.816111 0.8016868 24.85693 3.512732 1.720269e-03 ### Dicussion: Adding a correlation {#c6discuss} ## Model criticism for linear mixed models ### Model 3B: Residual plots ## QQ plot for Model 3B ### Model 3B: Random effect distribution ## make partiicpant means plot ## Random slopes for factors {#c6factorsissue} ### Model with random-effect correlations ## Linear mixed model fit by REML. t-tests use Satterthwaite’s method [ ## lmerModLmerTest] ## Formula: rhymeRating ~ conditionLabel + (1 + conditionLabel | participant) ## Data: halfrhyme ## ## REML criterion at convergence: 3826.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.6442 -0.4262 -0.0567 0.5333 3.8688 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr<br />
## participant (Intercept) 0.26067 0.5106<br />
## conditionLabel1 0.20112 0.4485 0.91<br />
## conditionLabel2 0.05675 0.2382 -0.73 -0.55 ## Residual 1.25335 1.1195<br />
## Number of obs: 1205, groups: participant, 31 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|)<br />
## (Intercept) 3.63504 0.09918 30.04544 36.652 &lt; 2e-16 </strong><em> ## conditionLabel1 0.89985 0.09086 29.89488 9.904 5.94e-11 </em><strong> ## conditionLabel2 1.42441 0.05166 30.13975 27.573 &lt; 2e-16 </strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Correlation of Fixed Effects: ## (Intr) cndtL1 ## conditnLbl1 0.677<br />
## conditnLbl2 -0.511 -0.335 ### Models without random-effect correlations {#lmem-mwrec} ## Warning in checkConv(attr(opt, “derivs”), opt<span class="math inline">\(par, ctrl = control\)</span>checkConv, : Model is nearly unidentifiable: large eigenvalue ratio ## - Rescale variables? ## Linear mixed model fit by REML. t-tests use Satterthwaite’s method [ ## lmerModLmerTest] ## Formula: ## rhymeRating ~ conditionLabel + (1 + conditionLabel || participant) ## Data: halfrhyme ## ## REML criterion at convergence: 3826.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.6442 -0.4262 -0.0567 0.5333 3.8688 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr<br />
## participant (Intercept) 8.833e-05 0.009398<br />
## participant.1 conditionLabelbad 1.623e-01 0.402815<br />
## conditionLabelvoice 1.230e+00 1.109149 0.66<br />
## conditionLabelgood 1.320e-01 0.363301 -0.23 0.37 ## Residual 1.253e+00 1.119530<br />
## Number of obs: 1205, groups: participant, 31 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|)<br />
## (Intercept) 3.63504 0.09918 30.04544 36.652 &lt; 2e-16 </em><strong> ## conditionLabel1 0.89985 0.09086 29.89489 9.904 5.94e-11 </strong><em> ## conditionLabel2 1.42441 0.05166 30.13975 27.573 &lt; 2e-16 </em><strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Correlation of Fixed Effects: ## (Intr) cndtL1 ## conditnLbl1 0.677<br />
## conditnLbl2 -0.511 -0.335 ## convergence code: 0 ## Model is nearly unidentifiable: large eigenvalue ratio ## - Rescale variables? ## Linear mixed model fit by REML. t-tests use Satterthwaite’s method [ ## lmerModLmerTest] ## Formula: rhymeRating ~ conditionLabel + (1 + clabel.c1 + clabel.c2 ||<br />
## participant) ## Data: halfrhyme ## ## REML criterion at convergence: 3860 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.2957 -0.5188 -0.0262 0.5393 3.8347 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 0.30396 0.5513<br />
## participant.1 clabel.c1 0.23903 0.4889<br />
## participant.2 clabel.c2 0.06519 0.2553<br />
## Residual 1.24808 1.1172<br />
## Number of obs: 1205, groups: participant, 31 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|)<br />
## (Intercept) 3.63410 0.10596 30.02772 34.297 &lt; 2e-16 </strong><em> ## conditionLabel1 0.90151 0.09733 30.01033 9.262 2.63e-10 </em><strong> ## conditionLabel2 1.42488 0.05420 30.28367 26.289 &lt; 2e-16 </strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Correlation of Fixed Effects: ## (Intr) cndtL1 ## conditnLbl1 -0.061<br />
## conditnLbl2 0.043 0.059 ## Other readings ## Appendix: Extra examples {#c6extraexamples} ### Predicting confidence intervals by simulation {#lmm-simulation-confint} ## a simple recipe for simulating 95% confidence intervals over model predictions ## set up dataframe to predict for (every participant, every value of the predictor) ## (simulate 10k times from the model, for newdata) ## lower and upper 95% CIs ## newdata now contains lower and upper bounds of 95% CI, with ‘prediction’ = median from simulations ### Random intercept and slope model for <code>givenness</code> data ## Linear mixed model fit by REML. t-tests use Satterthwaite’s method [ ## lmerModLmerTest] ## Formula: ## acoustics ~ conditionLabel.williams + (1 + conditionLabel.williams ||<br />
## participant) ## Data: givenness ## ## REML criterion at convergence: 897.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.0538 -0.7129 0.0083 0.6540 3.3136 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 0.08937 0.299<br />
## participant.1 conditionLabel.williams 0.00000 0.000<br />
## Residual 0.55800 0.747<br />
## Number of obs: 382, groups: participant, 27 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) -0.71856 0.06916 26.21655 -10.39 8.66e-11 ## conditionLabel.williams 0.32626 0.07677 356.75848 4.25 2.73e-05 ##<br />
## (Intercept) </em><strong> ## conditionLabel.williams </strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Correlation of Fixed Effects: ## (Intr) ## cndtnLbl.wl 0.002 ## Appendix: Extended exercise {#c6extendedexercise} ## Linear mixed model fit by REML. t-tests use Satterthwaite’s method [ ## lmerModLmerTest] ## Formula: ## vowelduration ~ syntax.trans </em> speechrate.slow + (1 + syntax.trans *<br />
## speechrate.slow || item) + (1 + syntax.trans * speechrate.slow ||</a></li>
<li class="chapter" data-level="7.328" data-path="lmem.html"><a href="lmem.html#participant-1"><i class="fa fa-check"></i><b>7.328</b> participant)</a></li>
<li class="chapter" data-level="7.329" data-path="lmem.html"><a href="lmem.html#data-tapped"><i class="fa fa-check"></i><b>7.329</b> Data: tapped</a></li>
<li class="chapter" data-level="7.330" data-path="lmem.html"><a href="lmem.html#section-311"><i class="fa fa-check"></i><b>7.330</b> </a></li>
<li class="chapter" data-level="7.331" data-path="lmem.html"><a href="lmem.html#reml-criterion-at-convergence--2911.9"><i class="fa fa-check"></i><b>7.331</b> REML criterion at convergence: -2911.9</a></li>
<li class="chapter" data-level="7.332" data-path="lmem.html"><a href="lmem.html#section-312"><i class="fa fa-check"></i><b>7.332</b> </a></li>
<li class="chapter" data-level="7.333" data-path="lmem.html"><a href="lmem.html#scaled-residuals-6"><i class="fa fa-check"></i><b>7.333</b> Scaled residuals:</a></li>
<li class="chapter" data-level="7.334" data-path="lmem.html"><a href="lmem.html#min-1q-median-3q-max-29"><i class="fa fa-check"></i><b>7.334</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="7.335" data-path="lmem.html"><a href="lmem.html#section-313"><i class="fa fa-check"></i><b>7.335</b> -3.8002 -0.5148 -0.0247 0.5248 5.3484</a></li>
<li class="chapter" data-level="7.336" data-path="lmem.html"><a href="lmem.html#section-314"><i class="fa fa-check"></i><b>7.336</b> </a></li>
<li class="chapter" data-level="7.337" data-path="lmem.html"><a href="lmem.html#random-effects-6"><i class="fa fa-check"></i><b>7.337</b> Random effects:</a></li>
<li class="chapter" data-level="7.338" data-path="lmem.html"><a href="lmem.html#groups-name-variance-std.dev.-6"><i class="fa fa-check"></i><b>7.338</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="7.339" data-path="lmem.html"><a href="lmem.html#participant-syntax.transspeechrate.slow-0.000e00-0.000000"><i class="fa fa-check"></i><b>7.339</b> participant syntax.trans:speechrate.slow 0.000e+00 0.000000</a></li>
<li class="chapter" data-level="7.340" data-path="lmem.html"><a href="lmem.html#participant.1-speechrate.slow-4.459e-04-0.021115"><i class="fa fa-check"></i><b>7.340</b> participant.1 speechrate.slow 4.459e-04 0.021115</a></li>
<li class="chapter" data-level="7.341" data-path="lmem.html"><a href="lmem.html#participant.2-syntax.trans-4.842e-05-0.006958"><i class="fa fa-check"></i><b>7.341</b> participant.2 syntax.trans 4.842e-05 0.006958</a></li>
<li class="chapter" data-level="7.342" data-path="lmem.html"><a href="lmem.html#participant.3-intercept-3.966e-04-0.019916"><i class="fa fa-check"></i><b>7.342</b> participant.3 (Intercept) 3.966e-04 0.019916</a></li>
<li class="chapter" data-level="7.343" data-path="lmem.html"><a href="lmem.html#item-syntax.transspeechrate.slow-0.000e00-0.000000"><i class="fa fa-check"></i><b>7.343</b> item syntax.trans:speechrate.slow 0.000e+00 0.000000</a></li>
<li class="chapter" data-level="7.344" data-path="lmem.html"><a href="lmem.html#item.1-speechrate.slow-1.245e-04-0.011158"><i class="fa fa-check"></i><b>7.344</b> item.1 speechrate.slow 1.245e-04 0.011158</a></li>
<li class="chapter" data-level="7.345" data-path="lmem.html"><a href="lmem.html#item.2-syntax.trans-4.895e-05-0.006996"><i class="fa fa-check"></i><b>7.345</b> item.2 syntax.trans 4.895e-05 0.006996</a></li>
<li class="chapter" data-level="7.346" data-path="lmem.html"><a href="lmem.html#item.3-intercept-1.428e-03-0.037785"><i class="fa fa-check"></i><b>7.346</b> item.3 (Intercept) 1.428e-03 0.037785</a></li>
<li class="chapter" data-level="7.347" data-path="lmem.html"><a href="lmem.html#residual-7.831e-04-0.027983"><i class="fa fa-check"></i><b>7.347</b> Residual 7.831e-04 0.027983</a></li>
<li class="chapter" data-level="7.348" data-path="lmem.html"><a href="lmem.html#number-of-obs-721-groups-participant-23-item-8"><i class="fa fa-check"></i><b>7.348</b> Number of obs: 721, groups: participant, 23; item, 8</a></li>
<li class="chapter" data-level="7.349" data-path="lmem.html"><a href="lmem.html#section-315"><i class="fa fa-check"></i><b>7.349</b> </a></li>
<li class="chapter" data-level="7.350" data-path="lmem.html"><a href="lmem.html#fixed-effects-6"><i class="fa fa-check"></i><b>7.350</b> Fixed effects:</a></li>
<li class="chapter" data-level="7.351" data-path="lmem.html"><a href="lmem.html#estimate-std.-error-df-t-value-2"><i class="fa fa-check"></i><b>7.351</b> Estimate Std. Error df t value</a></li>
<li class="chapter" data-level="7.352" data-path="lmem.html"><a href="lmem.html#intercept-0.101448-0.014029-8.381835-7.232"><i class="fa fa-check"></i><b>7.352</b> (Intercept) 0.101448 0.014029 8.381835 7.232</a></li>
<li class="chapter" data-level="7.353" data-path="lmem.html"><a href="lmem.html#syntax.trans--0.028215-0.003546-9.113087--7.956"><i class="fa fa-check"></i><b>7.353</b> syntax.trans -0.028215 0.003546 9.113087 -7.956</a></li>
<li class="chapter" data-level="7.354" data-path="lmem.html"><a href="lmem.html#speechrate.slow-0.043487-0.006269-18.830504-6.937"><i class="fa fa-check"></i><b>7.354</b> speechrate.slow 0.043487 0.006269 18.830504 6.937</a></li>
<li class="chapter" data-level="7.355" data-path="lmem.html"><a href="lmem.html#syntax.transspeechrate.slow--0.029350-0.004173-631.448408--7.033"><i class="fa fa-check"></i><b>7.355</b> syntax.trans:speechrate.slow -0.029350 0.004173 631.448408 -7.033</a></li>
<li class="chapter" data-level="7.356" data-path="lmem.html"><a href="lmem.html#prt-2"><i class="fa fa-check"></i><b>7.356</b> Pr(&gt;|t|)</a></li>
<li class="chapter" data-level="7.357" data-path="lmem.html"><a href="lmem.html#intercept-7.08e-05-syntax.trans-2.15e-05"><i class="fa fa-check"></i><b>7.357</b> (Intercept) 7.08e-05 <strong><em> ## syntax.trans 2.15e-05 </em></strong></a></li>
<li class="chapter" data-level="7.358" data-path="lmem.html"><a href="lmem.html#speechrate.slow-1.37e-06-syntax.transspeechrate.slow-5.25e-12"><i class="fa fa-check"></i><b>7.358</b> speechrate.slow 1.37e-06 <strong><em> ## syntax.trans:speechrate.slow 5.25e-12 </em></strong></a></li>
<li class="chapter" data-level="7.359" data-path="lmem.html"><a href="lmem.html#section-316"><i class="fa fa-check"></i><b>7.359</b> —</a></li>
<li class="chapter" data-level="7.360" data-path="lmem.html"><a href="lmem.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-22"><i class="fa fa-check"></i><b>7.360</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="7.361" data-path="lmem.html"><a href="lmem.html#section-317"><i class="fa fa-check"></i><b>7.361</b> </a></li>
<li class="chapter" data-level="7.362" data-path="lmem.html"><a href="lmem.html#correlation-of-fixed-effects-5"><i class="fa fa-check"></i><b>7.362</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="7.363" data-path="lmem.html"><a href="lmem.html#intr-syntx.-spchr."><i class="fa fa-check"></i><b>7.363</b> (Intr) syntx. spchr.</a></li>
<li class="chapter" data-level="7.364" data-path="lmem.html"><a href="lmem.html#syntax.trns-0.000"><i class="fa fa-check"></i><b>7.364</b> syntax.trns 0.000</a></li>
<li class="chapter" data-level="7.365" data-path="lmem.html"><a href="lmem.html#spechrt.slw-0.000-0.002"><i class="fa fa-check"></i><b>7.365</b> spechrt.slw 0.000 0.002</a></li>
<li class="chapter" data-level="7.366" data-path="lmem.html"><a href="lmem.html#syntx.trn.-0.001--0.001-0.000"><i class="fa fa-check"></i><b>7.366</b> syntx.trn:. 0.001 -0.001 0.000</a></li>
<li class="chapter" data-level="7.367" data-path="lmem.html"><a href="lmem.html#c6solns"><i class="fa fa-check"></i><b>7.367</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html"><i class="fa fa-check"></i><b>8</b> Mixed-effects logistic regression</a><ul>
<li class="chapter" data-level="8.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#loads-tappedmcgillling620.csv-from-osf-project-for-kilbourn-ceron-et-al-2017-data"><i class="fa fa-check"></i><b>8.1</b> loads tappedMcGillLing620.csv from OSF project for Kilbourn-Ceron et al (2017) data</a></li>
<li class="chapter" data-level="8.2" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#there-is-some-missing-data-for-tapped-variable-exclude-to-avoid-warnings-later"><i class="fa fa-check"></i><b>8.2</b> there is some missing data for ‘tapped’ variable – exclude to avoid warnings later</a></li>
<li class="chapter" data-level="8.3" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#loads-alternativesmcgillling620.csv-from-osf-project-for-wagner-2016-data-2"><i class="fa fa-check"></i><b>8.3</b> loads alternativesMcGillLing620.csv from OSF project for Wagner (2016) data</a></li>
<li class="chapter" data-level="8.4" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#loads-givennessmcgillling620.csv-from-osf-project-for-wagner-2012-data-3"><i class="fa fa-check"></i><b>8.4</b> loads givennessMcGillLing620.csv from OSF project for Wagner (2012) data</a></li>
<li class="chapter" data-level="8.5" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#function-for-computing-accuracy-of-a-logistic-regression-model"><i class="fa fa-check"></i><b>8.5</b> function for computing accuracy of a logistic regression model</a></li>
<li class="chapter" data-level="8.6" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#on-the-dataset-used-to-fit-the-model"><i class="fa fa-check"></i><b>8.6</b> (on the dataset used to fit the model)</a></li>
<li class="chapter" data-level="8.7" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod-fitted-model"><i class="fa fa-check"></i><b>8.7</b> lrMod = fitted model</a></li>
<li class="chapter" data-level="8.8" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#responsevar-name-of-response-variable-for-lrmod"><i class="fa fa-check"></i><b>8.8</b> responseVar = name of response variable for lrMod</a></li>
<li class="chapter" data-level="8.9" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#use.ranef-true-or-false-should-we-predict-for-grouping-factor-levels-in-this-data-or-for-an-average-level-truefalse"><i class="fa fa-check"></i><b>8.9</b> use.ranef = TRUE or FALSE (should we predict for grouping factor levels in this data, or for an “average” level? TRUE/FALSE)</a></li>
<li class="chapter" data-level="8.10" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#adapted-from-httpswww.r-bloggers.comevaluating-logistic-regression-models"><i class="fa fa-check"></i><b>8.10</b> adapted from: <a href="https://www.r-bloggers.com/evaluating-logistic-regression-models/" class="uri">https://www.r-bloggers.com/evaluating-logistic-regression-models/</a></a></li>
<li class="chapter" data-level="8.11" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#baseline-accuracy-for-a-logisitic-regression-model-lrmod"><i class="fa fa-check"></i><b>8.11</b> baseline accuracy for a logisitic regression model lrMod</a></li>
<li class="chapter" data-level="8.12" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#with-a-given-response-variable"><i class="fa fa-check"></i><b>8.12</b> with a given response variable</a></li>
<li class="chapter" data-level="8.13" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#preliminaries"><i class="fa fa-check"></i><b>8.13</b> Preliminaries</a><ul>
<li class="chapter" data-level="8.13.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#motivation"><i class="fa fa-check"></i><b>8.13.1</b> Motivation</a></li>
</ul></li>
<li class="chapter" data-level="8.14" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#basics"><i class="fa fa-check"></i><b>8.14</b> Basics</a><ul>
<li class="chapter" data-level="8.14.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7m1"><i class="fa fa-check"></i><b>8.14.1</b> Model 1: <code>givenness</code> data, crossed random effects (intercepts + slopes)</a></li>
</ul></li>
<li class="chapter" data-level="8.15" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#generalized-linear-mixed-model-fit-by-maximum-likelihood-laplace"><i class="fa fa-check"></i><b>8.15</b> Generalized linear mixed model fit by maximum likelihood (Laplace</a></li>
<li class="chapter" data-level="8.16" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#approximation-glmermod"><i class="fa fa-check"></i><b>8.16</b> Approximation) [glmerMod]</a></li>
<li class="chapter" data-level="8.17" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#family-binomial-logit"><i class="fa fa-check"></i><b>8.17</b> Family: binomial ( logit )</a></li>
<li class="chapter" data-level="8.18" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#formula-stressshift-clabel.williams-nptype.pron-voice.passive"><i class="fa fa-check"></i><b>8.18</b> Formula: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.19" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#clabel.williams-nptype.pron-item-1-clabel.williams"><i class="fa fa-check"></i><b>8.19</b> (1 + clabel.williams + npType.pron || item) + (1 + clabel.williams +</a></li>
<li class="chapter" data-level="8.20" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#nptype.pron-voice.passive-participant"><i class="fa fa-check"></i><b>8.20</b> npType.pron + voice.passive || participant)</a></li>
<li class="chapter" data-level="8.21" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-givenness-7"><i class="fa fa-check"></i><b>8.21</b> Data: givenness</a></li>
<li class="chapter" data-level="8.22" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#control-glmercontroloptimizer-bobyqa"><i class="fa fa-check"></i><b>8.22</b> Control: glmerControl(optimizer = “bobyqa”)</a></li>
<li class="chapter" data-level="8.23" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-318"><i class="fa fa-check"></i><b>8.23</b> </a></li>
<li class="chapter" data-level="8.24" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#aic-bic-loglik-deviance-df.resid"><i class="fa fa-check"></i><b>8.24</b> AIC BIC logLik deviance df.resid</a></li>
<li class="chapter" data-level="8.25" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-319"><i class="fa fa-check"></i><b>8.25</b> 349.6 393.0 -163.8 327.6 371</a></li>
<li class="chapter" data-level="8.26" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-320"><i class="fa fa-check"></i><b>8.26</b> </a></li>
<li class="chapter" data-level="8.27" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#scaled-residuals-7"><i class="fa fa-check"></i><b>8.27</b> Scaled residuals:</a></li>
<li class="chapter" data-level="8.28" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#min-1q-median-3q-max-30"><i class="fa fa-check"></i><b>8.28</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="8.29" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-321"><i class="fa fa-check"></i><b>8.29</b> -2.2442 -0.3174 -0.1881 0.4603 4.5955</a></li>
<li class="chapter" data-level="8.30" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-322"><i class="fa fa-check"></i><b>8.30</b> </a></li>
<li class="chapter" data-level="8.31" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#random-effects-7"><i class="fa fa-check"></i><b>8.31</b> Random effects:</a></li>
<li class="chapter" data-level="8.32" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#groups-name-variance-std.dev.-7"><i class="fa fa-check"></i><b>8.32</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="8.33" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant-voice.passive-1.648e00-1.284e00"><i class="fa fa-check"></i><b>8.33</b> participant voice.passive 1.648e+00 1.284e+00</a></li>
<li class="chapter" data-level="8.34" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant.1-nptype.pron-5.823e-01-7.631e-01"><i class="fa fa-check"></i><b>8.34</b> participant.1 npType.pron 5.823e-01 7.631e-01</a></li>
<li class="chapter" data-level="8.35" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant.2-clabel.williams-5.013e-15-7.080e-08"><i class="fa fa-check"></i><b>8.35</b> participant.2 clabel.williams 5.013e-15 7.080e-08</a></li>
<li class="chapter" data-level="8.36" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant.3-intercept-1.685e-01-4.105e-01"><i class="fa fa-check"></i><b>8.36</b> participant.3 (Intercept) 1.685e-01 4.105e-01</a></li>
<li class="chapter" data-level="8.37" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#item-nptype.pron-5.394e-01-7.344e-01"><i class="fa fa-check"></i><b>8.37</b> item npType.pron 5.394e-01 7.344e-01</a></li>
<li class="chapter" data-level="8.38" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#item.1-clabel.williams-1.619e00-1.273e00"><i class="fa fa-check"></i><b>8.38</b> item.1 clabel.williams 1.619e+00 1.273e+00</a></li>
<li class="chapter" data-level="8.39" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#item.2-intercept-2.624e-14-1.620e-07"><i class="fa fa-check"></i><b>8.39</b> item.2 (Intercept) 2.624e-14 1.620e-07</a></li>
<li class="chapter" data-level="8.40" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#number-of-obs-382-groups-participant-27-item-16-4"><i class="fa fa-check"></i><b>8.40</b> Number of obs: 382, groups: participant, 27; item, 16</a></li>
<li class="chapter" data-level="8.41" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-323"><i class="fa fa-check"></i><b>8.41</b> </a></li>
<li class="chapter" data-level="8.42" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fixed-effects-7"><i class="fa fa-check"></i><b>8.42</b> Fixed effects:</a></li>
<li class="chapter" data-level="8.43" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#estimate-std.-error-z-value-prz-3"><i class="fa fa-check"></i><b>8.43</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li class="chapter" data-level="8.44" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#intercept--1.1383-0.2076--5.483-4.18e-08-clabel.williams-3.7711-0.5676-6.644-3.05e-11"><i class="fa fa-check"></i><b>8.44</b> (Intercept) -1.1383 0.2076 -5.483 4.18e-08 <strong><em> ## clabel.williams 3.7711 0.5676 6.644 3.05e-11 </em></strong></a></li>
<li><a href="mixed-effects-logistic-regression.html#nptype.pron-0.7917-0.3987-1.986-0.0471-voice.passive-0.6496-0.4149-1.566-0.1174"><span class="toc-section-number">8.45</span> npType.pron 0.7917 0.3987 1.986 0.0471 *<br />
## voice.passive 0.6496 0.4149 1.566 0.1174</a></li>
<li class="chapter" data-level="8.46" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-324"><i class="fa fa-check"></i><b>8.46</b> —</a></li>
<li class="chapter" data-level="8.47" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-23"><i class="fa fa-check"></i><b>8.47</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="8.48" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-325"><i class="fa fa-check"></i><b>8.48</b> </a></li>
<li class="chapter" data-level="8.49" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#correlation-of-fixed-effects-6"><i class="fa fa-check"></i><b>8.49</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="8.50" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#intr-clbl.w-nptyp."><i class="fa fa-check"></i><b>8.50</b> (Intr) clbl.w npTyp.</a></li>
<li class="chapter" data-level="8.51" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#clabl.wllms--0.458"><i class="fa fa-check"></i><b>8.51</b> clabl.wllms -0.458</a></li>
<li class="chapter" data-level="8.52" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#nptype.pron--0.141-0.174"><i class="fa fa-check"></i><b>8.52</b> npType.pron -0.141 0.174</a></li>
<li class="chapter" data-level="8.53" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#voice.passv--0.036-0.082-0.028"><i class="fa fa-check"></i><b>8.53</b> voice.passv -0.036 0.082 0.028</a></li>
<li class="chapter" data-level="8.54" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#hypothesis-testing-3"><i class="fa fa-check"></i><b>8.54</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="8.54.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fixed-effects-8"><i class="fa fa-check"></i><b>8.54.1</b> Fixed effects</a></li>
</ul></li>
<li class="chapter" data-level="8.55" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-givenness-8"><i class="fa fa-check"></i><b>8.55</b> Data: givenness</a></li>
<li class="chapter" data-level="8.56" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#models-2"><i class="fa fa-check"></i><b>8.56</b> Models:</a></li>
<li class="chapter" data-level="8.57" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.sub-stressshift-clabel.williams-voice.passive-1-clabel.williams"><i class="fa fa-check"></i><b>8.57</b> lrMod1.sub: stressshift ~ clabel.williams + voice.passive + (1 + clabel.williams +</a></li>
<li class="chapter" data-level="8.58" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.sub-nptype.pron-item-1-clabel.williams-nptype.pron"><i class="fa fa-check"></i><b>8.58</b> lrMod1.sub: npType.pron || item) + (1 + clabel.williams + npType.pron +</a></li>
<li class="chapter" data-level="8.59" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.sub-voice.passive-participant"><i class="fa fa-check"></i><b>8.59</b> lrMod1.sub: voice.passive || participant)</a></li>
<li class="chapter" data-level="8.60" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-stressshift-clabel.williams-nptype.pron-voice.passive"><i class="fa fa-check"></i><b>8.60</b> lrMod1: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.61" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-1-clabel.williams-nptype.pron-item-1-clabel.williams"><i class="fa fa-check"></i><b>8.61</b> lrMod1: (1 + clabel.williams + npType.pron || item) + (1 + clabel.williams +</a></li>
<li class="chapter" data-level="8.62" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-nptype.pron-voice.passive-participant"><i class="fa fa-check"></i><b>8.62</b> lrMod1: npType.pron + voice.passive || participant)</a></li>
<li class="chapter" data-level="8.63" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-2"><i class="fa fa-check"></i><b>8.63</b> Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)</a></li>
<li class="chapter" data-level="8.64" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.sub-10-351.18-390.63--165.59-331.18"><i class="fa fa-check"></i><b>8.64</b> lrMod1.sub 10 351.18 390.63 -165.59 331.18</a></li>
<li class="chapter" data-level="8.65" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-11-349.64-393.04--163.82-327.64-3.5413-1-0.05986-."><i class="fa fa-check"></i><b>8.65</b> lrMod1 11 349.64 393.04 -163.82 327.64 3.5413 1 0.05986 .</a></li>
<li class="chapter" data-level="8.66" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-326"><i class="fa fa-check"></i><b>8.66</b> —</a></li>
<li class="chapter" data-level="8.67" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-24"><i class="fa fa-check"></i><b>8.67</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="8.68" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fit-model-and-get-lr-based-p-values"><i class="fa fa-check"></i><b>8.68</b> fit model and get LR-based p-values:</a></li>
<li class="chapter" data-level="8.69" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fitting-4-glmer-models"><i class="fa fa-check"></i><b>8.69</b> Fitting 4 (g)lmer() models:</a></li>
<li class="chapter" data-level="8.70" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-327"><i class="fa fa-check"></i><b>8.70</b> [….]</a></li>
<li class="chapter" data-level="8.71" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#see-the-results"><i class="fa fa-check"></i><b>8.71</b> see the results:</a></li>
<li class="chapter" data-level="8.72" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#mixed-model-anova-table-type-3-tests-lrt-method"><i class="fa fa-check"></i><b>8.72</b> Mixed Model Anova Table (Type 3 tests, LRT-method)</a></li>
<li class="chapter" data-level="8.73" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-328"><i class="fa fa-check"></i><b>8.73</b> </a></li>
<li class="chapter" data-level="8.74" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-stressshift-clabel.williams-nptype.pron-voice.passive"><i class="fa fa-check"></i><b>8.74</b> Model: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.75" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-1-clabel.williams-nptype.pron-item-1-clabel.williams"><i class="fa fa-check"></i><b>8.75</b> Model: (1 + clabel.williams + npType.pron || item) + (1 + clabel.williams +</a></li>
<li class="chapter" data-level="8.76" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-nptype.pron-voice.passive-participant"><i class="fa fa-check"></i><b>8.76</b> Model: npType.pron + voice.passive || participant)</a></li>
<li class="chapter" data-level="8.77" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-givenness-9"><i class="fa fa-check"></i><b>8.77</b> Data: givenness</a></li>
<li class="chapter" data-level="8.78" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#df-full-model-11"><i class="fa fa-check"></i><b>8.78</b> Df full model: 11</a></li>
<li class="chapter" data-level="8.79" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#effect-df-chisq-p.value"><i class="fa fa-check"></i><b>8.79</b> Effect df Chisq p.value</a></li>
<li class="chapter" data-level="8.80" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#clabel.williams-1-26.67-.0001"><i class="fa fa-check"></i><b>8.80</b> 1 clabel.williams 1 26.67 *** &lt;.0001</a></li>
<li class="chapter" data-level="8.81" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#nptype.pron-1-3.54-.06"><i class="fa fa-check"></i><b>8.81</b> 2 npType.pron 1 3.54 + .06</a></li>
<li class="chapter" data-level="8.82" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#voice.passive-1-2.36-.12"><i class="fa fa-check"></i><b>8.82</b> 3 voice.passive 1 2.36 .12</a></li>
<li class="chapter" data-level="8.83" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-329"><i class="fa fa-check"></i><b>8.83</b> —</a></li>
<li class="chapter" data-level="8.84" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-0.1-1-1"><i class="fa fa-check"></i><b>8.84</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘+’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="8.85" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#use-multiple-cores-if-your-machine-has-them."><i class="fa fa-check"></i><b>8.85</b> use multiple cores, if your machine has them.</a></li>
<li class="chapter" data-level="8.86" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-330"><i class="fa fa-check"></i><b>8.86</b> [1] 8</a></li>
<li class="chapter" data-level="8.87" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fit-a-random-intercepts-only-model-in-general-not-ok-but-it-would-take-much-longer-to-fit-the-model-with-random-slopes."><i class="fa fa-check"></i><b>8.87</b> fit a <em>random-intercepts only</em> model (in general, not OK, but it would take much longer to fit the model with random slopes).</a></li>
<li class="chapter" data-level="8.88" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#this-still-takes-5-minutes-on-my-8-core-computer"><i class="fa fa-check"></i><b>8.88</b> This still takes 5 minutes on my 8-core computer:</a></li>
<li class="chapter" data-level="8.89" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fitting-4-glmer-models."><i class="fa fa-check"></i><b>8.89</b> Fitting 4 (g)lmer() models.</a></li>
<li class="chapter" data-level="8.90" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#obtaining-3-p-values"><i class="fa fa-check"></i><b>8.90</b> Obtaining 3 p-values:</a></li>
<li class="chapter" data-level="8.91" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-331"><i class="fa fa-check"></i><b>8.91</b> […]</a></li>
<li class="chapter" data-level="8.92" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#look-at-the-p-values-nb-0.001-minimum-p-value-when-nsim1000"><i class="fa fa-check"></i><b>8.92</b> look at the p-values (nb: 0.001 = minimum p-value when nsim=1000)</a></li>
<li class="chapter" data-level="8.93" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#mixed-model-anova-table-type-3-tests-pb-method"><i class="fa fa-check"></i><b>8.93</b> Mixed Model Anova Table (Type 3 tests, PB-method)</a></li>
<li class="chapter" data-level="8.94" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-332"><i class="fa fa-check"></i><b>8.94</b> </a></li>
<li class="chapter" data-level="8.95" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-stressshift-clabel.williams-nptype.pron-voice.passive-1"><i class="fa fa-check"></i><b>8.95</b> Model: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.96" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-1-item-1-participant"><i class="fa fa-check"></i><b>8.96</b> Model: (1 | item) + (1 | participant)</a></li>
<li class="chapter" data-level="8.97" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-givenness-10"><i class="fa fa-check"></i><b>8.97</b> Data: givenness</a></li>
<li class="chapter" data-level="8.98" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#effect-df-chisq-p.value-1"><i class="fa fa-check"></i><b>8.98</b> Effect df Chisq p.value</a></li>
<li class="chapter" data-level="8.99" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#clabel.williams-1-150.61-.0010"><i class="fa fa-check"></i><b>8.99</b> 1 clabel.williams 1 150.61 *** .0010</a></li>
<li class="chapter" data-level="8.100" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#nptype.pron-1-5.06-.03"><i class="fa fa-check"></i><b>8.100</b> 2 npType.pron 1 5.06 * .03</a></li>
<li class="chapter" data-level="8.101" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#voice.passive-1-7.43-.009"><i class="fa fa-check"></i><b>8.101</b> 3 voice.passive 1 7.43 ** .009</a></li>
<li class="chapter" data-level="8.102" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-333"><i class="fa fa-check"></i><b>8.102</b> —</a></li>
<li class="chapter" data-level="8.103" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-0.1-1-2"><i class="fa fa-check"></i><b>8.103</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘+’ 0.1 ‘’ 1</a><ul>
<li class="chapter" data-level="8.103.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#random-effects-8"><i class="fa fa-check"></i><b>8.103.1</b> Random effects</a></li>
</ul></li>
<li class="chapter" data-level="8.104" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-givenness-11"><i class="fa fa-check"></i><b>8.104</b> Data: givenness</a></li>
<li class="chapter" data-level="8.105" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#models-3"><i class="fa fa-check"></i><b>8.105</b> Models:</a></li>
<li class="chapter" data-level="8.106" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.1-stressshift-clabel.williams-nptype.pron-voice.passive"><i class="fa fa-check"></i><b>8.106</b> lrMod1.1: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.107" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.1-1-nptype.pron-item-1-nptype.pron-voice.passive"><i class="fa fa-check"></i><b>8.107</b> lrMod1.1: (1 + npType.pron || item) + (1 + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.108" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.1-clabel.williams-participant"><i class="fa fa-check"></i><b>8.108</b> lrMod1.1: clabel.williams || participant)</a></li>
<li class="chapter" data-level="8.109" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-stressshift-clabel.williams-nptype.pron-voice.passive-1"><i class="fa fa-check"></i><b>8.109</b> lrMod1: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.110" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-1-clabel.williams-nptype.pron-item-1-clabel.williams-1"><i class="fa fa-check"></i><b>8.110</b> lrMod1: (1 + clabel.williams + npType.pron || item) + (1 + clabel.williams +</a></li>
<li class="chapter" data-level="8.111" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-nptype.pron-voice.passive-participant-1"><i class="fa fa-check"></i><b>8.111</b> lrMod1: npType.pron + voice.passive || participant)</a></li>
<li class="chapter" data-level="8.112" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-3"><i class="fa fa-check"></i><b>8.112</b> Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)</a></li>
<li class="chapter" data-level="8.113" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1.1-10-352.24-391.69--166.12-332.24"><i class="fa fa-check"></i><b>8.113</b> lrMod1.1 10 352.24 391.69 -166.12 332.24</a></li>
<li><a href="mixed-effects-logistic-regression.html#lrmod1-11-349.64-393.04--163.82-327.64-4.5994-1-0.03198-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-fixed-and-random-effects-all-terms-involving-voice-excluded-data-givenness-models-lrmod1.1-stressshift-clabel.williams-nptype.pron-1-clabel.williams-lrmod1.1-nptype.pron-item-1-nptype.pron-clabel.williams-lrmod1.1-participant-lrmod1-stressshift-clabel.williams-nptype.pron-voice.passive-lrmod1-1-clabel.williams-nptype.pron-item-1-clabel.williams-lrmod1-nptype.pron-voice.passive-participant-df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-lrmod1.1-9-353.08-388.59--167.54-335.08-lrmod1-11-349.64-393.04--163.82-327.64-7.4458-2-0.02416"><span class="toc-section-number">8.114</span> lrMod1 11 349.64 393.04 -163.82 327.64 4.5994 1 0.03198 <em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## Fixed and random effects ## all terms involving <code>voice</code> excluded ## Data: givenness ## Models: ## lrMod1.1: stressshift ~ clabel.williams + npType.pron + (1 + clabel.williams + ## lrMod1.1: npType.pron || item) + (1 + npType.pron + clabel.williams || ## lrMod1.1: participant) ## lrMod1: stressshift ~ clabel.williams + npType.pron + voice.passive + ## lrMod1: (1 + clabel.williams + npType.pron || item) + (1 + clabel.williams + ## lrMod1: npType.pron + voice.passive || participant) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)<br />
## lrMod1.1 9 353.08 388.59 -167.54 335.08<br />
## lrMod1 11 349.64 393.04 -163.82 327.64 7.4458 2 0.02416 </em></a></li>
<li class="chapter" data-level="8.115" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-334"><i class="fa fa-check"></i><b>8.115</b> —</a></li>
<li class="chapter" data-level="8.116" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-25"><i class="fa fa-check"></i><b>8.116</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="8.117" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#melr-practice"><i class="fa fa-check"></i><b>8.117</b> MELR Practice</a><ul>
<li class="chapter" data-level="8.117.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7ex1"><i class="fa fa-check"></i><b>8.117.1</b> Exercise 1: tapping</a></li>
</ul></li>
<li class="chapter" data-level="8.118" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#model-criticism-for-mixed-effects-logistic-regression"><i class="fa fa-check"></i><b>8.118</b> Model criticism for mixed-effects logistic regression</a><ul>
<li class="chapter" data-level="8.118.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#random-effect-distributions"><i class="fa fa-check"></i><b>8.118.1</b> Random-effect distributions</a></li>
<li class="chapter" data-level="8.118.2" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#residual-plots"><i class="fa fa-check"></i><b>8.118.2</b> Residual plots</a></li>
<li class="chapter" data-level="8.118.3" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#influence"><i class="fa fa-check"></i><b>8.118.3</b> Influence</a></li>
</ul></li>
<li class="chapter" data-level="8.119" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-335"><i class="fa fa-check"></i><b>8.119</b> [,1]</a></li>
<li class="chapter" data-level="8.120" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-336"><i class="fa fa-check"></i><b>8.120</b> 530 0.225778367</a></li>
<li class="chapter" data-level="8.121" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-337"><i class="fa fa-check"></i><b>8.121</b> 548 0.185550214</a></li>
<li class="chapter" data-level="8.122" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-338"><i class="fa fa-check"></i><b>8.122</b> 563 0.074174496</a></li>
<li class="chapter" data-level="8.123" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-339"><i class="fa fa-check"></i><b>8.123</b> 529 0.063628074</a></li>
<li class="chapter" data-level="8.124" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-340"><i class="fa fa-check"></i><b>8.124</b> 554 0.055073386</a></li>
<li class="chapter" data-level="8.125" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-341"><i class="fa fa-check"></i><b>8.125</b> 297 0.053395685</a></li>
<li class="chapter" data-level="8.126" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-342"><i class="fa fa-check"></i><b>8.126</b> 541 0.052571319</a></li>
<li class="chapter" data-level="8.127" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-343"><i class="fa fa-check"></i><b>8.127</b> 549 0.044627482</a></li>
<li class="chapter" data-level="8.128" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-344"><i class="fa fa-check"></i><b>8.128</b> 24 0.043046353</a></li>
<li class="chapter" data-level="8.129" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-345"><i class="fa fa-check"></i><b>8.129</b> 540 0.039707331</a></li>
<li class="chapter" data-level="8.130" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-346"><i class="fa fa-check"></i><b>8.130</b> 547 0.039506196</a></li>
<li class="chapter" data-level="8.131" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-347"><i class="fa fa-check"></i><b>8.131</b> 557 0.038630256</a></li>
<li class="chapter" data-level="8.132" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-348"><i class="fa fa-check"></i><b>8.132</b> 432 0.035733805</a></li>
<li class="chapter" data-level="8.133" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-349"><i class="fa fa-check"></i><b>8.133</b> 555 0.030503148</a></li>
<li class="chapter" data-level="8.134" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-350"><i class="fa fa-check"></i><b>8.134</b> 544 0.028093074</a></li>
<li class="chapter" data-level="8.135" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-351"><i class="fa fa-check"></i><b>8.135</b> 553 0.025852398</a></li>
<li class="chapter" data-level="8.136" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-352"><i class="fa fa-check"></i><b>8.136</b> 556 0.022235841</a></li>
<li class="chapter" data-level="8.137" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-353"><i class="fa fa-check"></i><b>8.137</b> 564 0.019375321</a></li>
<li class="chapter" data-level="8.138" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-354"><i class="fa fa-check"></i><b>8.138</b> 559 0.016134504</a></li>
<li class="chapter" data-level="8.139" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-355"><i class="fa fa-check"></i><b>8.139</b> 550 0.015203804</a></li>
<li class="chapter" data-level="8.140" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-356"><i class="fa fa-check"></i><b>8.140</b> 552 0.013620053</a></li>
<li class="chapter" data-level="8.141" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-357"><i class="fa fa-check"></i><b>8.141</b> 558 0.012093557</a></li>
<li class="chapter" data-level="8.142" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-358"><i class="fa fa-check"></i><b>8.142</b> 561 0.012054054</a></li>
<li class="chapter" data-level="8.143" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-359"><i class="fa fa-check"></i><b>8.143</b> 560 0.010068154</a></li>
<li class="chapter" data-level="8.144" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-360"><i class="fa fa-check"></i><b>8.144</b> 542 0.008765176</a></li>
<li class="chapter" data-level="8.145" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-361"><i class="fa fa-check"></i><b>8.145</b> 524 0.008675731</a></li>
<li class="chapter" data-level="8.146" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-362"><i class="fa fa-check"></i><b>8.146</b> 562 0.008593942</a></li>
<li class="chapter" data-level="8.147" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#estimate-std.-error-z-value-prz-4"><i class="fa fa-check"></i><b>8.147</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li class="chapter" data-level="8.148" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#intercept--1.1383258-0.2076053--5.483124-4.178800e-08"><i class="fa fa-check"></i><b>8.148</b> (Intercept) -1.1383258 0.2076053 -5.483124 4.178800e-08</a></li>
<li class="chapter" data-level="8.149" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#clabel.williams-3.7710505-0.5675843-6.644036-3.052075e-11"><i class="fa fa-check"></i><b>8.149</b> clabel.williams 3.7710505 0.5675843 6.644036 3.052075e-11</a></li>
<li class="chapter" data-level="8.150" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#nptype.pron-0.7917211-0.3987366-1.985574-4.708063e-02"><i class="fa fa-check"></i><b>8.150</b> npType.pron 0.7917211 0.3987366 1.985574 4.708063e-02</a></li>
<li class="chapter" data-level="8.151" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#voice.passive-0.6496316-0.4149409-1.565600-1.174422e-01"><i class="fa fa-check"></i><b>8.151</b> voice.passive 0.6496316 0.4149409 1.565600 1.174422e-01</a></li>
<li class="chapter" data-level="8.152" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#estimate-std.-error-z-value-prz-5"><i class="fa fa-check"></i><b>8.152</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li class="chapter" data-level="8.153" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#intercept--1.1848192-0.2138651--5.540030-3.024197e-08"><i class="fa fa-check"></i><b>8.153</b> (Intercept) -1.1848192 0.2138651 -5.540030 3.024197e-08</a></li>
<li class="chapter" data-level="8.154" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#clabel.williams-3.8105677-0.5956800-6.397005-1.584543e-10"><i class="fa fa-check"></i><b>8.154</b> clabel.williams 3.8105677 0.5956800 6.397005 1.584543e-10</a></li>
<li class="chapter" data-level="8.155" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#nptype.pron-0.9129111-0.3427896-2.663182-7.740552e-03"><i class="fa fa-check"></i><b>8.155</b> npType.pron 0.9129111 0.3427896 2.663182 7.740552e-03</a></li>
<li class="chapter" data-level="8.156" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#voice.passive-0.3137257-0.3848432-0.815204-4.149556e-01"><i class="fa fa-check"></i><b>8.156</b> voice.passive 0.3137257 0.3848432 0.815204 4.149556e-01</a></li>
<li class="chapter" data-level="8.157" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#evaluation-measures"><i class="fa fa-check"></i><b>8.157</b> Evaluation measures</a><ul>
<li class="chapter" data-level="8.157.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#evaluation-measure-1-likelihood-ratio-test"><i class="fa fa-check"></i><b>8.157.1</b> Evaluation measure 1: Likelihood ratio test</a></li>
</ul></li>
<li class="chapter" data-level="8.158" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-givenness-12"><i class="fa fa-check"></i><b>8.158</b> Data: givenness</a></li>
<li class="chapter" data-level="8.159" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#models-4"><i class="fa fa-check"></i><b>8.159</b> Models:</a></li>
<li class="chapter" data-level="8.160" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#m0-stressshift-1-item-1-participant"><i class="fa fa-check"></i><b>8.160</b> m0: stressshift ~ (1 | item) + (1 | participant)</a></li>
<li class="chapter" data-level="8.161" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-stressshift-clabel.williams-nptype.pron-voice.passive-2"><i class="fa fa-check"></i><b>8.161</b> lrMod1: stressshift ~ clabel.williams + npType.pron + voice.passive +</a></li>
<li class="chapter" data-level="8.162" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-1-clabel.williams-nptype.pron-item-1-clabel.williams-2"><i class="fa fa-check"></i><b>8.162</b> lrMod1: (1 + clabel.williams + npType.pron || item) + (1 + clabel.williams +</a></li>
<li class="chapter" data-level="8.163" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#lrmod1-nptype.pron-voice.passive-participant-2"><i class="fa fa-check"></i><b>8.163</b> lrMod1: npType.pron + voice.passive || participant)</a></li>
<li class="chapter" data-level="8.164" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-4"><i class="fa fa-check"></i><b>8.164</b> Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)</a></li>
<li class="chapter" data-level="8.165" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#m0-3-502.24-514.08--248.12-496.24"><i class="fa fa-check"></i><b>8.165</b> m0 3 502.24 514.08 -248.12 496.24</a></li>
<li><a href="mixed-effects-logistic-regression.html#lrmod1-11-349.64-393.04--163.82-327.64-168.6-8-2.2e-16-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-evaluation-measure-2-classification-accuracy-1-0.8638743-1-0.6465969-1-0.7879581-miscellaneous-mixed-effects-regression-topics-random-effect-correlation-issues-c7m2-groups-name-std.dev.-corr-participant-intercept-0.67835-clabel.williams-1.19637--0.726-nptype.pron-1.30652--0.218-0.657-voice.passive-1.32666--0.141--0.094--0.796-item-intercept-0.45694-clabel.williams-1.51394--1.000-nptype.pron-0.85705-1.000--1.000-example-dropping-correlation-terms-groups-name-std.dev.-corr-participant-intercept-0.60099-clabel.williams-1.05584--0.642-nptype.pron-1.30842--0.070-0.655-voice.passive-1.29183--0.201--0.157--0.827-item-intercept-0.41505-clabel.williams-1.40683--1.000-item.1-nptype.pron-0.70982-groups-name-std.dev.-corr-participant-intercept-0.54756-clabel.williams-1.02080--0.549-nptype.pron-1.33817-0.007-0.644-voice.passive-1.30948--0.327--0.082--0.807-item-intercept-0.00000-item.1-clabel.williams-1.13985-item.2-nptype.pron-0.70400-data-givenness-models-lrmod2.red2-stressshift-clabel.williams-nptype.pron-voice.passive-lrmod2.red2-1-clabel.williams-nptype.pron-voice.passive-participant-lrmod2.red2-1-item-0-clabel.williams-item-0-nptype.pron-lrmod2.red2-item-lrmod2-stressshift-clabel.williams-nptype.pron-voice.passive-lrmod2-1-clabel.williams-nptype.pron-item-1-clabel.williams-lrmod2-nptype.pron-voice.passive-participant-df-aic-bic-loglik-deviance-chisq-chi-df-prchisq-lrmod2.red2-17-352.88-419.95--159.44-318.88-lrmod2-20-353.31-432.22--156.66-313.31-5.5704-3-0.1345-example-bayesian-mems-bayesian-mems-cov-prior-participant-wishartdf-6.5-scale-inf-posterior.scale-cov-common.scale-true-item-wishartdf-5.5-scale-inf-posterior.scale-cov-common.scale-true-prior-dev--2.976-generalized-linear-mixed-model-fit-by-maximum-likelihood-laplace-approximation-bglmermod-family-binomial-logit-formula-stressshift-clabel.williams-nptype.pron-voice.passive-1-clabel.williams-nptype.pron-item-1-clabel.williams-nptype.pron-voice.passive-participant-data-givenness-control-glmercontroloptimizer-bobyqa-aic-bic-loglik-deviance-df.resid-360.5-439.4--160.3-320.5-362-scaled-residuals-min-1q-median-3q-max--2.05023--0.24401--0.07532-0.29963-2.57711-random-effects-groups-name-variance-std.dev.-corr-participant-intercept-1.1974-1.0943-clabel.williams-3.1481-1.7743--0.62-nptype.pron-3.4775-1.8648--0.18-0.50-voice.passive-3.7961-1.9484-0.03-0.06--0.68-item-intercept-0.7312-0.8551-clabel.williams-4.6235-2.1502--0.79-nptype.pron-1.9166-1.3844-0.56--0.73-number-of-obs-382-groups-participant-27-item-16-fixed-effects-estimate-std.-error-z-value-prz-intercept--1.9235-0.5112--3.763-0.000168"><span class="toc-section-number">8.166</span> lrMod1 11 349.64 393.04 -163.82 327.64 168.6 8 &lt; 2.2e-16 <strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ### Evaluation measure 2: Classification accuracy ## [1] 0.8638743 ## [1] 0.6465969 ## [1] 0.7879581 ## Miscellaneous mixed-effects regression topics ### Random-effect correlation issues {#c7m2} ## Groups Name Std.Dev. Corr<br />
## participant (Intercept) 0.67835<br />
## clabel.williams 1.19637 -0.726<br />
## npType.pron 1.30652 -0.218 0.657<br />
## voice.passive 1.32666 -0.141 -0.094 -0.796 ## item (Intercept) 0.45694<br />
## clabel.williams 1.51394 -1.000<br />
## npType.pron 0.85705 1.000 -1.000 #### Example: Dropping correlation terms ## Groups Name Std.Dev. Corr<br />
## participant (Intercept) 0.60099<br />
## clabel.williams 1.05584 -0.642<br />
## npType.pron 1.30842 -0.070 0.655<br />
## voice.passive 1.29183 -0.201 -0.157 -0.827 ## item (Intercept) 0.41505<br />
## clabel.williams 1.40683 -1.000<br />
## item.1 npType.pron 0.70982 ## Groups Name Std.Dev. Corr<br />
## participant (Intercept) 0.54756<br />
## clabel.williams 1.02080 -0.549<br />
## npType.pron 1.33817 0.007 0.644<br />
## voice.passive 1.30948 -0.327 -0.082 -0.807 ## item (Intercept) 0.00000<br />
## item.1 clabel.williams 1.13985<br />
## item.2 npType.pron 0.70400 ## Data: givenness ## Models: ## lrMod2.red2: stressshift ~ clabel.williams + npType.pron + voice.passive + ## lrMod2.red2: (1 + clabel.williams + npType.pron + voice.passive | participant) + ## lrMod2.red2: (1 | item) + (0 + clabel.williams | item) + (0 + npType.pron | ## lrMod2.red2: item) ## lrMod2: stressshift ~ clabel.williams + npType.pron + voice.passive + ## lrMod2: (1 + clabel.williams + npType.pron | item) + (1 + clabel.williams + ## lrMod2: npType.pron + voice.passive | participant) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## lrMod2.red2 17 352.88 419.95 -159.44 318.88<br />
## lrMod2 20 353.31 432.22 -156.66 313.31 5.5704 3 0.1345 #### Example: Bayesian MEMs {#bayesian-mems} ## Cov prior : participant ~ wishart(df = 6.5, scale = Inf, posterior.scale = cov, common.scale = TRUE) ## : item ~ wishart(df = 5.5, scale = Inf, posterior.scale = cov, common.scale = TRUE) ## Prior dev : -2.976 ## ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [bglmerMod] ## Family: binomial ( logit ) ## Formula: stressshift ~ clabel.williams + npType.pron + voice.passive +<br />
## (1 + clabel.williams + npType.pron | item) + (1 + clabel.williams +<br />
## npType.pron + voice.passive | participant) ## Data: givenness ## Control: glmerControl(optimizer = “bobyqa”) ## ## AIC BIC logLik deviance df.resid ## 360.5 439.4 -160.3 320.5 362 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.05023 -0.24401 -0.07532 0.29963 2.57711 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr<br />
## participant (Intercept) 1.1974 1.0943<br />
## clabel.williams 3.1481 1.7743 -0.62<br />
## npType.pron 3.4775 1.8648 -0.18 0.50<br />
## voice.passive 3.7961 1.9484 0.03 0.06 -0.68 ## item (Intercept) 0.7312 0.8551<br />
## clabel.williams 4.6235 2.1502 -0.79<br />
## npType.pron 1.9166 1.3844 0.56 -0.73<br />
## Number of obs: 382, groups: participant, 27; item, 16 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -1.9235 0.5112 -3.763 0.000168 </em></strong></a></li>
<li><a href="mixed-effects-logistic-regression.html#clabel.williams-5.8044-1.1396-5.093-3.52e-07-nptype.pron-0.9937-0.6655-1.493-0.135425-voice.passive-1.2633-0.6879-1.836-0.066286-.-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-clbl.w-nptyp.-clabl.wllms--0.799-nptype.pron-0.027-0.011-voice.passv--0.151-0.235--0.199-generalized-linear-mixed-model-fit-by-maximum-likelihood-laplace-approximation-glmermod-family-binomial-logit-formula-stressshift-clabel.williams-nptype.pron-voice.passive-1-clabel.williams-nptype.pron-item-1-clabel.williams-nptype.pron-voice.passive-participant-data-givenness-control-glmercontroloptimizer-bobyqa-aic-bic-loglik-deviance-df.resid-353.3-432.2--156.7-313.3-362-scaled-residuals-min-1q-median-3q-max--2.1302--0.2737--0.1186-0.4182-3.7528-random-effects-groups-name-variance-std.dev.-corr-participant-intercept-0.4602-0.6783-clabel.williams-1.4313-1.1964--0.73-nptype.pron-1.7070-1.3065--0.22-0.66-voice.passive-1.7600-1.3267--0.14--0.09--0.80-item-intercept-0.2088-0.4569-clabel.williams-2.2920-1.5139--1.00-nptype.pron-0.7345-0.8571-1.00--1.00-number-of-obs-382-groups-participant-27-item-16-fixed-effects-estimate-std.-error-z-value-prz-intercept--1.5286-0.3601--4.245-2.19e-05"><span class="toc-section-number">8.167</span> clabel.williams 5.8044 1.1396 5.093 3.52e-07 <strong><em> ## npType.pron 0.9937 0.6655 1.493 0.135425<br />
## voice.passive 1.2633 0.6879 1.836 0.066286 .<br />
## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Correlation of Fixed Effects: ## (Intr) clbl.w npTyp. ## clabl.wllms -0.799<br />
## npType.pron 0.027 0.011<br />
## voice.passv -0.151 0.235 -0.199 ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: stressshift ~ clabel.williams + npType.pron + voice.passive +<br />
## (1 + clabel.williams + npType.pron | item) + (1 + clabel.williams +<br />
## npType.pron + voice.passive | participant) ## Data: givenness ## Control: glmerControl(optimizer = “bobyqa”) ## ## AIC BIC logLik deviance df.resid ## 353.3 432.2 -156.7 313.3 362 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.1302 -0.2737 -0.1186 0.4182 3.7528 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr<br />
## participant (Intercept) 0.4602 0.6783<br />
## clabel.williams 1.4313 1.1964 -0.73<br />
## npType.pron 1.7070 1.3065 -0.22 0.66<br />
## voice.passive 1.7600 1.3267 -0.14 -0.09 -0.80 ## item (Intercept) 0.2088 0.4569<br />
## clabel.williams 2.2920 1.5139 -1.00<br />
## npType.pron 0.7345 0.8571 1.00 -1.00<br />
## Number of obs: 382, groups: participant, 27; item, 16 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -1.5286 0.3601 -4.245 2.19e-05 </em></strong></a></li>
<li><a href="mixed-effects-logistic-regression.html#clabel.williams-4.5928-0.8186-5.611-2.02e-08-nptype.pron-0.8047-0.4997-1.610-0.1073-voice.passive-0.9398-0.4722-1.990-0.0466-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-other-readings-appendices-appendix-random-slopes-for-factors-melr-random-slopes-for-factors-generalized-linear-mixed-model-fit-by-maximum-likelihood-laplace-approximation-glmermod-family-binomial-logit-formula-prominence-context-1-context-item-1-context-participant-data-alternatives-control-glmercontroloptimizer-bobyqa-aic-bic-loglik-deviance-df.resid-654.6-721.1--312.3-624.6-607-scaled-residuals-min-1q-median-3q-max--3.5691--0.5550-0.2148-0.5648-2.5891-random-effects-groups-name-variance-std.dev.-corr-participant-intercept-0.6585734-0.81153-context1-0.0917516-0.30291-0.06-context2-0.0169077-0.13003--0.24-0.95-item-intercept-0.6781250-0.82348-context1-0.0008455-0.02908-0.81-context2-0.4283623-0.65449-0.62-0.96-number-of-obs-622-groups-participant-18-item-12-fixed-effects-estimate-std.-error-z-value-prz-intercept-1.2516-0.3652-3.427-0.00061-context1-0.8659-0.1492-5.803-6.5e-09-context2-0.8132-0.2662-3.054-0.00226"><span class="toc-section-number">8.168</span> clabel.williams 4.5928 0.8186 5.611 2.02e-08 <strong><em> ## npType.pron 0.8047 0.4997 1.610 0.1073<br />
## voice.passive 0.9398 0.4722 1.990 0.0466 </em><br />
## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## Other readings ## Appendices ### Appendix: Random slopes for factors {#melr-random-slopes-for-factors} ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: prominence ~ context + (1 + context | item) + (1 + context |<br />
## participant) ## Data: alternatives ## Control: glmerControl(optimizer = “bobyqa”) ## ## AIC BIC logLik deviance df.resid ## 654.6 721.1 -312.3 624.6 607 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.5691 -0.5550 0.2148 0.5648 2.5891 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr<br />
## participant (Intercept) 0.6585734 0.81153<br />
## context1 0.0917516 0.30291 0.06<br />
## context2 0.0169077 0.13003 -0.24 0.95 ## item (Intercept) 0.6781250 0.82348<br />
## context1 0.0008455 0.02908 0.81<br />
## context2 0.4283623 0.65449 0.62 0.96 ## Number of obs: 622, groups: participant, 18; item, 12 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) 1.2516 0.3652 3.427 0.00061 </strong><em> ## context1 0.8659 0.1492 5.803 6.5e-09 </em><strong> ## context2 0.8132 0.2662 3.054 0.00226 </strong></a></li>
<li class="chapter" data-level="8.169" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-363"><i class="fa fa-check"></i><b>8.169</b> —</a></li>
<li class="chapter" data-level="8.170" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-26"><i class="fa fa-check"></i><b>8.170</b> Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1</a></li>
<li class="chapter" data-level="8.171" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-364"><i class="fa fa-check"></i><b>8.171</b> </a></li>
<li class="chapter" data-level="8.172" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#correlation-of-fixed-effects-7"><i class="fa fa-check"></i><b>8.172</b> Correlation of Fixed Effects:</a></li>
<li class="chapter" data-level="8.173" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#intr-cntxt1"><i class="fa fa-check"></i><b>8.173</b> (Intr) cntxt1</a></li>
<li class="chapter" data-level="8.174" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#context1-0.092"><i class="fa fa-check"></i><b>8.174</b> context1 0.092</a></li>
<li class="chapter" data-level="8.175" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#context2-0.566-0.062"><i class="fa fa-check"></i><b>8.175</b> context2 0.566 0.062</a><ul>
<li class="chapter" data-level="8.175.1" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#c7appendix2"><i class="fa fa-check"></i><b>8.175.1</b> Appendix: Multi-level factors and uncorrelated random effects</a></li>
</ul></li>
<li class="chapter" data-level="8.176" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#generalized-linear-mixed-model-fit-by-maximum-likelihood-laplace-1"><i class="fa fa-check"></i><b>8.176</b> Generalized linear mixed model fit by maximum likelihood (Laplace</a></li>
<li class="chapter" data-level="8.177" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#approximation-glmermod-1"><i class="fa fa-check"></i><b>8.177</b> Approximation) [glmerMod]</a></li>
<li class="chapter" data-level="8.178" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#family-binomial-logit-1"><i class="fa fa-check"></i><b>8.178</b> Family: binomial ( logit )</a></li>
<li class="chapter" data-level="8.179" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#formula-shifted-context-1-context1-context2-item-1"><i class="fa fa-check"></i><b>8.179</b> Formula: shifted ~ context + (1 + context1 + context2 || item) + (1 +</a></li>
<li class="chapter" data-level="8.180" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#context1-context2-participant"><i class="fa fa-check"></i><b>8.180</b> context1 + context2 || participant)</a></li>
<li class="chapter" data-level="8.181" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#data-alternatives"><i class="fa fa-check"></i><b>8.181</b> Data: alternatives</a></li>
<li class="chapter" data-level="8.182" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#control-glmercontroloptimizer-bobyqa-1"><i class="fa fa-check"></i><b>8.182</b> Control: glmerControl(optimizer = “bobyqa”)</a></li>
<li class="chapter" data-level="8.183" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-365"><i class="fa fa-check"></i><b>8.183</b> </a></li>
<li class="chapter" data-level="8.184" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#aic-bic-loglik-deviance-df.resid-1"><i class="fa fa-check"></i><b>8.184</b> AIC BIC logLik deviance df.resid</a></li>
<li class="chapter" data-level="8.185" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-366"><i class="fa fa-check"></i><b>8.185</b> 646.8 686.7 -314.4 628.8 613</a></li>
<li class="chapter" data-level="8.186" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-367"><i class="fa fa-check"></i><b>8.186</b> </a></li>
<li class="chapter" data-level="8.187" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#scaled-residuals-8"><i class="fa fa-check"></i><b>8.187</b> Scaled residuals:</a></li>
<li class="chapter" data-level="8.188" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#min-1q-median-3q-max-31"><i class="fa fa-check"></i><b>8.188</b> Min 1Q Median 3Q Max</a></li>
<li class="chapter" data-level="8.189" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-368"><i class="fa fa-check"></i><b>8.189</b> -2.9286 -0.5564 -0.2484 0.5676 3.5763</a></li>
<li class="chapter" data-level="8.190" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-369"><i class="fa fa-check"></i><b>8.190</b> </a></li>
<li class="chapter" data-level="8.191" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#random-effects-9"><i class="fa fa-check"></i><b>8.191</b> Random effects:</a></li>
<li class="chapter" data-level="8.192" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#groups-name-variance-std.dev.-8"><i class="fa fa-check"></i><b>8.192</b> Groups Name Variance Std.Dev.</a></li>
<li class="chapter" data-level="8.193" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant-context2-0.00000-0.0000"><i class="fa fa-check"></i><b>8.193</b> participant context2 0.00000 0.0000</a></li>
<li class="chapter" data-level="8.194" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant.1-context1-0.06545-0.2558"><i class="fa fa-check"></i><b>8.194</b> participant.1 context1 0.06545 0.2558</a></li>
<li class="chapter" data-level="8.195" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#participant.2-intercept-0.67379-0.8208"><i class="fa fa-check"></i><b>8.195</b> participant.2 (Intercept) 0.67379 0.8208</a></li>
<li class="chapter" data-level="8.196" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#item-context2-0.29399-0.5422"><i class="fa fa-check"></i><b>8.196</b> item context2 0.29399 0.5422</a></li>
<li class="chapter" data-level="8.197" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#item.1-context1-0.00000-0.0000"><i class="fa fa-check"></i><b>8.197</b> item.1 context1 0.00000 0.0000</a></li>
<li class="chapter" data-level="8.198" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#item.2-intercept-0.56035-0.7486"><i class="fa fa-check"></i><b>8.198</b> item.2 (Intercept) 0.56035 0.7486</a></li>
<li class="chapter" data-level="8.199" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#number-of-obs-622-groups-participant-18-item-12"><i class="fa fa-check"></i><b>8.199</b> Number of obs: 622, groups: participant, 18; item, 12</a></li>
<li class="chapter" data-level="8.200" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#section-370"><i class="fa fa-check"></i><b>8.200</b> </a></li>
<li class="chapter" data-level="8.201" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#fixed-effects-9"><i class="fa fa-check"></i><b>8.201</b> Fixed effects:</a></li>
<li class="chapter" data-level="8.202" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#estimate-std.-error-z-value-prz-6"><i class="fa fa-check"></i><b>8.202</b> Estimate Std. Error z value Pr(&gt;|z|)</a></li>
<li class="chapter" data-level="8.203" data-path="mixed-effects-logistic-regression.html"><a href="mixed-effects-logistic-regression.html#intercept--1.1533-0.3199--3.605-0.000312-context1--0.8716-0.1375--6.338-2.32e-10"><i class="fa fa-check"></i><b>8.203</b> (Intercept) -1.1533 0.3199 -3.605 0.000312 <strong><em> ## context1 -0.8716 0.1375 -6.338 2.32e-10 </em></strong></a></li>
<li><a href="mixed-effects-logistic-regression.html#context2--0.7014-0.1909--3.673-0.000240-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-cntxt1-context1-0.054-context2-0.129-0.018-data-alternatives-models-alternativesmod2-shifted-context-1-context1-context2-item-1-alternativesmod2-context1-context2-participant-alternativesmod1-prominence-context-1-context-item-1-context-alternativesmod1-participant-df-aic-bic-loglik-deviance-chisq-chi-df-alternativesmod2-9-646.83-686.73--314.42-628.83-alternativesmod1-15-654.56-721.05--312.28-624.56-4.2702-6-prchisq-alternativesmod2-alternativesmod1-0.6402-appendix-what-can-happen-if-a-random-slope-isnt-included-estimate-std.-error-z-value-prz-intercept--1.0110841-0.1644734--6.147402-7.876258e-10-clabel.williams-3.1918034-0.3288389-9.706283-2.834878e-22-nptype.pron-0.6148035-0.2767721-2.221335-2.632827e-02-voice.passive-0.7639485-0.2781885-2.746154-6.029846e-03-estimate-std.-error-z-value-prz-intercept--1.1383258-0.2076053--5.483124-4.178800e-08-clabel.williams-3.7710505-0.5675843-6.644036-3.052075e-11-nptype.pron-0.7917211-0.3987366-1.985574-4.708063e-02-voice.passive-0.6496316-0.4149409-1.565600-1.174422e-01-groups-name-variance-std.dev.-participant-intercept-0.039786-0.19946-item-intercept-0.000000-0.00000-groups-name-variance-std.dev.-participant-voice.passive-1.6482e00-1.2838e00-participant.1-nptype.pron-5.8230e-01-7.6308e-01-participant.2-clabel.williams-5.0132e-15-7.0804e-08-participant.3-intercept-1.6855e-01-4.1054e-01-item-nptype.pron-5.3942e-01-7.3445e-01-item.1-clabel.williams-1.6193e00-1.2725e00-item.2-intercept-2.6237e-14-1.6198e-07-solutions-c7solns-generalized-linear-mixed-model-fit-by-maximum-likelihood-laplace-approximation-glmermod-family-binomial-logit-formula-tapped-speechrate.slow-syntax.trans-1-syntax.trans-speechrate.slow-participant-1-syntax.trans-speechrate.slow-item-data-tapped-aic-bic-loglik-deviance-df.resid-330.0-371.2--156.0-312.0-706-scaled-residuals-min-1q-median-3q-max--2.4530--0.2026--0.0697--0.0302-4.1061-random-effects-groups-name-variance-std.dev.-participant-intercept-2.011e00-1.418e00-participant.1-syntax.trans-0.000e00-0.000e00-participant.2-speechrate.slow-1.272e01-3.566e00-item-intercept-3.174e-01-5.634e-01-item.1-syntax.trans-4.284e-01-6.545e-01-item.2-speechrate.slow-5.115e-10-2.262e-05-number-of-obs-715-groups-participant-23-item-8-fixed-effects-estimate-std.-error-z-value-prz-intercept--4.3843-0.6155--7.123-1.06e-12"><span class="toc-section-number">8.204</span> context2 -0.7014 0.1909 -3.673 0.000240 <strong><em> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Correlation of Fixed Effects: ## (Intr) cntxt1 ## context1 0.054<br />
## context2 0.129 0.018 ## Data: alternatives ## Models: ## alternativesMod2: shifted ~ context + (1 + context1 + context2 || item) + (1 + ## alternativesMod2: context1 + context2 || participant) ## alternativesMod1: prominence ~ context + (1 + context | item) + (1 + context | ## alternativesMod1: participant) ## Df AIC BIC logLik deviance Chisq Chi Df ## alternativesMod2 9 646.83 686.73 -314.42 628.83<br />
## alternativesMod1 15 654.56 721.05 -312.28 624.56 4.2702 6 ## Pr(&gt;Chisq) ## alternativesMod2<br />
## alternativesMod1 0.6402 ### Appendix: What can happen if a random slope isn’t included? ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.0110841 0.1644734 -6.147402 7.876258e-10 ## clabel.williams 3.1918034 0.3288389 9.706283 2.834878e-22 ## npType.pron 0.6148035 0.2767721 2.221335 2.632827e-02 ## voice.passive 0.7639485 0.2781885 2.746154 6.029846e-03 ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.1383258 0.2076053 -5.483124 4.178800e-08 ## clabel.williams 3.7710505 0.5675843 6.644036 3.052075e-11 ## npType.pron 0.7917211 0.3987366 1.985574 4.708063e-02 ## voice.passive 0.6496316 0.4149409 1.565600 1.174422e-01 ## Groups Name Variance Std.Dev. ## participant (Intercept) 0.039786 0.19946 ## item (Intercept) 0.000000 0.00000 ## Groups Name Variance Std.Dev.<br />
## participant voice.passive 1.6482e+00 1.2838e+00 ## participant.1 npType.pron 5.8230e-01 7.6308e-01 ## participant.2 clabel.williams 5.0132e-15 7.0804e-08 ## participant.3 (Intercept) 1.6855e-01 4.1054e-01 ## item npType.pron 5.3942e-01 7.3445e-01 ## item.1 clabel.williams 1.6193e+00 1.2725e+00 ## item.2 (Intercept) 2.6237e-14 1.6198e-07 ## Solutions {#c7solns} ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: binomial ( logit ) ## Formula: tapped ~ speechrate.slow + syntax.trans + (1 + syntax.trans +<br />
## speechrate.slow || participant) + (1 + syntax.trans + speechrate.slow ||<br />
## item) ## Data: tapped ## ## AIC BIC logLik deviance df.resid ## 330.0 371.2 -156.0 312.0 706 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.4530 -0.2026 -0.0697 -0.0302 4.1061 ## ## Random effects: ## Groups Name Variance Std.Dev. ## participant (Intercept) 2.011e+00 1.418e+00 ## participant.1 syntax.trans 0.000e+00 0.000e+00 ## participant.2 speechrate.slow 1.272e+01 3.566e+00 ## item (Intercept) 3.174e-01 5.634e-01 ## item.1 syntax.trans 4.284e-01 6.545e-01 ## item.2 speechrate.slow 5.115e-10 2.262e-05 ## Number of obs: 715, groups: participant, 23; item, 8 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|)<br />
## (Intercept) -4.3843 0.6155 -7.123 1.06e-12 </em></strong></a></li>
<li><a href="mixed-effects-logistic-regression.html#speechrate.slow--4.0897-1.0355--3.950-7.83e-05-syntax.trans-1.0909-0.4209-2.592-0.00955-signif.-codes-0-0.001-0.01-0.05-.-0.1-1-correlation-of-fixed-effects-intr-spchr.-spechrt.slw-0.419-syntax.trns--0.156--0.068"><span class="toc-section-number">8.205</span> speechrate.slow -4.0897 1.0355 -3.950 7.83e-05 *<strong> ## syntax.trans 1.0909 0.4209 2.592 0.00955 </strong> ## — ## Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ‘’ 1 ## ## Correlation of Fixed Effects: ## (Intr) spchr. ## spechrt.slw 0.419<br />
## syntax.trns -0.156 -0.068</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><i class="fa fa-check"></i><b>9</b> Practical regression topics 2: Ordered factors, nonlinear effects, model predictions, post-hoc tests</a><ul>
<li class="chapter" data-level="9.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#introduction-1"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#ordered-factors"><i class="fa fa-check"></i><b>9.2</b> Ordered factors</a><ul>
<li class="chapter" data-level="9.2.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#orthogonal-polynomial-contrasts"><i class="fa fa-check"></i><b>9.2.1</b> Orthogonal polynomial contrasts</a></li>
<li class="chapter" data-level="9.2.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#using-an-ordered-factor-as-a-predictor"><i class="fa fa-check"></i><b>9.2.2</b> Using an ordered factor as a predictor</a></li>
<li class="chapter" data-level="9.2.3" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#further-points"><i class="fa fa-check"></i><b>9.2.3</b> Further points</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#nonlinear-effects"><i class="fa fa-check"></i><b>9.3</b> Nonlinear effects</a><ul>
<li class="chapter" data-level="9.3.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#splines-definition-and-benefits"><i class="fa fa-check"></i><b>9.3.1</b> Splines: Definition and benefits</a></li>
<li class="chapter" data-level="9.3.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#restricted-cubic-splines"><i class="fa fa-check"></i><b>9.3.2</b> Restricted cubic splines</a></li>
<li class="chapter" data-level="9.3.3" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#choosing-spline-complexity"><i class="fa fa-check"></i><b>9.3.3</b> Choosing spline complexity</a></li>
<li class="chapter" data-level="9.3.4" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#rcs-components"><i class="fa fa-check"></i><b>9.3.4</b> RCS components</a></li>
<li class="chapter" data-level="9.3.5" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#using-rcs-in-a-mixed-model"><i class="fa fa-check"></i><b>9.3.5</b> Using RCS in a mixed model</a></li>
<li class="chapter" data-level="9.3.6" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#random-slopes-for-rcs-terms"><i class="fa fa-check"></i><b>9.3.6</b> Random slopes for RCS terms</a></li>
<li class="chapter" data-level="9.3.7" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#nonlinear-effects-summary"><i class="fa fa-check"></i><b>9.3.7</b> Nonlinear effects: Summary</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#predictions-from-mixed-models"><i class="fa fa-check"></i><b>9.4</b> Predictions from mixed models</a><ul>
<li class="chapter" data-level="9.4.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#making-model-predictions"><i class="fa fa-check"></i><b>9.4.1</b> Making Model Predictions</a></li>
<li class="chapter" data-level="9.4.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#simulation-based-predictions"><i class="fa fa-check"></i><b>9.4.2</b> Simulation-based predictions</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#post-hoc-mult-comp"><i class="fa fa-check"></i><b>9.5</b> Post-hoc tests and multiple comparisons</a></li>
<li class="chapter" data-level="9.6" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8indivpreds"><i class="fa fa-check"></i><b>9.6</b> Appendix: Model predictions for indiviudal participants</a><ul>
<li class="chapter" data-level="9.6.1" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#predictions-incorporating-offsets-for-individual-speakers"><i class="fa fa-check"></i><b>9.6.1</b> Predictions incorporating offsets for individual speakers</a></li>
<li class="chapter" data-level="9.6.2" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#predicted-williams-effect-for-each-speaker"><i class="fa fa-check"></i><b>9.6.2</b> Predicted Williams effect for each speaker</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8slopesForFactors"><i class="fa fa-check"></i><b>9.7</b> Appendix: Random slopes for factors</a></li>
<li class="chapter" data-level="9.8" data-path="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html"><a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8solns"><i class="fa fa-check"></i><b>9.8</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="datasets-appendix.html"><a href="datasets-appendix.html"><i class="fa fa-check"></i><b>10</b> Appendix: Datasets and packages</a><ul>
<li class="chapter" data-level="10.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#engdata"><i class="fa fa-check"></i><b>10.1</b> <code>english</code> lexical decision and naming latencies</a></li>
<li class="chapter" data-level="10.2" data-path="datasets-appendix.html"><a href="datasets-appendix.html#dutch-regularity"><i class="fa fa-check"></i><b>10.2</b> Dutch <code id="dregdata">regularity</code></a></li>
<li class="chapter" data-level="10.3" data-path="datasets-appendix.html"><a href="datasets-appendix.html#european-french-phrase-medial-vowel-devoicing"><i class="fa fa-check"></i><b>10.3</b> European French phrase-medial vowel <code id="devdata">devoicing</code></a><ul>
<li class="chapter" data-level="10.3.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background"><i class="fa fa-check"></i><b>10.3.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="datasets-appendix.html"><a href="datasets-appendix.html#north-american-english-tapping"><i class="fa fa-check"></i><b>10.4</b> North American English <code id="tapdata">tapping</code></a><ul>
<li class="chapter" data-level="10.4.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-1"><i class="fa fa-check"></i><b>10.4.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="datasets-appendix.html"><a href="datasets-appendix.html#halfdata"><i class="fa fa-check"></i><b>10.5</b> <code>halfrhyme</code>: English half-rhymes</a></li>
<li class="chapter" data-level="10.6" data-path="datasets-appendix.html"><a href="datasets-appendix.html#givedata"><i class="fa fa-check"></i><b>10.6</b> <code>givenness</code> data: the Williams Effect</a><ul>
<li class="chapter" data-level="10.6.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-2"><i class="fa fa-check"></i><b>10.6.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="datasets-appendix.html"><a href="datasets-appendix.html#alternatives"><i class="fa fa-check"></i><b>10.7</b> <code id="altdata">alternatives</code></a><ul>
<li class="chapter" data-level="10.7.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-3"><i class="fa fa-check"></i><b>10.7.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="datasets-appendix.html"><a href="datasets-appendix.html#votdata"><i class="fa fa-check"></i><b>10.8</b> VOT</a><ul>
<li class="chapter" data-level="10.8.1" data-path="datasets-appendix.html"><a href="datasets-appendix.html#background-4"><i class="fa fa-check"></i><b>10.8.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="datasets-appendix.html"><a href="datasets-appendix.html#transitionsdata"><i class="fa fa-check"></i><b>10.9</b> Transitions</a></li>
<li class="chapter" data-level="10.10" data-path="datasets-appendix.html"><a href="datasets-appendix.html#packages"><i class="fa fa-check"></i><b>10.10</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Quantitative Methods for Linguistic Data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Practical regression topics 2: Ordered factors, nonlinear effects, model predictions, post-hoc tests</h1>
<p><strong>Preliminary code</strong></p>
<p>This code is needed to make other code below work:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gridExtra) <span class="co"># for grid.arrange() to print plots side-by-side</span>
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(languageR)
<span class="kw">library</span>(scales)
<span class="kw">library</span>(rms)
<span class="kw">library</span>(arm)
<span class="kw">library</span>(lsmeans)


## loads votMcGillLing620.csv from OSF project for Sonderegger et al. (2017) data
vot &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="kw">url</span>(<span class="st">&quot;https://osf.io/qpab9/download&quot;</span>))

## loads halfrhymeMcGillLing620.csv from OSF project for Harder (2013) data
halfrhyme &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="kw">url</span>(<span class="st">&quot;https://osf.io/37uqt/download&quot;</span>))

## loads alternativesMcGillLing620.csv from OSF project for Wagner (2016) data
alternatives &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="kw">url</span>(<span class="st">&quot;https://osf.io/6qctp/download&quot;</span>))

## remove rows where response is NA (shouldn&#39;t be any...)
alternatives &lt;-<span class="st"> </span><span class="kw">filter</span>(alternatives, !<span class="kw">is.na</span>(prominence))

## add the &#39;shifted&#39; numeric variable
alternatives &lt;-<span class="st"> </span>alternatives %&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">shifted =</span> -<span class="dv">1</span>*<span class="kw">as.numeric</span>(prominence)+<span class="dv">2</span>)

## relevel context to be in the intuitively plausible order
alternatives &lt;-<span class="st"> </span><span class="kw">mutate</span>(alternatives, <span class="dt">context=</span><span class="kw">as.ordered</span>(<span class="kw">factor</span>(context, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;Alternative&quot;</span>, <span class="st">&quot;NoAlternative&quot;</span>, <span class="st">&quot;New&quot;</span>))))

## regularity dataset: 
## order levels for Auxiliary in their natural order
regularity$Auxiliary &lt;-<span class="st"> </span><span class="kw">factor</span>(regularity$Auxiliary, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;hebben&quot;</span>, <span class="st">&quot;zijnheb&quot;</span>, <span class="st">&quot;zijn&quot;</span>))

## loads givennessMcGillLing620.csv from OSF project for Wagner (2012) data
givenness &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="kw">url</span>(<span class="st">&quot;https://osf.io/q9e3a/download&quot;</span>))

givenness &lt;-<span class="st"> </span><span class="kw">mutate</span>(givenness,
                    <span class="dt">conditionLabel.williams =</span> arm::<span class="kw">rescale</span>(conditionLabel),
                    <span class="dt">clabel.williams =</span> arm::<span class="kw">rescale</span>(conditionLabel),
                    <span class="dt">npType.pronoun =</span> arm::<span class="kw">rescale</span>(npType),
                    <span class="dt">npType.pron =</span> arm::<span class="kw">rescale</span>(npType),
                    <span class="dt">voice.passive =</span> arm::<span class="kw">rescale</span>(voice),
                    <span class="dt">order.std =</span> arm::<span class="kw">rescale</span>(order),
                    <span class="dt">stressshift.num =</span> (<span class="kw">as.numeric</span>(stressshift) -<span class="st"> </span><span class="dv">1</span>)
)</code></pre></div>
<script src="js/hideOutput.js"></script>
<p><strong>Note</strong>: Answers to some questions/exercises not listed in text are in <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8solns">Solutions</a></p>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">9.1</span> Introduction</h2>
<p>These notes cover several practical topics which come up in fitting regression models (mixed-effects or not):</p>
<ul>
<li><p>Ordered factors</p></li>
<li><p>Nonlinear effects</p></li>
<li><p>Making model predictions</p></li>
</ul>
<p>We also briefly discuss:</p>
<ul>
<li><p>Post-hoc tests</p></li>
<li><p>Multiple comparisons</p></li>
</ul>
<!-- TODO FUTURE: flesh out last two topics -->
</div>
<div id="ordered-factors" class="section level2">
<h2><span class="header-section-number">9.2</span> Ordered factors</h2>
<p>So far we have considered two types of variables as predictors in regression models.</p>
<p>First: <strong>numeric</strong> variables, which are continuous and <em>ordered</em>, meaning that there are “larger” and “smaller” values of the variable. When a numeric variable <span class="math inline">\(X\)</span> is used as a predictor in a regression model, it is assumed that a unit change always has the same effect on the response <span class="math inline">\(Y\)</span> (the “slope”): increasing <span class="math inline">\(X\)</span> from 1 to 2 has the same effect on <span class="math inline">\(Y\)</span> as increasing <span class="math inline">\(X\)</span> from 3 to 4.</p>
<p>Second: <strong>factors</strong>, which are discrete and unordered: no level of a factor is “larger” than other levels.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> When a factor is used as a predictor in a regression model, it is not assumed that changing from level 1 to level 2 has the same effect on the response as changing from level 2 to level 3.</p>
<p><strong>Ordered factors</strong> lie in between these two types of variables. They are discrete, like factors, but ordered, like continuous variables. It is assumed that level 1 is conceptually “less than” level 2, and so on (like a continuous variable), but it is not assumed that level 1 <span class="math inline">\(\to\)</span> 2 has the same effect as level 2 <span class="math inline">\(\to\)</span> 3 (like a factor). Ordered factors are often used for variables where the levels can be thought of as lying on a scale, and take on few values (~3–6).</p>
<div id="c8ex1" class="section level4 unnumbered">
<h4>Example 1</h4>
<p>Consider the <a href="datasets-appendix.html#dregdata">Dutch verb regularity dataset</a>, <code>regularity</code>.</p>
<ul>
<li><p>The <strong>response</strong> variable is <code>Regularity</code>: whether the verb has a regular or irregular past tense (1/0)</p></li>
<li><p>The <strong>predictor</strong> of interest is <code>Auxiliary</code>: which auxiliary a verb takes (<em>hebben</em>, <em>zijnheb</em>, or <em>zijn</em>)</p>
<ul>
<li>These levels have a natural order: <em>zijnheb</em> lies between the other two (because it means “this verb can take either <em>zijn</em> or <em>hebben</em> as an auxiliary.”)</li>
</ul></li>
</ul>
<p>Thus, we convert <code>Auxiliary</code> to an ordered factor:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## make ordered factor for auxiliary
regularity$Auxiliary.ord &lt;-<span class="st"> </span><span class="kw">as.ordered</span>(regularity$Auxiliary)
<span class="kw">head</span>(regularity$Auxiliary.ord)</code></pre></div>
<pre><code>## [1] hebben  zijnheb zijn    hebben  hebben  hebben 
## Levels: hebben &lt; zijnheb &lt; zijn</code></pre>
<p>Note that the R output shows this is an ordered factor by showing the ordering of levels with &lt;. Compare to the R output for an unordered factor:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(regularity$Auxiliary)</code></pre></div>
<pre><code>## [1] hebben  zijnheb zijn    hebben  hebben  hebben 
## Levels: hebben zijnheb zijn</code></pre>
</div>
<div id="orthogonal-polynomial-contrasts" class="section level3">
<h3><span class="header-section-number">9.2.1</span> Orthogonal polynomial contrasts</h3>
<p>What “converting to an ordered factor” (the <code>as.ordered</code> command) actually means is using a particular contrast coding scheme (See Sec. <a href="#contrast-coding-schemes"><strong>??</strong></a> for details): <em>orthogonal polynomial contrasts</em>. For three levels, the contrasts are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">contrasts</span>(regularity$Auxiliary.ord), <span class="dv">3</span>)</code></pre></div>
<pre><code>##          .L     .Q
## [1,] -0.707  0.408
## [2,]  0.000 -0.816
## [3,]  0.707  0.408</code></pre>
<p>The two contrasts correspond to “linear” and “quadratic” <em>trends</em> (<code>.L</code> and <code>.Q</code> columns), which represent different kinds of relationship between the factor and the response, <strong>if</strong> the levels were treated as equally-spaced (and continuous):</p>
<ul>
<li><p>Linear: how much does relationship with response look like a line?</p></li>
<li><p>Quadratic: how much does relationship with the response look like a parabola?</p></li>
</ul>
<p>The contrasts for <span class="math inline">\(k=3\)</span> can be visualized as:</p>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-5-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>For ordered factors with more levels, further contrasts correspond to a cubic trend, and so on. For a four-level ordered factor:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">contr.poly</span>(<span class="dv">4</span>)</code></pre></div>
<pre><code>##              .L   .Q         .C
## [1,] -0.6708204  0.5 -0.2236068
## [2,] -0.2236068 -0.5  0.6708204
## [3,]  0.2236068 -0.5 -0.6708204
## [4,]  0.6708204  0.5  0.2236068</code></pre>
<p>the three contrasts capture:</p>
<ul>
<li><p>L: how much does relationship with response look like a line?</p></li>
<li><p>Q: `` `` a parabola?</p></li>
<li><p>C: `` `` a cubic function?</p></li>
</ul>
<p>Visually, the contrasts for four levels (<span class="math inline">\(k=4\)</span>) are: <img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>where axes have been removed for clarity.</p>
</div>
<div id="using-an-ordered-factor-as-a-predictor" class="section level3">
<h3><span class="header-section-number">9.2.2</span> Using an ordered factor as a predictor</h3>
<p>For <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8ex1">our example</a>, we predict <code>Regularity</code> as a function of the verb’s auxiliary (<code>Auxiliary.ord</code>) using a logistic regression:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">regularity.mod<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(Regularity ~<span class="st"> </span>Auxiliary.ord, <span class="dt">data=</span>regularity, <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)
<span class="kw">summary</span>(regularity.mod<span class="fl">.1</span>)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Regularity ~ Auxiliary.ord, family = &quot;binomial&quot;, 
##     data = regularity)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.8307   0.6438   0.6438   0.6438   1.3537  
## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      0.51944    0.17029   3.050  0.00229 ** 
## Auxiliary.ord.L -1.32507    0.33145  -3.998 6.39e-05 ***
## Auxiliary.ord.Q  0.02954    0.25324   0.117  0.90713    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 750.12  on 699  degrees of freedom
## Residual deviance: 719.92  on 697  degrees of freedom
## AIC: 725.92
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>The linear trend has large effect size and is very significant (<span class="math inline">\(p&lt;0.0001\)</span>), while the quadratic trend has low effect size and is not significant (<span class="math inline">\(p=0.91\)</span>). This means the model predicts an essentially linear relationship between <code>Auxiliary.ord</code> and <code>Regularity</code>.</p>
<p>This example illustrates one use for ordered factors—dimensionality reduction, by reducing the number of contrasts needed to represent a factor’s effect. If we wanted to simplify the model, it would be justified at this point to drop the quadratic trend, and just use the linear contrast to represent the effect of <code>Auxiliary.ord</code>.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> We wouldn’t gain much by doing so here (just one fewer regression coefficient), but when dealing with ordered factors with 5+ levels, dimensionality reduction can make model fitting and interpretation much easier.</p>
<!-- Note that the ordered -->
<!-- * More specific information than "significant effect of `Auxiliary`" -->
<!--     * Result of model comparison, dropping `Auxiliary.ord`: $p < 0.0001$ -->
<!-- ---  -->
<p>To visualize the predicted relationship between auxiliary and regularity probability (in log-odds and probability space):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## set up a dataframe which varies in Auxiliary.ord:
newdata &lt;-<span class="st"> </span><span class="kw">with</span>(regularity, <span class="kw">data.frame</span>(<span class="dt">Auxiliary.ord =</span> <span class="kw">unique</span>(Auxiliary.ord)))

## predictions at each level of Auxiliary.ord (in log-odds)
newdata$pred &lt;-<span class="st"> </span><span class="kw">predict</span>(regularity.mod<span class="fl">.1</span>, <span class="dt">newdata=</span>newdata)

## predictions in probability 
newdata$pred.p &lt;-<span class="st"> </span><span class="kw">invlogit</span>(newdata$pred)

regularityPlot1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Auxiliary.ord, <span class="dt">y=</span>pred), <span class="dt">data=</span>newdata) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Auxiliary (log-odds)&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Predicted % regular (logit)&quot;</span>)

regularityPlot2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Auxiliary.ord, <span class="dt">y=</span>pred.p), <span class="dt">data=</span>newdata) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Auxiliary (probability)&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Predicted % regular&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels=</span>percent)

<span class="kw">grid.arrange</span>(regularityPlot1, regularityPlot2, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The predicted trend is “linear” in the sense that the three points lie on a line. This replicates the pattern in the empirical data (in log-odds):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">summDf &lt;-<span class="st"> </span>regularity %&gt;%<span class="st"> </span><span class="kw">group_by</span>(Auxiliary) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">mean=</span><span class="kw">logit</span>(<span class="kw">mean</span>(Regularity==<span class="st">&#39;regular&#39;</span>)))

<span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Auxiliary,<span class="dt">y=</span>mean), <span class="dt">data=</span>summDf) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;log-odds (Regularity==regular)&quot;</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-10-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
<div id="further-points" class="section level3">
<h3><span class="header-section-number">9.2.3</span> Further points</h3>
<p>Some other variables that could be represented by ordered factors:</p>
<ul>
<li><p>Number of onset consonants in a syllable (Ex: <em>1</em> &lt; <em>2</em> &lt; <em>3</em>)</p></li>
<li><p>Socio-economic status (SES) (Ex: <em>low</em> &lt; <em>low/mid</em> &lt; <em>high/mid</em> &lt; <em>high</em>)</p></li>
<li><p>Strength of prosodic boundary (<em>word</em> &lt; <em>small phrase</em> &lt; <em>large phrase</em> &lt; <em>utterance</em>)</p></li>
<li><p>L2 level (<em>no knowledge</em> &lt; <em>beginner</em> &lt; <em>intermediate</em> &lt; <em>advanced</em>)</p></li>
</ul>
<p>Note that ordered factors are just factors with a particular (sensible) contrast coding scheme. A model where a conceptually “ordered” variable is entered as a non-ordered factor is not incorrect, the results just may be harder to interpret.</p>
<p>When using ordered factors in a mixed-effects model: because ordered factors are still factors, the issues with including factors in a mixed model discussed in Section <a href="#c6factorsissue"><strong>??</strong></a> arise. These issues (frequently overparametrized models, uncorrelated random effects) and solutions are very similar for ordered factors, and are discussed in an Appendix (Sec. <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8slopesForFactors">9.7</a>).</p>
<div id="example-2-1" class="section level4 unnumbered">
<h4>Example 2</h4>
<!-- (LING 620: this can be skipped.) -->
<p>For <a href="datasets-appendix.html#altdata">the <code>alternatives</code> data</a>, we model the probability of stress shifting (<code>shifted</code>) in a mixed-effects logistic regression, with:</p>
<ul>
<li><p>Fixed effect: <code>context</code></p></li>
<li><p>Random effects: by-item and by-participant intercept and slope</p></li>
</ul>
<p>This predictor is conceptually ordered, with levels <em>Alternative</em> &lt; <em>NoAlternative</em> &lt; <em>New</em> (see <a href="datasets-appendix.html#altdata">the dataset description</a> to understand why). So we can convert it to an ordered factor:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alternatives &lt;-<span class="st"> </span><span class="kw">mutate</span>(alternatives, <span class="dt">context=</span><span class="kw">as.ordered</span>(<span class="kw">factor</span>(context, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;Alternative&quot;</span>, <span class="st">&quot;NoAlternative&quot;</span>, <span class="st">&quot;New&quot;</span>))))</code></pre></div>
<p>It turns out (see Section <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8slopesForFactors">9.7</a>) that this model gives perfect random-effect correlations if the random effect structure <code>(1+context|participant) + (1|context|item)</code> is used, so we instead use uncorrelated random effects. To do so, we first convert <code>context</code> to two numeric contrasts, which correspond to the linear and quadratic trends:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alternatives &lt;-<span class="st"> </span><span class="kw">mutate</span>(alternatives, 
                       <span class="dt">contextL =</span> <span class="kw">model.matrix</span>(~context, alternatives)[,<span class="dv">2</span>],
                       <span class="dt">contextQ =</span> <span class="kw">model.matrix</span>(~context, alternatives)[,<span class="dv">3</span>])</code></pre></div>
<p>To fit and summarize the model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alternativesMod2 &lt;-<span class="st"> </span><span class="kw">glmer</span>(shifted ~<span class="st"> </span>context +<span class="st"> </span>
<span class="st">                            </span>(<span class="dv">1</span>+contextL +<span class="st"> </span>contextQ||item) +<span class="st"> </span>
<span class="st">                            </span>(<span class="dv">1</span>+contextL +<span class="st"> </span>contextQ||participant), 
                          <span class="dt">data=</span>alternatives, 
                          <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>, 
                          <span class="dt">control=</span><span class="kw">glmerControl</span>(<span class="dt">optimizer =</span> <span class="st">&quot;bobyqa&quot;</span>)) 

<span class="kw">summary</span>(alternativesMod2)</code></pre></div>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: shifted ~ context + (1 + contextL + contextQ || item) + (1 +  
##     contextL + contextQ || participant)
##    Data: alternatives
## Control: glmerControl(optimizer = &quot;bobyqa&quot;)
## 
##      AIC      BIC   logLik deviance df.resid 
##    652.4    692.3   -317.2    634.4      613 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.8990 -0.5248 -0.2875  0.5782  3.5101 
## 
## Random effects:
##  Groups        Name        Variance  Std.Dev. 
##  participant   contextQ    2.272e-15 4.766e-08
##  participant.1 contextL    2.174e-01 4.663e-01
##  participant.2 (Intercept) 6.526e-01 8.078e-01
##  item          contextQ    1.723e-01 4.151e-01
##  item.1        contextL    9.398e-01 9.694e-01
##  item.2        (Intercept) 4.925e-01 7.018e-01
## Number of obs: 622, groups:  participant, 18; item, 12
## 
## Fixed effects:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -1.0609     0.3040  -3.490 0.000483 ***
## context.L    -1.9482     0.3748  -5.198 2.01e-07 ***
## context.Q     0.2936     0.2196   1.337 0.181273    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##           (Intr) cntx.L
## context.L 0.103        
## context.Q 0.048  0.108</code></pre>
<blockquote>
<p><strong>Questions</strong>:</p>
<p>What does the model predict about:</p>
<ul>
<li><p>The overall effect of <code>context</code>? (What kind of relationship with log-odds of stress shift?)</p></li>
<li><p>By-participant and by-item variability in the <code>context</code> effect?</p></li>
</ul>
</blockquote>
<p>Comparing the predicted overall effect (for an “average” participant/item) to the empirical means (probability of stress shift for each <code>context</code> value):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## get model predictions at each level of &#39;context&#39;
newdata &lt;-<span class="st"> </span><span class="kw">with</span>(alternatives, <span class="kw">data.frame</span>(<span class="dt">context =</span> <span class="kw">unique</span>(context)))

## re.form = NA : get predictions at &quot;average&quot; speaker and item values
newdata$pred &lt;-<span class="st"> </span><span class="kw">invlogit</span>(<span class="kw">predict</span>(alternativesMod2, <span class="dt">newdata=</span>newdata, <span class="dt">re.form=</span><span class="ot">NA</span>))
summDf2 &lt;-<span class="st"> </span>alternatives %&gt;%<span class="st"> </span><span class="kw">group_by</span>(context) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">pred=</span><span class="kw">mean</span>(shifted))
predEmpDf &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">data.frame</span>(newdata, <span class="dt">type=</span><span class="st">&#39;Predicted&#39;</span>), 
                   <span class="kw">data.frame</span>(summDf2, <span class="dt">type=</span><span class="st">&#39;Empirical&#39;</span>))

<span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>context, <span class="dt">y=</span>pred), <span class="dt">data=</span>predEmpDf) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color=</span>type),<span class="dt">size=</span><span class="dv">3</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Context&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Percent shifted stress&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept=</span><span class="dv">0</span>), <span class="dt">lty=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept=</span><span class="dv">1</span>), <span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-14-1.png" width="480" style="display: block; margin: auto;" /> The model’s prediction (significant linear trend but not quadratic trend) makes sense. The relationship is basically linear—and would look more so in log-odds space.</p>
<p>Interestingly, the empirical data shows substantial variability among participants and items, many of which do not show a linear trend:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alternatives %&gt;%<span class="st"> </span><span class="kw">group_by</span>(context, participant) %&gt;%
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean=</span><span class="kw">mean</span>(shifted)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>context,<span class="dt">y=</span>mean)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Percent shifted (by partic)&quot;</span>) +
<span class="st">  </span><span class="kw">facet_wrap</span>(~participant) +<span class="st"> </span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels=</span>percent, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alternatives %&gt;%<span class="st"> </span><span class="kw">group_by</span>(context, item) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">mean=</span><span class="kw">mean</span>(shifted)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>context,<span class="dt">y=</span>mean)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Percent shifted (by item)&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">facet_wrap</span>(~item) +<span class="st">  </span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels=</span>percent, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-16-1.png" width="672" style="display: block; margin: auto;" /></p>
<blockquote>
<p><strong>Questions</strong>:</p>
<ul>
<li><p>What kind of variability is observed, among participants and among items? (In overall probability of stress shifting? In the <code>condition</code> effect?)</p></li>
<li><p>How do the by-participant and by-item random effect estimates of the model reflect these patterns of variability?</p></li>
</ul>
</blockquote>
<!-- --- -->
<!-- ((Q4M: I couldn't find the original code, but going through the slides it appears that I was able to rebuild it)) -->
<!-- ```{r, echo=F} -->
<!-- halfrhyme <- mutate(halfrhyme, -->
<!--                     conditionLabel =  -->
<!--                       factor(conditionLabel, levels = c("bad", "voice", "good"))) -->
<!-- halfrhyme$conditionLabel <- as.ordered(halfrhyme$conditionLabel) -->
<!-- halfrhyme$clabel.c1 <- model.matrix(~conditionLabel, halfrhyme)[,2] -->
<!-- halfrhyme$clabel.c2 <- model.matrix(~conditionLabel, halfrhyme)[,3] -->
<!-- ``` -->
<!-- ```{r} -->
<!-- summary(lmer(rhymeRating ~ conditionLabel +  -->
<!--                (1|participant) +  -->
<!--                (0+clabel.c1|participant) +  -->
<!--                (0+clabel.c2|participant),  -->
<!--              data=halfrhyme)) -->
<!-- ``` -->
<!-- * $\implies$ significant, **positive** lienar and quadratic trends -->
<!--     * Mostly linear (why?) -->
</div>
</div>
</div>
<div id="nonlinear-effects" class="section level2">
<h2><span class="header-section-number">9.3</span> Nonlinear effects</h2>
<p>So far we have always assumed that continuous variables have a relationship with the response that is <em>linear</em>—well-described by a straight line. In reality this is often not the case.</p>
<p>For example, consider the effect of word frequency (<code>WrittenFrequency</code>) on lexical decision reaction time (<code>RTlexdec</code>) in <a href="datasets-appendix.html#engdata">the <code>english</code> dataset</a>. Plotting this relationship using a nonlinear smoother:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>WrittenFrequency, <span class="dt">y=</span>RTlexdec), <span class="dt">data=</span>english) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_smooth</span>() +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.15</span>, <span class="dt">size=</span><span class="dv">1</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-17-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>it is clear the relationship is not linear. Certainly RT decreases as a function of frequency, but the relationship is not a straight line. We would like to model this kind of relationship in a regression model.</p>
<p>There are several options for modeling such <em>nonlinear functions</em>, including:</p>
<ul>
<li><p><em>Polynomials</em>, such as a parabola or cubic equation. These are fitted in R by including terms like <code>poly(x,2)</code> in a model (for a quadratic equation).</p></li>
<li><p><em>Natural cubic splines</em>, which you fit in R using <code>ns()</code> (e.g. <code>ns(x,3)</code> for a spline with one “bend”)</p></li>
</ul>
<p>We will use a related family of functions: <em>restricted cubic splines</em> (RCS), which are fitted using the <code>rcs</code> function in the <code>rms</code> package. Some discussion of RCS is given by <span class="citation">Baayen (<a href="#ref-baayen2008analyzing">2008</a>)</span>, and more technical discussion by <span class="citation">Harrell (<a href="#ref-harrell2001regression">2001</a>)</span>.</p>
<div id="splines-definition-and-benefits" class="section level3">
<h3><span class="header-section-number">9.3.1</span> Splines: Definition and benefits</h3>
<p>While polynomials are probably familiar to you (from high school math: lines, parabolas, etc.) splines are probably not. What are splines, and why should we use them instead of polynomial functions—which are easier to understand?</p>
<p>Intuitively a spline is a function made up of several polynomials glued together (“piecewise-defined”), constrained to be “smooth” at the places where the polynomial pieces connect (called <em>knots</em>). The glued-together polynomials can be small pieces of parabolas, lines, and so on.</p>
<p>Splines are like polynomials, but better behaved: they avoid interpolation errors and <a href="https://en.wikipedia.org/wiki/Runge%27s_phenomenon">Runge’s phenomenon</a>. They are better than polynomials especially at the very high and low values of a variable being modeled: polynomials tend to “blow up” when extrapolated beyond the range of the variable in the data, while splines can be constrained to grow only linearly.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<p>A polynomial is made up of <em>components</em> for different orders: you add together multiples of <span class="math inline">\(1\)</span>, <span class="math inline">\(x\)</span>, <span class="math inline">\(x^2\)</span>, and so on to approximate a function. Splines also approximate functions, but using a different (and more complex) set of components. There are many ways of defining splines (hence <code>bs</code>, <code>ns</code>, <code>rcs</code>, and other R functions), of which we consider only RCS.</p>
</div>
<div id="restricted-cubic-splines" class="section level3">
<h3><span class="header-section-number">9.3.2</span> Restricted cubic splines</h3>
<p>Intuitively, a restricted cubic spline with <span class="math inline">\(k\)</span> <em>knots</em> describes a curve with <span class="math inline">\(k-2\)</span> “bends”. Thus, the simplest possible RCS has three knots, and describes a curve with one bend (analogous to a quadratic polynomial). An RCS term for a variable <code>x</code> is be added to a regression model in R using the notation <code>rcs(x,k)</code>. For example, here we fit three models of reaction time as a function of word frequency, using progressively more complex splines (<span class="math inline">\(k= 3, 5, 7\)</span>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.rcs3 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">3</span>), <span class="dt">data=</span>english)
mod.rcs5 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">5</span>), <span class="dt">data=</span>english)
mod.rcs7 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">7</span>), <span class="dt">data=</span>english)</code></pre></div>
<p>The predictions of these models are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">english$pred.rcs3 &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.rcs3)
english$pred.rcs5 &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.rcs5)
english$pred.rcs7 &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.rcs7)

rcs3PredPlot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>WrittenFrequency, <span class="dt">y=</span>pred.rcs3), <span class="dt">data=</span>english) +
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size=</span><span class="dv">1</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;RT (predicted)&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Written Frequency</span><span class="ch">\n\n</span><span class="st">Oversmooths&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;k = 3&quot;</span>) +
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="fl">0.5</span>))

rcs5PredPlot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>WrittenFrequency, <span class="dt">y=</span>pred.rcs5), <span class="dt">data=</span>english) +
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size=</span><span class="dv">1</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;RT (predicted)&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Written Frequency</span><span class="ch">\n\n</span><span class="st">&quot;</span>) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;k = 5&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="fl">0.5</span>))

rcs7PredPlot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>WrittenFrequency, <span class="dt">y=</span>pred.rcs7), <span class="dt">data=</span>english) +
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size=</span><span class="dv">1</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;RT (predicted)&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Written Frequency</span><span class="ch">\n\n</span><span class="st">Overfits&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;k = 7&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="fl">0.5</span>))

<span class="kw">grid.arrange</span>(rcs3PredPlot, rcs5PredPlot, rcs7PredPlot, <span class="dt">ncol =</span> <span class="dv">3</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-19-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Comparing to the plot of the empirical data above, we can see visually that <span class="math inline">\(k=3\)</span> is not complex enough (“underfits”) and <span class="math inline">\(k=7\)</span> is too complex (“overfits”).</p>
</div>
<div id="choosing-spline-complexity" class="section level3">
<h3><span class="header-section-number">9.3.3</span> Choosing spline complexity</h3>
<p>This example leads to the question: how to decide on a value of <span class="math inline">\(k\)</span> to model a nonlinear effect, and whether a nonlinear effect is justified at all?</p>
<div id="method-1-visual-inspection" class="section level4">
<h4><span class="header-section-number">9.3.3.1</span> Method 1: Visual inspection</h4>
<p>Make a plot of the predictor versus the response, using a nonlinear smoother, and eyeball the number of bends in the relationship between the two variables.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<p>For example, for the RT~frequency example, it looks like there are two bends:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>WrittenFrequency, <span class="dt">y=</span>RTlexdec), <span class="dt">data=</span>english) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_smooth</span>() +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.15</span>, <span class="dt">size=</span><span class="dv">1</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-20-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>so we would choose <span class="math inline">\(k=4\)</span>.</p>
</div>
<div id="method-2-data-driven" class="section level4">
<h4><span class="header-section-number">9.3.3.2</span> Method 2: Data-driven</h4>
<p>Fit models with different values of <span class="math inline">\(k\)</span>, as well as a linear model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.linear &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span>WrittenFrequency, <span class="dt">data=</span>english)
mod.rcs3 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">3</span>), <span class="dt">data=</span>english)
mod.rcs4 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">4</span>), <span class="dt">data=</span>english)
mod.rcs5 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">5</span>), <span class="dt">data=</span>english)
mod.rcs6 &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">6</span>), <span class="dt">data=</span>english)</code></pre></div>
<p>then use model comparison to see at what value of <span class="math inline">\(k\)</span> adding complexity no longer gives a better fit:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(mod.linear, mod.rcs3, mod.rcs4, mod.rcs5, mod.rcs6, mod.rcs7)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: RTlexdec ~ WrittenFrequency
## Model 2: RTlexdec ~ rcs(WrittenFrequency, 3)
## Model 3: RTlexdec ~ rcs(WrittenFrequency, 4)
## Model 4: RTlexdec ~ rcs(WrittenFrequency, 5)
## Model 5: RTlexdec ~ rcs(WrittenFrequency, 6)
## Model 6: RTlexdec ~ rcs(WrittenFrequency, 7)
##   Res.Df    RSS Df Sum of Sq       F    Pr(&gt;F)    
## 1   4566 91.194                                   
## 2   4565 89.602  1   1.59256 81.8914 &lt; 2.2e-16 ***
## 3   4564 89.056  1   0.54555 28.0526 1.236e-07 ***
## 4   4563 88.862  1   0.19449 10.0011  0.001575 ** 
## 5   4562 88.807  1   0.05496  2.8259  0.092822 .  
## 6   4561 88.699  1   0.10793  5.5497  0.018526 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The significant difference between the linear model and the <span class="math inline">\(k=3\)</span> model means that a nonlinear effect is justified. Increasing <span class="math inline">\(k\)</span> from 3 to 4 significantly improves the model, as does increasing from 4 to 5, but increasing from 5 to 6 doesn’t (<span class="math inline">\(p=0.09\)</span>). So we would choose a nonlinear relationship with <span class="math inline">\(k=5\)</span>. (Note that this is different from what we chose by visual inspection, <span class="math inline">\(k=4\)</span>, but the relationships for <span class="math inline">\(k=4\)</span> and <span class="math inline">\(k=5\)</span> turn out to be very similar.)</p>
<p><strong>Practical note</strong></p>
<p>Choosing <span class="math inline">\(k\)</span> is a <a href="#lm-model-comparison">model selection problem</a>, and like all model selection techniques the resulting model needs to be sanity-checked against the empirical data. In practice, models with very high <span class="math inline">\(k\)</span> often are “better” than a model with lower <span class="math inline">\(k\)</span> by model comparison via <code>anova()</code>, even when the value of <span class="math inline">\(k\)</span> makes no sense given visual inspection. For example, a model with 9 knots significantly improves on the <span class="math inline">\(k=5\)</span> model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.rcs9&lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="kw">rcs</span>(WrittenFrequency,<span class="dv">9</span>), <span class="dt">data=</span>english)
<span class="kw">anova</span>(mod.rcs5, mod.rcs9)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: RTlexdec ~ rcs(WrittenFrequency, 5)
## Model 2: RTlexdec ~ rcs(WrittenFrequency, 9)
##   Res.Df    RSS Df Sum of Sq    F  Pr(&gt;F)  
## 1   4563 88.862                            
## 2   4559 88.664  4   0.19759 2.54 0.03796 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>but there are obviously not 7 clear bends in the empirical relationship between <code>WrittenFrequency</code> and <code>RTlexdec</code>. In practice, you might use the lowest value of <span class="math inline">\(k\)</span> for which model comparison shows a significant improvement (over <span class="math inline">\(k-1\)</span>) <em>and</em> the predicted relationship is sensical.</p>
<p>Another option to choose a good value of <span class="math inline">\(k\)</span> would be to use another method for model comparison, rather than the F test (what <code>anova</code> does by default for linear regressions). BIC (Sec. <a href="linear-regression.html#non-nested-model-comparison">3.146.1</a>) may be a good choice, as it tends to penalize extra terms more highly than other <a href="#lm-model-comparison">methods we’ve considered</a> (e.g. AIC, F test, <a href="#c4lrt">LR test for logistic regressions</a>). For the current example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">BIC</span>(mod.linear, mod.rcs3, mod.rcs4, mod.rcs5, mod.rcs6, mod.rcs9)</code></pre></div>
<pre><code>##            df       BIC
## mod.linear  3 -4889.713
## mod.rcs3    4 -4961.764
## mod.rcs4    5 -4981.235
## mod.rcs5    6 -4982.795
## mod.rcs6    7 -4977.194
## mod.rcs9   10 -4959.256</code></pre>
<p>choosing the model with lowest BIC would give <span class="math inline">\(k=5\)</span>, a sensible value.</p>
</div>
</div>
<div id="rcs-components" class="section level3">
<h3><span class="header-section-number">9.3.4</span> RCS components</h3>
<p>Examining the model with <span class="math inline">\(k=5\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(mod.rcs5)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = RTlexdec ~ rcs(WrittenFrequency, 5), data = english)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.46761 -0.11624 -0.00069  0.10278  0.53806 
## 
## Coefficients:
##                                              Estimate Std. Error t value
## (Intercept)                                  6.742126   0.016089 419.059
## rcs(WrittenFrequency, 5)WrittenFrequency    -0.030765   0.005694  -5.404
## rcs(WrittenFrequency, 5)WrittenFrequency&#39;   -0.159054   0.037966  -4.189
## rcs(WrittenFrequency, 5)WrittenFrequency&#39;&#39;   0.761531   0.183525   4.149
## rcs(WrittenFrequency, 5)WrittenFrequency&#39;&#39;&#39; -0.810377   0.241481  -3.356
##                                             Pr(&gt;|t|)    
## (Intercept)                                  &lt; 2e-16 ***
## rcs(WrittenFrequency, 5)WrittenFrequency    6.87e-08 ***
## rcs(WrittenFrequency, 5)WrittenFrequency&#39;   2.85e-05 ***
## rcs(WrittenFrequency, 5)WrittenFrequency&#39;&#39;  3.39e-05 ***
## rcs(WrittenFrequency, 5)WrittenFrequency&#39;&#39;&#39; 0.000798 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1396 on 4563 degrees of freedom
## Multiple R-squared:  0.2098, Adjusted R-squared:  0.2091 
## F-statistic: 302.9 on 4 and 4563 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>there are four rows, with regression coefficients (etc.) describing the nonlinear relationship. For a linear relationship it was clear what the coefficient means: the change in <span class="math inline">\(Y\)</span> for a unit change in <span class="math inline">\(X\)</span>. <strong>What do the coefficients for an RCS mean?</strong></p>
<div id="short-answer" class="section level4">
<h4><span class="header-section-number">9.3.4.1</span> Short answer</h4>
<p>The short answer is: these coefficients are hard to interpret, and it’s fine to mostly ignore them, increase interpreting the nonlinear effect of <span class="math inline">\(X\)</span> as follows:</p>
<ul>
<li><p>Plotting model predictions to see the predicted effect</p></li>
<li><p>To assess whether (the nonlinear effect of) <span class="math inline">\(X\)</span> is significant, report a model comparison with a model without the nonlinear term.</p></li>
</ul>
<p>For the current example: code to visualize the nonlinear relationship is above, and you could report this in a paper as:</p>
<blockquote>
<p>“There was a nonlinear effect of frequency on reaction time, modeled using a restricted cubic spline with 5 knots (<span class="math inline">\(F_{4567,4} = 303\)</span>, <span class="math inline">\(p&lt;0.0001\)</span>), where the number of knots was chosen by picking the value which gave lowest BIC.”</p>
</blockquote>
<p>If you want to also report that a <em>nonlinear</em> effect in particular was justified, you could add a sentence like</p>
<blockquote>
<p>“A nonlinear relationship is clear from the empirical data (Fig. X), and significantly improves on a linear effect of frequency (<span class="math inline">\(F_{4566,3}=40\)</span>, <span class="math inline">\(p&lt;0.0001\)</span>).”<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p>
</blockquote>
<p>The model comparisons used in these reports are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.int &lt;-<span class="st"> </span><span class="kw">lm</span>(RTlexdec ~<span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>english)
<span class="kw">anova</span>(mod.linear, mod.rcs5)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: RTlexdec ~ WrittenFrequency
## Model 2: RTlexdec ~ rcs(WrittenFrequency, 5)
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1   4566 91.194                                  
## 2   4563 88.862  3    2.3326 39.926 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(mod.int, mod.rcs5)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: RTlexdec ~ 1
## Model 2: RTlexdec ~ rcs(WrittenFrequency, 5)
##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1   4567 112.456                                  
## 2   4563  88.862  4    23.594 302.88 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="c8longanswer" class="section level4">
<h4><span class="header-section-number">9.3.4.2</span> Long answer: Components of nonlinear functions</h4>
<!-- (LING 620: This could be skipped if short on time.) -->
<p>The rows of the regression table actually refer to “components” of the nonlinear function being modeled by the spline. To get a sense for what that means, let’s consider an example: the <code>WrittenFrequency</code> variable, which is roughly normally distributed with range <span class="math inline">\(\approx 0-12\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(english$WrittenFrequency)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-27-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>A nonlinear function of this variable could be included in a regression using a polynomial term, or an RCS term.</p>
<p>The first few components for a <strong>polynomial</strong> term would be: <img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-28-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Note that for degree <span class="math inline">\(k&gt;2\)</span> if <code>WrittenFrequency</code> goes below 0 or above 10, the component increases or decreases very quickly (as <span class="math inline">\(x^k\)</span>).</p>
<p>In comparison, the components for restricted cubic splines <strong>for this data</strong> for <span class="math inline">\(k=4\)</span> are: <img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-29-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>And for <span class="math inline">\(k=5\)</span> the components are: <img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-30-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>The four coefficients of the model above (with a <span class="math inline">\(k=5\)</span> RCS term for <code>WrittenFrequency</code>) refer to these four components. The predicted effect of <code>WrittenFrequency</code> on reaction time is: <span class="math display">\[
-0.03 \cdot \text{component1} -0.016 \cdot \text{component2} + 
0.761 \cdot \text{component3} -0.810 \cdot \text{component4}
\]</span> where -0.03, etc. are the coefficient values.</p>
<p>From the last two figures, we can see that each RCS component only grows <strong>linearly</strong> if extrapolated beyond the endpoints of the data. This is a useful property which gives better generalization on new data, when new values of the independent variable (here, <code>WrittenFrequency</code>) are observed.</p>
</div>
</div>
<div id="using-rcs-in-a-mixed-model" class="section level3">
<h3><span class="header-section-number">9.3.5</span> Using RCS in a mixed model</h3>
<p>As an example, we model the effect of speech rate deviation (<code>speakingRateDev</code>) on log-transformed voice onset time (<code>logVOT</code>) for <a href="datasets-appendix.html#votdata">the VOT dataset</a>.</p>
<p>The empirical effect seems clearly non-linear:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>speakingRateDev, <span class="dt">y=</span>logVOT), <span class="dt">data=</span>vot) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_smooth</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.15</span>, <span class="dt">size=</span><span class="dv">1</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Speech rate deviation&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;log(VOT)&quot;</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-31-1.png" width="384" style="display: block; margin: auto;" /> with speech rate having little effect on VOT in sufficiently fast speech.</p>
<blockquote>
<p><strong>Questions</strong>:</p>
<ul>
<li>What <span class="math inline">\(k\)</span> would we choose by visual inspection?</li>
</ul>
</blockquote>
<div id="exercise-5" class="section level4 unnumbered">
<h4>Exercise</h4>
<p>To choose <span class="math inline">\(k\)</span> in a data-driven fashion, try fitting these models using just random intercepts (no slopes) of <code>Speaker</code> and <code>Word</code>, and compare them using model comparison:</p>
<ul>
<li><p><code>VOT ~ speakingRateDev</code> (linear model)</p></li>
<li><p>Similar model with RCS for <span class="math inline">\(k = 3\)</span></p></li>
<li><p>Similar model with RCS for <span class="math inline">\(k = 4\)</span></p></li>
</ul>
</div>
</div>
<div id="random-slopes-for-rcs-terms" class="section level3">
<h3><span class="header-section-number">9.3.6</span> Random slopes for RCS terms</h3>
<p>Fitting a “maximal” mixed-effects model with random slopes for RCS terms often results in issues that are by now familiar (Sec. <a href="#c6factorsissue"><strong>??</strong></a>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">votMod.corr &lt;-<span class="st"> </span><span class="kw">lmer</span>(logVOT ~<span class="st"> </span><span class="kw">rcs</span>(speakingRateDev, <span class="dv">3</span>) +<span class="st"> </span>(<span class="dv">1</span>+<span class="kw">rcs</span>(speakingRateDev, <span class="dv">3</span>) |<span class="st"> </span>Word) +<span class="st"> </span>(<span class="dv">1</span>+<span class="kw">rcs</span>(speakingRateDev,<span class="dv">3</span>)|Speaker), <span class="dt">data=</span>vot)</code></pre></div>
<pre><code>## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl =
## control$checkConv, : unable to evaluate scaled gradient</code></pre>
<pre><code>## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl =
## control$checkConv, : Model failed to converge: degenerate Hessian with 1
## negative eigenvalues</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(votMod.corr)</code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: logVOT ~ rcs(speakingRateDev, 3) + (1 + rcs(speakingRateDev,  
##     3) | Word) + (1 + rcs(speakingRateDev, 3) | Speaker)
##    Data: vot
## 
## REML criterion at convergence: 4595.4
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.2267 -0.6003  0.0509  0.6510  3.0740 
## 
## Random effects:
##  Groups   Name                                    Variance  Std.Dev. Corr 
##  Word     (Intercept)                             0.0000000 0.00000       
##           rcs(speakingRateDev, 3)speakingRateDev  0.0170030 0.13040    NaN
##           rcs(speakingRateDev, 3)speakingRateDev&#39; 0.0235881 0.15358    NaN
##  Speaker  (Intercept)                             0.0253568 0.15924       
##           rcs(speakingRateDev, 3)speakingRateDev  0.0022754 0.04770   0.16
##           rcs(speakingRateDev, 3)speakingRateDev&#39; 0.0001518 0.01232   0.12
##  Residual                                         0.1450546 0.38086       
##       
##       
##       
##  -1.00
##       
##       
##  -0.96
##       
## Number of obs: 4728, groups:  Word, 424; Speaker, 21
## 
## Fixed effects:
##                                         Estimate Std. Error t value
## (Intercept)                              3.99525    0.03700 107.966
## rcs(speakingRateDev, 3)speakingRateDev  -0.15343    0.01908  -8.043
## rcs(speakingRateDev, 3)speakingRateDev&#39;  0.10948    0.01828   5.989
## 
## Correlation of Fixed Effects:
##             (Intr) rc(RD,3)RD
## rcs(RD,3)RD  0.230           
## rc(RD,3)RD&#39; -0.175 -0.837    
## convergence code: 0
## unable to evaluate scaled gradient
## Model failed to converge: degenerate  Hessian with 1 negative eigenvalues</code></pre>
<p>non-convergence, and perfect correlations between random effects. There are a couple probable causes, both of which came up when we have hit these issues before:</p>
<ol style="list-style-type: decimal">
<li><p>The model may be overparametrized—the random-effect structure is too complex for the dataset size.</p></li>
<li><p>The predictors are not centered (see Section <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#rcs-components">9.3.4</a>)—which results in substantial avoidable collinearity. (See the lower-right entry of <code>Correlation of fixed effects</code>: the correlation between the two RCS components is high (<span class="math inline">\(-0.83\)</span>).)</p></li>
</ol>
<p>There are two corresponding ways to deal with these issues if they come up.</p>
<div id="option-1-fit-a-model-without-random-effect-correlations" class="section level4 unnumbered">
<h4>Option 1: Fit a model without random-effect correlations</h4>
<p>To do this, we need to extract the individual components of the RCS term as numeric variables—this is analogous to extracting the contrasts as numeric variables for a factor, to use uncorrelated random effects.</p>
<p>This code extracts the two components for the spline with 3 knots, and adds them to the dataframe as columns:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">vot$rateDev.comp1 &lt;-<span class="st"> </span><span class="kw">rcspline.eval</span>(vot$speakingRateDev, <span class="dt">nk=</span><span class="dv">3</span>, <span class="dt">inclx=</span><span class="ot">TRUE</span>)[,<span class="dv">1</span>]
vot$rateDev.comp2 &lt;-<span class="st"> </span><span class="kw">rcspline.eval</span>(vot$speakingRateDev, <span class="dt">nk=</span><span class="dv">3</span>, <span class="dt">inclx=</span><span class="ot">TRUE</span>)[,<span class="dv">2</span>]</code></pre></div>
<p>The function <code>rcspline.eval</code> gives a matrix of components, <code>nk=3</code> selects <span class="math inline">\(k\)</span>, <code>[,1]</code> or <code>[,2]</code> selects the matrix column number, and <code>inclx=TRUE</code> adds the linear component in addition to the nonlinear components. <!-- (I"m not sure why this isn't the default.) --></p>
<p>We can then fit the model without random-effect correlations:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">votMod.nocorr &lt;-<span class="st"> </span><span class="kw">lmer</span>(logVOT ~<span class="st"> </span>rateDev.comp1 +<span class="st"> </span>rateDev.comp2 +<span class="st"> </span>
<span class="st">                        </span>(<span class="dv">1</span>+rateDev.comp1 +<span class="st"> </span>rateDev.comp2 ||<span class="st"> </span>Word) +<span class="st"> </span>
<span class="st">                        </span>(<span class="dv">1</span>+rateDev.comp1 +<span class="st"> </span>rateDev.comp2||Speaker), 
                      <span class="dt">data=</span>vot)</code></pre></div>
<p>The model now converges. (This may not be kosher, though—there are conceptual issues with using uncorrelated random effects for non-centered variables <span class="citation">(Barr, Levy, Scheepers, &amp; Tily, <a href="#ref-barr2013random">2013</a>)</span>.</p>
<!-- TODO FUTURE: check if that's right, or just something Roger has said in online posts..? get a better ref -->
<p>The model is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(votMod.nocorr)</code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: 
## logVOT ~ rateDev.comp1 + rateDev.comp2 + ((1 | Word) + (0 + rateDev.comp1 |  
##     Word) + (0 + rateDev.comp2 | Word)) + ((1 | Speaker) + (0 +  
##     rateDev.comp1 | Speaker) + (0 + rateDev.comp2 | Speaker))
##    Data: vot
## 
## REML criterion at convergence: 4475.1
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.3005 -0.5865  0.0448  0.6312  3.3378 
## 
## Random effects:
##  Groups    Name          Variance  Std.Dev.
##  Word      (Intercept)   2.914e-02 0.170708
##  Word.1    rateDev.comp1 2.327e-04 0.015255
##  Word.2    rateDev.comp2 9.418e-06 0.003069
##  Speaker   (Intercept)   2.540e-02 0.159365
##  Speaker.1 rateDev.comp1 1.358e-03 0.036856
##  Speaker.2 rateDev.comp2 0.000e+00 0.000000
##  Residual                1.394e-01 0.373399
## Number of obs: 4728, groups:  Word, 424; Speaker, 21
## 
## Fixed effects:
##               Estimate Std. Error t value
## (Intercept)    4.07384    0.03913 104.113
## rateDev.comp1 -0.10347    0.01391  -7.436
## rateDev.comp2  0.03810    0.01237   3.080
## 
## Correlation of Fixed Effects:
##             (Intr) rtDv.1
## rateDv.cmp1  0.176       
## rateDv.cmp2 -0.259 -0.646</code></pre>
<p>Note the significant <code>rateDev.comp1</code> and <code>rateDev.comp2</code> terms, which we can think of as the “linear” and “nonlinear” terms.</p>
<blockquote>
<p><strong>Questions</strong>:</p>
<ul>
<li><p>What does the fact that both are significant tell us?</p></li>
<li><p>How do people differ in the speech rate effect? (Examine the random slope terms.)</p></li>
</ul>
</blockquote>
<!-- ### Exercise -->
<!-- * Fit a model with **linear** effect of `speechRateDev` (standardized)  -->
<!--     * Random slopes, no correlations -->
<!-- * Check that `votMod.nocorr` is a significant improvement -->
<!-- * Extra: Fit a model with a nonlinear effect with $k = 5$ (again: random slopes, no correlations) -->
<!--       * Show that it doesn't significantly improve on `mod2` -->
<p><strong>Detour</strong>: Visualizing nonlinear effects</p>
<p>It would be nice to visualize the predicted nonlinear effect from a model, but this turns out to be slightly tricky and is not shown here. <!-- (TODO in a future year: actually show how to do this in an appendix.) --></p>
<p>An easier approximation, which is usually a good idea anyway (as a sanity check that the empirical data shows the qualitative effect predicted by the model), is to plot a smooth over the empirical data using a spline with the same number of knots as the RCS term in the model.</p>
<p>For example, to visualize the effect of an RCS term with 3 knots for a <code>VOT ~ speech rate</code> model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>speakingRateDev, <span class="dt">y=</span>logVOT), <span class="dt">data=</span>vot) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&#39;lm&#39;</span>, <span class="dt">formula=</span>y~splines::<span class="kw">ns</span>(x,<span class="dv">3</span>)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Speech rate deviation&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;VOT (log)&quot;</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-36-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
<div id="option-2-use-centered-predictors" class="section level4 unnumbered">
<h4>Option 2: Use centered predictors</h4>
<p>Note that RCS components are not centered, by default—as can be seen in the plots of these components for <span class="math inline">\(k=4\)</span> and <span class="math inline">\(k=5\)</span> in Sec. <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8longanswer">9.3.4.2</a>, where each component is positive for all values of <code>WrittenFrequency</code>. Less problematically, they are not orthogonal—for example, components 1 and 2 are clearly correlated (for <span class="math inline">\(k=4\)</span> and <span class="math inline">\(k=5\)</span>), as component 2 is a line for <code>WrittenFrequency</code>&gt;6.</p>
<p>We can address both issues by using the <em>principal components</em> of the RCS components: a linear transformation which makes them centered and orthogonal. You can extract the principal components in R using the <code>pc=TRUE</code> flag:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">vot$rateDev.pcomp1 &lt;-<span class="st"> </span><span class="kw">rcspline.eval</span>(vot$speakingRateDev, <span class="dt">nk=</span><span class="dv">3</span>,<span class="dt">inclx=</span><span class="ot">TRUE</span>, <span class="dt">pc=</span><span class="ot">TRUE</span>)[,<span class="dv">1</span>]
vot$rateDev.pcomp2 &lt;-<span class="st"> </span><span class="kw">rcspline.eval</span>(vot$speakingRateDev, <span class="dt">nk=</span><span class="dv">3</span>, <span class="dt">inclx=</span><span class="ot">TRUE</span>, <span class="dt">pc=</span><span class="ot">TRUE</span>)[,<span class="dv">2</span>]</code></pre></div>
<p>These are still restricted cubic spline components (they look like glued-together polynomials, etc.), but they look different from before. For example, the first and second components for <span class="math inline">\(k=3\)</span> for <code>speakingRateDev</code> for the <code>vot</code> data are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rcsPlot1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>speakingRateDev,<span class="dt">y=</span>rateDev.pcomp1), <span class="dt">data=</span>vot) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Speech rate deviation&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;First component&quot;</span>)

rcsPlot2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>speakingRateDev,<span class="dt">y=</span>rateDev.pcomp2), <span class="dt">data=</span>vot) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Speech rate deviation&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Second component&quot;</span>)

<span class="kw">grid.arrange</span>(rcsPlot1, rcsPlot2, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-38-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>(Compare to the plots for <span class="math inline">\(k=4\)</span> and <span class="math inline">\(k=5\)</span> above.) For our purposes, the most important difference is that the PCs are centered.</p>
<p>A model using the PC versions of the RCS components, with full maximal random-effect structure (correlations between random effects included), would be:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">votMod.corr<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">lmer</span>(logVOT ~<span class="st"> </span>rateDev.pcomp1 +<span class="st"> </span>rateDev.pcomp2 +<span class="st"> </span>
<span class="st">                          </span>(<span class="dv">1</span>+rateDev.pcomp1 +<span class="st"> </span>rateDev.pcomp2|Word) +<span class="st"> </span>
<span class="st">                          </span>(<span class="dv">1</span>+rateDev.pcomp1 +<span class="st"> </span>rateDev.pcomp2|Speaker), 
                        <span class="dt">data=</span>vot)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(votMod.corr<span class="fl">.2</span>)</code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: logVOT ~ rateDev.pcomp1 + rateDev.pcomp2 + (1 + rateDev.pcomp1 +  
##     rateDev.pcomp2 | Word) + (1 + rateDev.pcomp1 + rateDev.pcomp2 |  
##     Speaker)
##    Data: vot
## 
## REML criterion at convergence: 4467.3
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.2831 -0.5951  0.0451  0.6310  3.3031 
## 
## Random effects:
##  Groups   Name           Variance  Std.Dev. Corr       
##  Word     (Intercept)    0.0277041 0.16645             
##           rateDev.pcomp1 0.0001375 0.01172   0.84      
##           rateDev.pcomp2 0.0011219 0.03349  -0.87 -0.46
##  Speaker  (Intercept)    0.0253885 0.15934             
##           rateDev.pcomp1 0.0007723 0.02779  -0.24      
##           rateDev.pcomp2 0.0029008 0.05386   0.02 -0.98
##  Residual                0.1394170 0.37339             
## Number of obs: 4728, groups:  Word, 424; Speaker, 21
## 
## Fixed effects:
##                 Estimate Std. Error t value
## (Intercept)     4.103607   0.037700 108.848
## rateDev.pcomp1  0.057963   0.008032   7.217
## rateDev.pcomp2 -0.113209   0.021463  -5.275
## 
## Correlation of Fixed Effects:
##             (Intr) rtDv.1
## ratDv.pcmp1 -0.145       
## ratDv.pcmp2 -0.011 -0.427</code></pre>
<p>Crucially, this model makes the same predictions as <code>votMod.corr</code>—the only difference is in how the nonlinear function of <code>speechRateDev</code> is coded (analogously to using different contrast coding schemes for a factor).<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> However, the new model converged without issue, while <code>votMod.corr</code> did not—likely because we are now representing the <code>speechRateDev</code> effect using centered and orthogonal variables.</p>
<p>Note that there is less collinearity in <code>votMod.corr.2</code> than in <code>votMod.corr</code>—the correlations in <code>Correlation of Fixed Effects</code> are closer to zero.</p>
<blockquote>
<p><strong>Questions</strong>:</p>
<ul>
<li>Why is this?</li>
</ul>
</blockquote>
</div>
</div>
<div id="nonlinear-effects-summary" class="section level3">
<h3><span class="header-section-number">9.3.7</span> Nonlinear effects: Summary</h3>
<p>To summarize:</p>
<ul>
<li><p>Nonlinear effects can be used to capture non-linear relationships between the response and (a) predictor(s). Such relationships are common, so <strong>using nonlinear effects is often appropriate.</strong></p>
<ul>
<li>Modeling nonlinear relationships <strong>somehow</strong> is more important than the actual method used!</li>
</ul></li>
<li><p>In terms of a method: we recommend using splines to code nonlinear effects. (Here we have demonstrated restricted cubic splines, but other flavors are OK.)</p>
<ul>
<li><p>Pro: Splines are well-behaved and should lead to better generalization to new data.</p></li>
<li><p>Con: Spline components are tricky to interpret, and (in R) sometimes tricky to work with.</p></li>
</ul></li>
<li><p>Using polynomials to model nonlinear effects is OK, but dispreferred.</p>
<ul>
<li><p>Pro: Polynomial terms are easy to interpret</p></li>
<li><p>Con: Polynomial functions are not well-behaved (interpolation issues, etc.) and can make bad predictions on new data.</p></li>
<li><p>Regardless, polynomials are commonly used, e.g. in <a href="http://www.danmirman.org/gca">Growth Curve Analysis</a> (which is basically mixed-effects models with polynomials used to model a nonlinear relationship).</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="predictions-from-mixed-models" class="section level2">
<h2><span class="header-section-number">9.4</span> Predictions from mixed models</h2>
<p>To visualize the predictions of mixed models, it is useful to make:</p>
<ul>
<li><p><em>partial effect plots</em>: These show the model’s prediction as one predictor is changed, holding others constant.</p></li>
<li><p>predictions for different levels of grouping factors (e.g. different participants): in the overall value (“intercept”), partial effect of a given predictor (“slope”), or something more complex.</p></li>
</ul>
<p>Decent software (in 2018) exists for making such predictions from mixed models, such as:</p>
<ul>
<li><p>The <a href="https://cran.r-project.org/web/packages/effects/index.html"><code>effects</code></a> package (see <a href="https://cran.r-project.org/web/packages/effects/vignettes/effectsMethods.pdf">vignette</a>)</p></li>
<li><p>The <a href="http://www.strengejacke.de/sjPlot/sjp.lmer/"><code>sjPlot</code></a> package</p></li>
<li><p><code>plotLMER.fnc()</code> in <code>languageR</code></p></li>
</ul>
<p>Nonetheless, it is also useful to know how to make such predictions yourself, as pre-existing packages make various assumptions, and don’t always give exactly what you want.</p>
<div id="making-model-predictions" class="section level3">
<h3><span class="header-section-number">9.4.1</span> Making Model Predictions</h3>
<!-- (LING 620: This could be skipped if short on time, given the existence of the packages above.) -->
<p>Visualizing predictions from a model in R always involves three steps:</p>
<ol style="list-style-type: decimal">
<li><p>Make a new dataframe of values you want to predict at</p></li>
<li><p>Get predictions of model for these values</p></li>
<li><p>Make plots of the predictions</p></li>
</ol>
<div id="example-13" class="section level4 unnumbered">
<h4>Example</h4>
<p>Let’s use a basic model of the <code>acoustics</code> correlate of stress shifting, for <a href="datasets-appendix.html#givedata">the <code>givenness</code> data</a>:<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod1 &lt;-<span class="st"> </span><span class="kw">lmer</span>(acoustics ~<span class="st"> </span>conditionLabel*npType +<span class="st"> </span>voice +
<span class="st">                 </span>(<span class="dv">1</span> +<span class="st"> </span>clabel.williams*npType.pron ||<span class="st"> </span>item) +
<span class="st">                 </span>(<span class="dv">1</span> +<span class="st"> </span>clabel.williams*npType.pron +<span class="st"> </span>voice.passive|<span class="st"> </span>participant),
             <span class="dt">data=</span>givenness)</code></pre></div>
</div>
<div id="predictions-only-no-confidence-intervals" class="section level4 unnumbered">
<h4>Predictions only (no confidence intervals)</h4>
<p><strong>Step 1</strong>: Make dataframe of new values we want to predict the response for:</p>
<p>The <code>expand.grid()</code> function can be used to make all possible combinations of multiple predictors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newdata &lt;-<span class="st"> </span><span class="kw">with</span>(givenness,
                <span class="kw">expand.grid</span>(<span class="dt">conditionLabel=</span><span class="kw">unique</span>(conditionLabel),
                            <span class="dt">npType=</span><span class="kw">unique</span>(npType), 
                            <span class="dt">voice=</span><span class="kw">unique</span>(voice)))

newdata</code></pre></div>
<pre><code>##   conditionLabel  npType   voice
## 1       Williams    full passive
## 2       Contrast    full passive
## 3       Williams pronoun passive
## 4       Contrast pronoun passive
## 5       Williams    full  active
## 6       Contrast    full  active
## 7       Williams pronoun  active
## 8       Contrast pronoun  active</code></pre>
<p><strong>Step 2</strong>: Make model predictions</p>
<p>If you want predictions based on <strong>fixed effects only</strong> (no random effects), use the <code>predict()</code> function with the flag <code>re.form=NA</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newdata$prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(mod1, <span class="dt">newdata=</span>newdata, <span class="dt">re.form=</span><span class="ot">NA</span>)</code></pre></div>
<p><strong>Step 3</strong>: Visualize</p>
<p>The model’s predictions for <code>acoustics</code> as a function of the three predictors (condition label, NP type, voice) are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>conditionLabel, <span class="dt">y=</span>prediction), <span class="dt">data=</span>newdata) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color=</span>npType)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color=</span>npType,<span class="dt">group=</span>npType)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">facet_wrap</span>(~voice) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Predicted value&quot;</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-44-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>These predictions are for an average participant, and “average item”: meaning, the average over <code>voice</code>=active and <code>voice</code>=passive items.</p>
<p>To make a “partial effect plot” of just the effect of <code>conditionLabel</code>, say, we can simply average over the other variables:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newdata %&gt;%<span class="st"> </span><span class="kw">group_by</span>(conditionLabel) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">pred=</span><span class="kw">mean</span>(prediction), <span class="dt">dummy=</span><span class="dv">1</span>) %&gt;%<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>conditionLabel, <span class="dt">y=</span>pred)) +<span class="st"> </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group=</span>dummy)) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Predicted value&quot;</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
</div>
<div id="predictions-with-confidence-intervals" class="section level4 unnumbered">
<h4>Predictions with confidence intervals</h4>
<p>Generally we want to show model predictions with a measure of uncertainty, such as confidence intervals (CIs)</p>
<p>Obtaining CIs turns out to be less straightforward than obtaining just model predictions, because there is more than one way to define “uncertainty”. For example: do we want to take into account uncertainty from just (uncertainty about the) fixed effects? What about random effects? And how? (You can google “confidence intervals prediction lme4” to get a sense of the issue.)</p>
<p>You can get confidence intervals relatively simply using just the uncertainty in the fixed effects, as illustrated in Ben Bolker’s <a href="https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#predictions-andor-confidence-or-prediction-intervals-on-predictions">FAQ</a>. Applied to our data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## &quot;design matrix&quot; for fitted model
mm &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="kw">terms</span>(mod1), <span class="kw">data.frame</span>(<span class="dt">acoustics=</span><span class="dv">1</span>, newdata))

## SE of prediction, just from uncertainty in fixed effects and residual variance:
newdata$SE &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">diag</span>(mm %*%<span class="st"> </span><span class="kw">tcrossprod</span>(<span class="kw">vcov</span>(mod1), mm)))</code></pre></div>
<p>Note that the computed standard error (<code>SE</code>) does not take into account variation among participants, etc. It can be thought of as “the error for an average subject and item”.</p>
<p>Multiplying these standard errors by 1.96 can be used to construct 95% confidence intervals (again, calculated from the fixed-effect errors only), which can be visualized:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>conditionLabel, <span class="dt">y=</span>prediction, <span class="dt">ymin=</span>prediction<span class="fl">-1.96</span>*SE, <span class="dt">ymax=</span>prediction<span class="fl">+1.96</span>*SE), <span class="dt">data=</span>newdata) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color=</span>npType)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">color=</span>npType), <span class="dt">width=</span><span class="fl">0.3</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">facet_wrap</span>(~voice) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Predicted value&quot;</span>)</code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-47-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
<div id="extracting-predicted-random-effects" class="section level4 unnumbered">
<h4>Extracting predicted random effects</h4>
<p>Extracting partial effects, and “overall” values (intercepts) for each participant (etc.) is also of interest. Some examples are given in previous chapters, and further examples are shown in an Appendix (Sec. <a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#c8indivpreds">9.6</a>).</p>
<!-- TODO FUTURE: link to previous chapter examples -->
</div>
</div>
<div id="simulation-based-predictions" class="section level3">
<h3><span class="header-section-number">9.4.2</span> Simulation-based predictions</h3>
<p>The examples seen so far calculate model predictions and confidence intervals using the terms of the fitted models—fixed-effect coefficient values and SEs, and so on. This requires writing some code (and some knowledge), but the predictions/CIs are computed quickly.</p>
<p>The more general solution, which requires little code or knowledge—but can be very slow—is computing model predictions and confidence intervals using simulation. Parametric or semi-parametric bootstrapping, as implemented in the <code>bootMer</code> package or the <code>simulate</code> function (from the <code>arm</code> package), can be used to estimate the probability distribution over values of <strong>any</strong> quantity predicted by the model—including a particular combination of predictor values, as in a partial-effect plot. This distribution can be used to obtain a “prediction” and “95% confidence interval” by computing e.g. the median and the 2.5%/97.5% quantiles. The downside is that simulation can be very computationally intensive—you essentially have to re-fit the model many (1000+) times to get reasonable estimates.</p>
<p>Useful examples are given in:</p>
<ul>
<li><p>A <a href="https://cran.r-project.org/web/packages/merTools/vignettes/Using_predictInterval.html">vignette</a> by J. Knowles and C. Frederick</p></li>
<li><p>An <a href="https://www.r-bloggers.com/confidence-intervals-for-prediction-in-glmms/">R-bloggers</a> page by grumble10.</p></li>
</ul>
<p>An example of a simple simulation-based method is shown for LMMs in Section <a href="#lmm-simulation-confint"><strong>??</strong></a>.</p>
</div>
</div>
<div id="post-hoc-mult-comp" class="section level2">
<h2><span class="header-section-number">9.5</span> Post-hoc tests and multiple comparisons</h2>
<p>The <em>multiple comparisons</em> problem refers to the issue that the more hypotheses you test, the less meaningful the <span class="math inline">\(p\)</span>-values are. (If we test 20 hypotheses with <span class="math inline">\(\alpha\)</span> level <span class="math inline">\(0.05\)</span>, we will find 1 significant effect by chance, on average.)</p>
<p>A solution commonly used is to correct the <span class="math inline">\(p\)</span>-values for “multiple comparisons” before comparing to <span class="math inline">\(\alpha\)</span> (e.g. 0.05). Many such correction methods exist, including:</p>
<ul>
<li>The <em>Bonferroni</em> method: multiply <span class="math inline">\(p\)</span> by the number of tests conducted
<ul>
<li>This method has low power, and should never be used—see <code>?p.adjust.methods</code> in R.</li>
</ul></li>
<li>The <em>Holm</em> method
<ul>
<li>Less conservative than Bonferroni</li>
</ul></li>
<li><p><em>Tukey HSD</em> (“Honestly Significant Difference”)</p></li>
<li><p><em>FDR</em> (“False Discovery Rate”), a.k.a. the Benjamini &amp; Hochberg (BH) method</p></li>
</ul>
<p>Not correcting for multiple comparisons when doing many statistical tests can easily lead to spurious results—this is often called “data dredging” or “p-hacking”.</p>
<p>Which multiple comparison method should be used? There is a trade-off between methods with higher power and lower Type I error. Reasonable and widely-used methods are Holm and Tukey HSD.</p>
<p>One place where the multiple comparisons problem comes up is for factors with multiple (&gt;2) levels. When a model includes a categorical variable <span class="math inline">\(X\)</span> with <span class="math inline">\(k\)</span> levels, we know how to:</p>
<ol style="list-style-type: decimal">
<li><p>Ask <span class="math inline">\(k-1\)</span> questions about how it affects the response: <strong>contrast coding</strong> (discussed in Sec. <a href="practical-regression-topics-1-multi-level-factors-contrast-coding-interactions.html#contrast-coding">6.6</a>)</p></li>
<li><p>Ask “does <span class="math inline">\(X\)</span> affect the response?”: <strong>likelihood ratio test</strong> (discussed in Sec. <a href="#c5mlf"><strong>??</strong></a>)</p></li>
</ol>
<p>It is customary to not correct for multiple comparisons for (1)—and indeed, for any set of predictors in multiple regression models in general.<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></p>
<p>But often, we would like to ask more than <span class="math inline">\(k-1\)</span> questions, such as:</p>
<ul>
<li><p>“is level 1 diff from level 2?” “Level 2 from level 3?” “Level 1 from level 3?”</p></li>
<li><p>“is there any Williams effect when <code>npType</code> = pronoun?” (for the <code>givenness</code> data)</p></li>
</ul>
<p>Such questions can be answered via hypothesis tests using <em>post-hoc tests</em>.<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> These are also called “difference in means tests”, or other terms. It is common in ANOVA analyses to use “post-hoc tests” to refer to “testing which levels of a factor <span class="math inline">\(X\)</span> are actually different from each other, after an ANOVA showed that <span class="math inline">\(X\)</span> has a significant effect.”</p>
<p>When we ask more than <span class="math inline">\(k-1\)</span> questions, the questions are not independent, so we <strong>need</strong> to correct for multiple comparisons.</p>
<div id="example-14" class="section level4 unnumbered">
<h4>Example</h4>
<p>As an example, consider the <code>alternatives</code> dataset, where we will fit a mixed-effects logistic regression, with:</p>
<ul>
<li><p>Response: <code>prominence</code></p></li>
<li><p>Predictor: <code>context</code> (<em>NoAlternative</em>, <em>Alternative</em>, <em>None</em>)</p></li>
<li><p>Random effects: maximal, without random-effect correlations</p></li>
</ul>
<p>The empirical pattern is:</p>
<pre><code>##         context prominence.ID         se
## 1   Alternative     0.4146341 0.03449301
## 2 NoAlternative     0.7380952 0.03041268
## 3           New     0.8502415 0.02486184</code></pre>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-48-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>First, we make <code>context1</code>, <code>context2</code> numerical predictors, corresponding to the two Helmert contrasts:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">contrasts</span>(alternatives$context) &lt;-<span class="st"> </span><span class="kw">contr.helmert</span>(<span class="dv">3</span>)
alternatives &lt;-<span class="st"> </span><span class="kw">mutate</span>(alternatives, 
                       <span class="dt">context1 =</span> <span class="kw">model.matrix</span>(~context, alternatives)[,<span class="dv">2</span>],
                       <span class="dt">context2 =</span> <span class="kw">model.matrix</span>(~context, alternatives)[,<span class="dv">3</span>])</code></pre></div>
<p>The model is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.nocorr &lt;-<span class="st"> </span><span class="kw">glmer</span>(prominence ~<span class="st"> </span>context +<span class="st"> </span>
<span class="st">                      </span>(<span class="dv">1</span>+context1 +<span class="st"> </span>context2||participant) +<span class="st"> </span>
<span class="st">                      </span>(<span class="dv">1</span>+context1 +<span class="st"> </span>context2||item), 
                    <span class="dt">data=</span>alternatives, 
                    <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>, 
                    <span class="dt">control=</span><span class="kw">glmerControl</span>(<span class="dt">optimizer =</span> <span class="st">&quot;bobyqa&quot;</span>))
<span class="kw">summary</span>(mod.nocorr)</code></pre></div>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: 
## prominence ~ context + (1 + context1 + context2 || participant) +  
##     (1 + context1 + context2 || item)
##    Data: alternatives
## Control: glmerControl(optimizer = &quot;bobyqa&quot;)
## 
##      AIC      BIC   logLik deviance df.resid 
##    646.8    686.7   -314.4    628.8      613 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.5763 -0.5676  0.2484  0.5564  2.9286 
## 
## Random effects:
##  Groups        Name        Variance Std.Dev.
##  participant   (Intercept) 0.67379  0.8208  
##  participant.1 context1    0.06545  0.2558  
##  participant.2 context2    0.00000  0.0000  
##  item          (Intercept) 0.56035  0.7486  
##  item.1        context1    0.00000  0.0000  
##  item.2        context2    0.29399  0.5422  
## Number of obs: 622, groups:  participant, 18; item, 12
## 
## Fixed effects:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   1.1533     0.3199   3.605 0.000312 ***
## context1      0.8716     0.1375   6.338 2.32e-10 ***
## context2      0.7014     0.1909   3.673 0.000240 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##          (Intr) cntxt1
## context1 0.054        
## context2 0.129  0.018</code></pre>
<p>The two significant fixed-effect coefficients can be interpreted as:</p>
<ul>
<li><p><em>NoAlternative</em> &gt; <em>Alternative</em> (in terms of probability of prominence shift)</p></li>
<li><p><em>New</em> &gt; <em>NoAlternative</em>/<em>Alternative</em></p></li>
</ul>
<p>But what about <em>NoAlternative</em> versus <em>New</em>, or <em>Alternative</em> versus <em>New</em>?</p>
<p>The <code>lsmeans</code> package (now superceded by the <code>emmeans</code> package, with expanded functionality) is invaluable for carrying out post-hoc tests <span class="citation">(Lenth, <a href="#ref-lsmeans">2016</a>, <a href="#ref-emmeans">2018</a>)</span>. In this case, we examine every difference between two levels:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.lsmeans &lt;-<span class="st"> </span>lsmeans::<span class="kw">lsmeans</span>(mod.nocorr, ~context)
<span class="kw">pairs</span>(mod.lsmeans)</code></pre></div>
<pre><code>##  contrast                     estimate        SE df z.ratio p.value
##  Alternative - NoAlternative -1.743220 0.2750211 NA  -6.338  &lt;.0001
##  Alternative - New           -2.975683 0.5915409 NA  -5.030  &lt;.0001
##  NoAlternative - New         -1.232463 0.5866488 NA  -2.101  0.0896
## 
## Results are given on the log odds ratio (not the response) scale. 
## P value adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<p>This reports an estimated difference between each pair of levels (here, in log-odds), with an associated <span class="math inline">\(p\)</span>-value, corrected for multiple comparisons using the Tukey HSD method.</p>
<p>We can conclude that: <em>Alternative</em> <span class="math inline">\(&lt;\)</span> <em>NoAlternative</em> <span class="math inline">\(\leq\)</span> <em>New</em> (at <span class="math inline">\(\alpha=0.05\)</span>).</p>
<p>Post-hoc tests can also be used for:</p>
<ul>
<li><p>Checking whether particular subsets of levels differ from others</p></li>
<li><p>Checking whether <span class="math inline">\(X\)</span> has an effect, for each level of <span class="math inline">\(Y\)</span> (e.g., “is the Williams effect significant for <strong>each</strong> level of <code>npType</code>?”, for the <code>givenness</code> data)</p></li>
</ul>
<p>For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">temp &lt;-<span class="st"> </span>lsmeans::<span class="kw">lsmeans</span>(mod1, ~conditionLabel |<span class="st"> </span>npType)
<span class="kw">pairs</span>(temp)</code></pre></div>
<pre><code>## npType = full:
##  contrast              estimate         SE    df t.ratio p.value
##  Contrast - Williams -0.1694650 0.08214115 53.57  -2.063  0.0440
## 
## npType = pronoun:
##  contrast              estimate         SE    df t.ratio p.value
##  Contrast - Williams -0.4691477 0.09227544 22.89  -5.084  &lt;.0001
## 
## Results are averaged over the levels of: voice</code></pre>
<p>You can read more in the very useful <a href="http://cran.r-project.org/web/packages/lsmeans/vignettes/using-lsmeans.pdf">vignette</a> for <code>lsmeans</code> (or <a href="https://cran.r-project.org/web/packages/emmeans/vignettes/">for <code>emmeans</code></a>).</p>
<p><strong>Exercise</strong></p>
<ul>
<li><p>For <a href="datasets-appendix.html#dregdata">the <code>regularity</code> data</a>, fit a logistic regression of <code>regularity</code> as a function of <code>Auxiliary</code></p></li>
<li><p>Use <code>lsmeans</code> to test: is there a difference between</p>
<ul>
<li><p><em>zijn</em>/<em>hebben</em></p></li>
<li><p><em>zijnheb</em>/<em>hebben</em></p></li>
<li><p><em>zijn</em>/<em>zijnheb</em></p></li>
</ul></li>
</ul>
<p>?</p>
<!-- TODO FUTURE: "other readings" section -->
</div>
</div>
<div id="c8indivpreds" class="section level2">
<h2><span class="header-section-number">9.6</span> Appendix: Model predictions for indiviudal participants</h2>
<p>A couple additional examples of predictions from <code>mod1</code>:</p>
<div id="predictions-incorporating-offsets-for-individual-speakers" class="section level3">
<h3><span class="header-section-number">9.6.1</span> Predictions incorporating offsets for individual speakers</h3>
<p>Get predictions for every speaker, for every combination of fixed-effect values: <!-- ((Q4M: Below in `predict` the slides make reference to `mod3.full`. This model doesn't appear in the code and so I have temporarily placed `mod1` as standby since this model is the only one discussed))   --> <!-- ((I can't get this code to work without fairly substantial edits, and as a result this following figures aren't identical)) --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newdata &lt;-<span class="st"> </span><span class="kw">with</span>(givenness,
                <span class="kw">expand.grid</span>(<span class="dt">participant=</span><span class="kw">unique</span>(participant),
                            <span class="dt">item=</span><span class="kw">unique</span>(item),
                            <span class="dt">conditionLabel=</span><span class="kw">unique</span>(conditionLabel),
                            <span class="dt">npType=</span><span class="kw">unique</span>(npType), 
                            <span class="dt">voice=</span><span class="kw">unique</span>(voice),
                            <span class="dt">voice.passive=</span><span class="kw">unique</span>(voice.passive),
                            <span class="dt">clabel.williams=</span><span class="kw">unique</span>(clabel.williams),
                            <span class="dt">npType.pron=</span><span class="kw">unique</span>(npType.pron)))

newdata$prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(mod1, <span class="dt">newdata=</span>newdata, <span class="dt">re.form=</span>~(<span class="dv">1</span>|participant))</code></pre></div>
<p>These predictions can be used to obtain each speaker’s intercept (fixed effect + by-speaker intercept), and visualize their distribution across speakers:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">byParticInt &lt;-<span class="st"> </span>newdata %&gt;%<span class="st"> </span><span class="kw">group_by</span>(participant) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">intercept =</span> <span class="kw">mean</span>(prediction))

<span class="kw">ggplot</span>(byParticInt, <span class="kw">aes</span>(intercept)) +
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">30</span>) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept=</span><span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Speaker&#39;s intercept&quot;</span>) </code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-54-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>We can conclude that speakers differ substantially in their baseline rate of stress shifting (<code>acoustics</code>) value, but they are always more likely to <em>not</em> shift (negative value).</p>
</div>
<div id="predicted-williams-effect-for-each-speaker" class="section level3">
<h3><span class="header-section-number">9.6.2</span> Predicted Williams effect for each speaker</h3>
<p>One way to do this:</p>
<ul>
<li>Get overall Williams effect (across participant and items)</li>
</ul>
<!-- ((Q4M: Again, slides reference `mod3.full`, which I have replaced with `mod1` as a hotfit)) -->
<!-- ((Q4M: Also, slides reference `givenness2`, which isn't loaded (but is the name of the csv loaded into `givenness` -- so I used this data frame))) -->
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newdata2 &lt;-<span class="st"> </span><span class="kw">with</span>(givenness,
                 <span class="kw">expand.grid</span>(<span class="dt">conditionLabel=</span><span class="kw">unique</span>(conditionLabel),
                             <span class="dt">npType=</span><span class="kw">unique</span>(npType), 
                             <span class="dt">voice=</span><span class="st">&#39;active&#39;</span>))
newdata2$prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(mod1, newdata2, <span class="dt">re.form=</span><span class="ot">NA</span>)

overall &lt;-<span class="st"> </span><span class="kw">mean</span>((newdata2[<span class="dv">1</span>,<span class="st">&#39;prediction&#39;</span>]-newdata2[<span class="dv">2</span>,<span class="st">&#39;prediction&#39;</span>]),
                (newdata2[<span class="dv">3</span>,<span class="st">&#39;prediction&#39;</span>]-newdata2[<span class="dv">4</span>,<span class="st">&#39;prediction&#39;</span>]))</code></pre></div>
<ul>
<li>Then, add each participant’s offset (random slope): <!-- ((Q4M: Figure not identical due to above mentioned issues)) --></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">slopes &lt;-<span class="st"> </span><span class="kw">ranef</span>(mod1)$participant[[<span class="st">&#39;clabel.williams&#39;</span>]]
byParticSlope &lt;-<span class="st">  </span><span class="kw">data.frame</span>(<span class="dt">participant=</span><span class="kw">rownames</span>(<span class="kw">ranef</span>(mod1)$participant),
                             <span class="dt">williamsEffect=</span>overall +<span class="st"> </span>slopes)</code></pre></div>
<p>Visualize distribution of participant effects:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(byParticSlope, <span class="kw">aes</span>(williamsEffect)) +
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">30</span>) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept=</span><span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Speaker&#39;s Williams effect&quot;</span>) </code></pre></div>
<p><img src="09-ordered-nonlinear-predictions_files/figure-html/unnamed-chunk-57-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="c8slopesForFactors" class="section level2">
<h2><span class="header-section-number">9.7</span> Appendix: Random slopes for factors</h2>
<p>Ordered factors have the same issues when fitting random slopes with uncorrelated random-effect structures that we have seen for factors with multiple levels.</p>
<p>As an example, using the <code>alternatives</code> data, we fit a model with a fixed effect of <code>context</code>, coded as an ordered factor (<em>Alternative</em> &lt; <em>NoAlternative</em> &lt; <em>New</em>)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## relevel context to be in the intuitively plausible order
alternatives &lt;-<span class="st"> </span><span class="kw">mutate</span>(alternatives, <span class="dt">context=</span><span class="kw">as.ordered</span>(<span class="kw">factor</span>(context, <span class="dt">levels=</span><span class="kw">c</span>(<span class="st">&quot;Alternative&quot;</span>, <span class="st">&quot;NoAlternative&quot;</span>, <span class="st">&quot;New&quot;</span>))))</code></pre></div>
<p>and with by-participant random effects only.</p>
<p><strong>Exercise</strong>: fit this model</p>
<p>Solution:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(alternativesMod1)</code></pre></div>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: 
## shifted ~ context + (1 + context | item) + (1 + context | participant)
##    Data: alternatives
## Control: glmerControl(optimizer = &quot;bobyqa&quot;)
## 
##      AIC      BIC   logLik deviance df.resid 
##    654.6    721.1   -312.3    624.6      607 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.5891 -0.5648 -0.2148  0.5550  3.5691 
## 
## Random effects:
##  Groups      Name        Variance Std.Dev. Corr       
##  participant (Intercept) 0.65857  0.8115              
##              context.L   0.23473  0.4845   -0.11      
##              context.Q   0.05022  0.2241   -0.27 -0.93
##  item        (Intercept) 0.67813  0.8235              
##              context.L   1.98312  1.4082   0.62       
##              context.Q   0.58874  0.7673   0.61  1.00 
## Number of obs: 622, groups:  participant, 18; item, 12
## 
## Fixed effects:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -1.25159    0.36521  -3.427  0.00061 ***
## context.L   -2.33728    0.58091  -4.024 5.73e-05 ***
## context.Q    0.06461    0.36381   0.178  0.85905    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##           (Intr) cntx.L
## context.L 0.567        
## context.Q 0.461  0.760</code></pre>
<p>The high random-effect correlations here suggest we should try a model with uncorrelated random effects.</p>
<p>As we’ve seen before, fitting a model with standard notation for uncorrelated random effects (<code>||</code>) doesn’t work:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lmer</span>(shifted ~<span class="st"> </span>context +<span class="st"> </span>
<span class="st">       </span>(<span class="dv">1</span>+context||participant) +
<span class="st">       </span>(<span class="dv">1</span>+context||participant), 
     <span class="dt">data=</span>alternatives)</code></pre></div>
<pre><code>## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: large eigenvalue ratio
##  - Rescale variables?</code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: 
## shifted ~ context + ((1 | participant) + (0 + context | participant)) +  
##     ((1 | participant) + (0 + context | participant))
##    Data: alternatives
## REML criterion at convergence: 704.8152
## Random effects:
##  Groups        Name                 Std.Dev. Corr     
##  participant   (Intercept)          0.00000           
##  participant.1 contextAlternative   0.17163           
##                contextNoAlternative 0.10918  0.83     
##                contextNew           0.04853  0.83 1.00
##  participant.2 (Intercept)          0.00000           
##  participant.3 contextAlternative   0.10457           
##                contextNoAlternative 0.08913  0.67     
##                contextNew           0.03927  0.68 1.00
##  Residual                           0.41044           
## Number of obs: 622, groups:  participant, 18
## Fixed Effects:
## (Intercept)    context.L    context.Q  
##     0.33134     -0.30660      0.08701  
## convergence code 0; 1 optimizer warnings; 0 lme4 warnings</code></pre>
<p><strong>Exercise</strong>: carry out the same procedure to implement uncorrelated random effects as we saw for multi-level factors in Section <a href="mixed-effects-logistic-regression.html#c7appendix2">8.175.1</a></p>
<ul>
<li><p>Manually make numeric variables for each contrast, called <code>context1</code>, <code>context2</code></p></li>
<li><p>Fit a model with uncorrelated random effects using these numeric variables</p></li>
<li><p>Check using a model comparison whether the models with and without correlations significantly differ</p></li>
</ul>
</div>
<div id="c8solns" class="section level2">
<h2><span class="header-section-number">9.8</span> Solutions</h2>
<p><strong>Q</strong>: What does the model predict about:</p>
<ul>
<li><p>The overall effect of <code>context</code>? (What kind of relationship with log-odds of stress shift?)</p></li>
<li><p>By-participant and by-item variability in the <code>context</code> effect?</p></li>
</ul>
<p><strong>A</strong>: There is a significant linear effect of the ordered predictor linear, but the quadratic component does not reach significance. There is substantial by-item and by-participant variability with respect to both linear and quadratic effect.</p>
<hr />
<p><strong>Q</strong>: What <span class="math inline">\(k\)</span> would we choose by visual inspection?</p>
<p><strong>A</strong>: k=3 (we choose k so there are k - 2 ‘bends’, and it looks like there is one bend in the curve)</p>
<hr />
<p><strong>Exercise</strong>: To choose <span class="math inline">\(k\)</span> in a data-driven fashion, try fitting these models using just random intercepts (no slopes) of <code>Speaker</code> and <code>Word</code>, and compare them using model comparison:</p>
<ul>
<li><p><code>VOT ~ speakingRateDev</code> (linear model)</p></li>
<li><p>Similar model with RCS for <span class="math inline">\(k = 3\)</span></p></li>
<li><p>Similar model with RCS for <span class="math inline">\(k = 4\)</span></p></li>
</ul>
<p><strong>A</strong>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modelVOT=<span class="kw">lmer</span>(logVOT ~<span class="st"> </span>speakingRateDev +
<span class="st">       </span>(<span class="dv">1</span>|Speaker) +<span class="st"> </span>(<span class="dv">1</span>|Word), 
     <span class="dt">data=</span>vot)
modelVOT.rcs3 &lt;-<span class="st"> </span><span class="kw">lmer</span>(logVOT ~<span class="st"> </span><span class="kw">rcs</span>(speakingRateDev,<span class="dv">3</span>) +<span class="st"> </span>(<span class="dv">1</span>|Speaker) +<span class="st"> </span>(<span class="dv">1</span>|Word), <span class="dt">data=</span>vot)
modelVOT.rcs4 &lt;-<span class="st"> </span><span class="kw">lmer</span>(logVOT ~<span class="st"> </span><span class="kw">rcs</span>(speakingRateDev,<span class="dv">4</span>) +<span class="st"> </span>(<span class="dv">1</span>|Speaker) +<span class="st"> </span>(<span class="dv">1</span>|Word), <span class="dt">data=</span>vot)

<span class="kw">anova</span>(modelVOT,modelVOT.rcs3, modelVOT.rcs4)</code></pre></div>
<pre><code>## refitting model(s) with ML (instead of REML)</code></pre>
<pre><code>## Data: vot
## Models:
## modelVOT: logVOT ~ speakingRateDev + (1 | Speaker) + (1 | Word)
## modelVOT.rcs3: logVOT ~ rcs(speakingRateDev, 3) + (1 | Speaker) + (1 | Word)
## modelVOT.rcs4: logVOT ~ rcs(speakingRateDev, 4) + (1 | Speaker) + (1 | Word)
##               Df    AIC    BIC  logLik deviance   Chisq Chi Df Pr(&gt;Chisq)
## modelVOT       5 4493.5 4525.8 -2241.8   4483.5                          
## modelVOT.rcs3  6 4482.6 4521.4 -2235.3   4470.6 12.9231      1  0.0003246
## modelVOT.rcs4  7 4483.8 4529.0 -2234.9   4469.8  0.8121      1  0.3675095
##                  
## modelVOT         
## modelVOT.rcs3 ***
## modelVOT.rcs4    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The results are line with the visual inspection: Having splines with k = 4 does not improve the model over just having splines with k = 3.</p>
<hr />
<p><strong>Q</strong>:</p>
<ul>
<li><p>What does the fact that both are significant tell us?</p></li>
<li><p>How do people differ in the speech rate effect? (Examine the random slope terms.)</p></li>
</ul>
<p><strong>A</strong>: The fact that both are significant tells us that just fitting a linear predictor would not be justified–the non-linear component contributes significantly to the model. Participants show variability in the linear effect.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-baayen2008analyzing">
<p>Baayen, R. (2008). <em>Analyzing linguistic data</em>. Cambridge: Cambridge University Press.</p>
</div>
<div id="ref-harrell2001regression">
<p>Harrell, F. (2001). <em>Regression modeling strategies: With applications to linear models, logistic regression, and survival analysis</em>. New York: Springer Verlag.</p>
</div>
<div id="ref-barr2013random">
<p>Barr, D. J., Levy, R., Scheepers, C., &amp; Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: Keep it maximal. <em>Journal of Memory and Language</em>, <em>68</em>(3), 255–278.</p>
</div>
<div id="ref-lsmeans">
<p>Lenth, R. (2016). Least-squares means: The R package lsmeans. <em>Journal of Statistical Software</em>, <em>69</em>(1), 1–33. <a href="https://doi.org/10.18637/jss.v069.i01" class="uri">https://doi.org/10.18637/jss.v069.i01</a></p>
</div>
<div id="ref-emmeans">
<p>Lenth, R. (2018). <em>Emmeans: Estimated marginal means, aka least-squares means</em>. Retrieved from <a href="https://CRAN.R-project.org/package=emmeans" class="uri">https://CRAN.R-project.org/package=emmeans</a></p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>This may be confusing, since levels of a factor are often discussed as if they do have an order: “level 1”, “level 2”, and so on. This ordering is used to define contrasts (e.g. which factor level is the “base level”), and is assumed by R when making plots involving the factor, etc. However, this ordering is <em>arbitrary</em>—there is no sense in which level 1 is inherently “less” than level 2.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref1">↩</a></p></li>
<li id="fn2"><p>To do this we’d have to use numeric variables for the contrast, as <a href="#lmem-mwrec">shown for mixed models</a>.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref2">↩</a></p></li>
<li id="fn3"><p>For example, think about trying to fit a cubic equation to the reaction time ~ frequency relationship above. The cubic you would need to draw will grow as frequency<span class="math inline">\(^3\)</span> for frequencies below 0, or above 10.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref3">↩</a></p></li>
<li id="fn4"><p>Ideally you should try to see the number of bends using the <strong>empirical data</strong>, since any nonlinear smoother you use is already making assumptions about how much to smooth the data—analogous to choosing a value of <span class="math inline">\(k\)</span>. However, this isn’t always possible.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref4">↩</a></p></li>
<li id="fn5"><p>This probably isn’t necessary as long as there is an empirical plot where a nonlinear relationship is clear.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref5">↩</a></p></li>
<li id="fn6"><p>At least, we think this is the case.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref6">↩</a></p></li>
<li id="fn7"><p>We use uncorrelated by-item random effects in this model because the correlations do not significantly improve model likelihood (by an LR test), the by-item random effects have smaller magnitudes, and the model with correlations does not converge.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref7">↩</a></p></li>
<li id="fn8"><p>It is beyond our knowledge whether there is actually a good reason for this, but googling (e.g. <a href="https://stats.stackexchange.com/questions/3200/is-adjusting-p-values-in-a-multiple-regression-for-multiple-comparisons-a-good-i?noredirect=1&amp;lq=1">here</a>, <a href="https://stats.stackexchange.com/questions/59670/multiple-regression-and-multiple-comparisons">here</a>) suggests that “why don’t we correct for multiple comparisons in multiple regression models?” is a common question.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref8">↩</a></p></li>
<li id="fn9"><p>Why “post-hoc”? The terminology comes from ANOVAs applied in a traditional experimental setup, where “post-hoc” tests are different from “planned comparisons”.<a href="practical-regression-topics-2-ordered-factors-nonlinear-effects-model-predictions-post-hoc-tests.html#fnref9">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="mixed-effects-logistic-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="datasets-appendix.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
